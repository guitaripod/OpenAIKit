{"sections":[],"seeAlsoSections":[{"identifiers":["doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionFormat","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TimestampGranularity"],"anchor":"Related-Documentation","title":"Related Documentation"},{"generated":true,"identifiers":["doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionFormat","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TimestampGranularity"],"anchor":"Transcribing-Audio","title":"Transcribing Audio"}],"metadata":{"externalID":"s:9OpenAIKit13AudioEndpointC14transcriptionsyAA21TranscriptionResponseVAA0F7RequestVYaKF","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"transcriptions"},{"kind":"text","text":"("},{"kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit20TranscriptionRequestV","text":"TranscriptionRequest"},{"kind":"text","text":") "},{"kind":"keyword","text":"async"},{"kind":"text","text":" "},{"kind":"keyword","text":"throws"},{"kind":"text","text":" -> "},{"kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit21TranscriptionResponseV","text":"TranscriptionResponse"}],"role":"symbol","modules":[{"name":"OpenAIKit"}],"title":"transcriptions(_:)","roleHeading":"Instance Method","symbolKind":"method"},"schemaVersion":{"major":0,"minor":3,"patch":0},"variants":[{"paths":["\/documentation\/openaikit\/audioendpoint\/transcriptions(_:)"],"traits":[{"interfaceLanguage":"swift"}]}],"abstract":[{"type":"text","text":"Transcribes audio into text in the original language."}],"primaryContentSections":[{"kind":"declarations","declarations":[{"platforms":["Linux"],"languages":["swift"],"tokens":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"transcriptions"},{"kind":"text","text":"("},{"kind":"externalParam","text":"_"},{"kind":"text","text":" "},{"kind":"internalParam","text":"request"},{"kind":"text","text":": "},{"kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit20TranscriptionRequestV","text":"TranscriptionRequest","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest"},{"kind":"text","text":") "},{"kind":"keyword","text":"async"},{"kind":"text","text":" "},{"kind":"keyword","text":"throws"},{"kind":"text","text":" -> "},{"kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit21TranscriptionResponseV","text":"TranscriptionResponse","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse"}]}]},{"kind":"parameters","parameters":[{"name":"request","content":[{"inlineContent":[{"text":"A ","type":"text"},{"type":"reference","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","isActive":true},{"text":" containing the audio file and configuration options.","type":"text"}],"type":"paragraph"}]}]},{"kind":"content","content":[{"text":"Return Value","level":2,"type":"heading","anchor":"return-value"},{"inlineContent":[{"text":"A ","type":"text"},{"type":"reference","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","isActive":true},{"text":" containing the transcribed text and optional metadata.","type":"text"}],"type":"paragraph"}]},{"kind":"content","content":[{"level":2,"text":"Discussion","type":"heading","anchor":"discussion"},{"inlineContent":[{"type":"text","text":"This method uses OpenAI’s Whisper model to convert audio files into accurate transcriptions."},{"type":"text","text":" "},{"type":"text","text":"It supports multiple languages, various audio formats, and can provide detailed timing information."}],"type":"paragraph"},{"level":2,"text":"Basic Example","type":"heading","anchor":"Basic-Example"},{"code":["\/\/ Simple transcription","let audioData = try Data(contentsOf: audioFileURL)","let request = TranscriptionRequest(","    file: audioData,","    fileName: \"interview.mp3\"",")","let response = try await audioEndpoint.transcriptions(request)","print(response.text)"],"type":"codeListing","syntax":"swift"},{"level":2,"text":"Advanced Example with Timestamps","type":"heading","anchor":"Advanced-Example-with-Timestamps"},{"code":["\/\/ Detailed transcription with word-level timestamps","let request = TranscriptionRequest(","    file: audioData,","    fileName: \"podcast.mp3\",","    language: \"en\",  \/\/ Hint for better accuracy","    prompt: \"Technical podcast about Swift programming\",","    responseFormat: .verboseJson,","    timestampGranularities: [.word, .segment]",")","","let response = try await audioEndpoint.transcriptions(request)","","\/\/ Access detailed information","print(\"Detected language: \\(response.language ?? \"unknown\")\")","print(\"Duration: \\(response.duration ?? 0) seconds\")","","\/\/ Process word-level timestamps","for word in response.words ?? [] {","    print(\"\\(word.word) at \\(word.start)s\")","}"],"type":"codeListing","syntax":"swift"},{"level":2,"text":"Creating Subtitles","type":"heading","anchor":"Creating-Subtitles"},{"code":["\/\/ Generate SRT subtitles","let request = TranscriptionRequest(","    file: videoAudioData,","    fileName: \"video_audio.mp3\",","    responseFormat: .srt",")","let response = try await audioEndpoint.transcriptions(request)","try response.text.write(to: subtitlesURL, atomically: true, encoding: .utf8)"],"type":"codeListing","syntax":"swift"},{"style":"note","name":"Throws","type":"aside","content":[{"inlineContent":[{"type":"text","text":""},{"isActive":true,"type":"reference","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError"},{"type":"text","text":" if the transcription fails. Common errors include:"}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/invalidFileData","isActive":true,"type":"reference"},{"text":": Audio file is corrupted or in an unsupported format","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/apiError(_:)","isActive":true,"type":"reference"},{"type":"text","text":": File too large (>25MB) or other API errors"}]}]},{"content":[{"inlineContent":[{"type":"reference","isActive":true,"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/rateLimitExceeded"},{"type":"text","text":": Too many concurrent requests"}],"type":"paragraph"}]}],"type":"unorderedList"}]},{"style":"note","name":"Note","type":"aside","content":[{"inlineContent":[{"type":"text","text":"Supported audio formats include: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, and webm."},{"type":"text","text":" "},{"type":"text","text":"File uploads are limited to 25 MB."}],"type":"paragraph"}]}]}],"hierarchy":{"paths":[["doc:\/\/OpenAIKit\/documentation\/OpenAIKit","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint"]]},"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint\/transcriptions(_:)"},"kind":"symbol","references":{"doc://OpenAIKit/documentation/OpenAIKit/AudioEndpoint/transcriptions(_:)":{"fragments":[{"text":"func","kind":"keyword"},{"text":" ","kind":"text"},{"text":"transcriptions","kind":"identifier"},{"text":"(","kind":"text"},{"preciseIdentifier":"s:9OpenAIKit20TranscriptionRequestV","text":"TranscriptionRequest","kind":"typeIdentifier"},{"text":") ","kind":"text"},{"text":"async","kind":"keyword"},{"text":" ","kind":"text"},{"text":"throws","kind":"keyword"},{"text":" -> ","kind":"text"},{"text":"TranscriptionResponse","preciseIdentifier":"s:9OpenAIKit21TranscriptionResponseV","kind":"typeIdentifier"}],"role":"symbol","abstract":[{"type":"text","text":"Transcribes audio into text in the original language."}],"title":"transcriptions(_:)","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint\/transcriptions(_:)","url":"\/documentation\/openaikit\/audioendpoint\/transcriptions(_:)","type":"topic","kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionResponse":{"fragments":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"kind":"identifier","text":"TranscriptionResponse"}],"role":"symbol","navigatorTitle":[{"kind":"identifier","text":"TranscriptionResponse"}],"abstract":[{"type":"text","text":"The response from an audio transcription request."}],"title":"TranscriptionResponse","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","url":"\/documentation\/openaikit\/transcriptionresponse","kind":"symbol","type":"topic"},"doc://OpenAIKit/documentation/OpenAIKit/OpenAIError/apiError(_:)":{"fragments":[{"kind":"keyword","text":"case"},{"kind":"text","text":" "},{"kind":"identifier","text":"apiError"},{"kind":"text","text":"("},{"preciseIdentifier":"s:9OpenAIKit8APIErrorV","kind":"typeIdentifier","text":"APIError"},{"kind":"text","text":")"}],"role":"symbol","abstract":[{"text":"An error response was received from the OpenAI API.","type":"text"}],"title":"OpenAIError.apiError(_:)","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/apiError(_:)","url":"\/documentation\/openaikit\/openaierror\/apierror(_:)","kind":"symbol","type":"topic"},"doc://OpenAIKit/documentation/OpenAIKit/OpenAIError/rateLimitExceeded":{"fragments":[{"text":"case","kind":"keyword"},{"text":" ","kind":"text"},{"text":"rateLimitExceeded","kind":"identifier"}],"role":"symbol","abstract":[{"text":"The API rate limit has been exceeded.","type":"text"}],"title":"OpenAIError.rateLimitExceeded","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/rateLimitExceeded","url":"\/documentation\/openaikit\/openaierror\/ratelimitexceeded","kind":"symbol","type":"topic"},"doc://OpenAIKit/documentation/OpenAIKit/TimestampGranularity":{"fragments":[{"kind":"keyword","text":"enum"},{"kind":"text","text":" "},{"kind":"identifier","text":"TimestampGranularity"}],"role":"symbol","navigatorTitle":[{"kind":"identifier","text":"TimestampGranularity"}],"abstract":[{"text":"Granularity levels for timestamps in transcription responses.","type":"text"}],"title":"TimestampGranularity","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TimestampGranularity","url":"\/documentation\/openaikit\/timestampgranularity","type":"topic","kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit":{"abstract":[{"type":"text","text":"A powerful, type-safe Swift SDK for the OpenAI API with support for all major endpoints and platforms."}],"type":"topic","role":"collection","title":"OpenAIKit","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit","kind":"symbol","url":"\/documentation\/openaikit"},"doc://OpenAIKit/documentation/OpenAIKit/OpenAIError":{"abstract":[{"text":"The primary error type for all OpenAI API interactions.","type":"text"}],"type":"topic","navigatorTitle":[{"kind":"identifier","text":"OpenAIError"}],"role":"symbol","title":"OpenAIError","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError","kind":"symbol","url":"\/documentation\/openaikit\/openaierror","fragments":[{"kind":"keyword","text":"enum"},{"kind":"text","text":" "},{"kind":"identifier","text":"OpenAIError"}]},"doc://OpenAIKit/documentation/OpenAIKit/AudioEndpoint":{"abstract":[{"type":"text","text":"Provides access to OpenAI’s audio-related API endpoints."}],"type":"topic","navigatorTitle":[{"kind":"identifier","text":"AudioEndpoint"}],"role":"symbol","title":"AudioEndpoint","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint","kind":"symbol","url":"\/documentation\/openaikit\/audioendpoint","fragments":[{"kind":"keyword","text":"class"},{"kind":"text","text":" "},{"kind":"identifier","text":"AudioEndpoint"}]},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionRequest":{"navigatorTitle":[{"text":"TranscriptionRequest","kind":"identifier"}],"fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"TranscriptionRequest","kind":"identifier"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","kind":"symbol","type":"topic","abstract":[{"text":"A request to transcribe audio into text using OpenAI’s Whisper model.","type":"text"}],"title":"TranscriptionRequest","role":"symbol","url":"\/documentation\/openaikit\/transcriptionrequest"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionFormat":{"fragments":[{"kind":"keyword","text":"enum"},{"kind":"text","text":" "},{"kind":"identifier","text":"TranscriptionFormat"}],"role":"symbol","navigatorTitle":[{"kind":"identifier","text":"TranscriptionFormat"}],"abstract":[{"type":"text","text":"Output formats for audio transcription."}],"title":"TranscriptionFormat","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionFormat","url":"\/documentation\/openaikit\/transcriptionformat","kind":"symbol","type":"topic"},"doc://OpenAIKit/documentation/OpenAIKit/OpenAIError/invalidFileData":{"fragments":[{"text":"case","kind":"keyword"},{"text":" ","kind":"text"},{"text":"invalidFileData","kind":"identifier"}],"role":"symbol","abstract":[{"type":"text","text":"The provided file data is invalid or corrupted."}],"title":"OpenAIError.invalidFileData","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/invalidFileData","url":"\/documentation\/openaikit\/openaierror\/invalidfiledata","kind":"symbol","type":"topic"}}}