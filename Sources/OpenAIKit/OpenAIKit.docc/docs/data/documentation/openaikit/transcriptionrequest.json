{"abstract":[{"text":"A request to transcribe audio into text using OpenAI’s Whisper model.","type":"text"}],"hierarchy":{"paths":[["doc:\/\/OpenAIKit\/documentation\/OpenAIKit"]]},"seeAlsoSections":[{"identifiers":["doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/SpeechRequest","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranslationRequest"],"generated":true,"anchor":"Audio","title":"Audio"}],"schemaVersion":{"minor":3,"major":0,"patch":0},"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest"},"kind":"symbol","primaryContentSections":[{"kind":"declarations","declarations":[{"tokens":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"TranscriptionRequest","kind":"identifier"}],"platforms":["Linux"],"languages":["swift"]}]},{"content":[{"anchor":"overview","type":"heading","text":"Overview","level":2},{"type":"paragraph","inlineContent":[{"type":"text","text":"Transcribes audio files in various formats and languages into text."},{"text":" ","type":"text"},{"text":"Supports timestamps, different output formats, and streaming responses.","type":"text"}]},{"anchor":"Supported-File-Formats","type":"heading","text":"Supported File Formats","level":2},{"type":"paragraph","inlineContent":[{"text":"flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm","type":"text"}]},{"anchor":"Example","type":"heading","text":"Example","level":2},{"code":["let audioData = try Data(contentsOf: audioFileURL)","let request = TranscriptionRequest(","    file: audioData,","    fileName: \"audio.mp3\",","    language: \"en\",","    responseFormat: .verboseJson,","    timestampGranularities: [.word, .segment]",")"],"type":"codeListing","syntax":"swift"}],"kind":"content"}],"topicSections":[{"identifiers":["doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/init(file:fileName:model:chunkingStrategy:include:language:prompt:responseFormat:stream:temperature:timestampGranularities:)"],"generated":true,"anchor":"Initializers","title":"Initializers"},{"identifiers":["doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/chunkingStrategy","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/file","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/fileName","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/include","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/language","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/model","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/prompt","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/responseFormat","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/stream","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/temperature","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/timestampGranularities"],"generated":true,"anchor":"Instance-Properties","title":"Instance Properties"}],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/openaikit\/transcriptionrequest"]}],"sections":[],"relationshipsSections":[{"identifiers":["doc:\/\/OpenAIKit\/s8SendableP"],"kind":"relationships","type":"conformsTo","title":"Conforms To"}],"metadata":{"symbolKind":"struct","externalID":"s:9OpenAIKit20TranscriptionRequestV","navigatorTitle":[{"kind":"identifier","text":"TranscriptionRequest"}],"role":"symbol","title":"TranscriptionRequest","roleHeading":"Structure","modules":[{"name":"OpenAIKit"}],"fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"TranscriptionRequest","kind":"identifier"}]},"references":{"doc://OpenAIKit/documentation/OpenAIKit":{"abstract":[{"type":"text","text":"A powerful, type-safe Swift SDK for the OpenAI API with support for all major endpoints and platforms."}],"type":"topic","role":"collection","title":"OpenAIKit","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit","kind":"symbol","url":"\/documentation\/openaikit"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionRequest/fileName":{"fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"text":"fileName","kind":"identifier"},{"text":": ","kind":"text"},{"text":"String","kind":"typeIdentifier","preciseIdentifier":"s:SS"}],"role":"symbol","abstract":[{"text":"The name of the audio file including extension.","type":"text"}],"title":"fileName","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/fileName","url":"\/documentation\/openaikit\/transcriptionrequest\/filename","kind":"symbol","type":"topic"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionRequest/prompt":{"fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"text":"prompt","kind":"identifier"},{"text":": ","kind":"text"},{"text":"String","kind":"typeIdentifier","preciseIdentifier":"s:SS"},{"text":"?","kind":"text"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/prompt","kind":"symbol","abstract":[{"type":"text","text":"Optional text to guide the model’s style or continue a previous segment."}],"type":"topic","title":"prompt","role":"symbol","url":"\/documentation\/openaikit\/transcriptionrequest\/prompt"},"doc://OpenAIKit/documentation/OpenAIKit/SpeechRequest":{"fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"SpeechRequest","kind":"identifier"}],"role":"symbol","navigatorTitle":[{"text":"SpeechRequest","kind":"identifier"}],"abstract":[{"type":"text","text":"A request to generate audio from text using OpenAI’s text-to-speech models."}],"title":"SpeechRequest","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/SpeechRequest","url":"\/documentation\/openaikit\/speechrequest","type":"topic","kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionRequest/responseFormat":{"abstract":[{"text":"The format of the transcript output.","type":"text"}],"type":"topic","role":"symbol","title":"responseFormat","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/responseFormat","kind":"symbol","url":"\/documentation\/openaikit\/transcriptionrequest\/responseformat","fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"kind":"identifier","text":"responseFormat"},{"kind":"text","text":": "},{"preciseIdentifier":"s:9OpenAIKit19TranscriptionFormatO","kind":"typeIdentifier","text":"TranscriptionFormat"},{"kind":"text","text":"?"}]},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionRequest/stream":{"abstract":[{"text":"Whether to stream the transcription response.","type":"text"}],"role":"symbol","type":"topic","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/stream","url":"\/documentation\/openaikit\/transcriptionrequest\/stream","kind":"symbol","title":"stream","fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"text":"stream","kind":"identifier"},{"text":": ","kind":"text"},{"text":"Bool","kind":"typeIdentifier","preciseIdentifier":"s:Sb"},{"text":"?","kind":"text"}]},"doc://OpenAIKit/documentation/OpenAIKit/AudioEndpoint":{"abstract":[{"type":"text","text":"Provides access to OpenAI’s audio-related API endpoints."}],"type":"topic","navigatorTitle":[{"kind":"identifier","text":"AudioEndpoint"}],"role":"symbol","title":"AudioEndpoint","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint","kind":"symbol","url":"\/documentation\/openaikit\/audioendpoint","fragments":[{"kind":"keyword","text":"class"},{"kind":"text","text":" "},{"kind":"identifier","text":"AudioEndpoint"}]},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionRequest/file":{"fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"kind":"identifier","text":"file"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Data","preciseIdentifier":"s:20FoundationEssentials4DataV"}],"role":"symbol","abstract":[{"type":"text","text":"The audio file data to transcribe."}],"title":"file","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/file","url":"\/documentation\/openaikit\/transcriptionrequest\/file","type":"topic","kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionRequest/timestampGranularities":{"fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"text":"timestampGranularities","kind":"identifier"},{"text":": [","kind":"text"},{"text":"TimestampGranularity","kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit20TimestampGranularityO"},{"text":"]?","kind":"text"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/timestampGranularities","abstract":[{"text":"The timestamp granularities to populate.","type":"text"}],"kind":"symbol","type":"topic","title":"timestampGranularities","role":"symbol","url":"\/documentation\/openaikit\/transcriptionrequest\/timestampgranularities"},"doc://OpenAIKit/s8SendableP":{"title":"Swift.Sendable","identifier":"doc:\/\/OpenAIKit\/s8SendableP","type":"unresolvable"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionRequest/chunkingStrategy":{"abstract":[{"text":"Strategy for chunking long audio files.","type":"text"}],"role":"symbol","type":"topic","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/chunkingStrategy","url":"\/documentation\/openaikit\/transcriptionrequest\/chunkingstrategy","kind":"symbol","title":"chunkingStrategy","fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"text":"chunkingStrategy","kind":"identifier"},{"text":": ","kind":"text"},{"preciseIdentifier":"s:9OpenAIKit16ChunkingStrategyO","text":"ChunkingStrategy","kind":"typeIdentifier"},{"text":"?","kind":"text"}]},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionRequest/include":{"fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"kind":"identifier","text":"include"},{"kind":"text","text":": ["},{"preciseIdentifier":"s:SS","kind":"typeIdentifier","text":"String"},{"kind":"text","text":"]?"}],"role":"symbol","abstract":[{"text":"Additional information to include in the response.","type":"text"}],"title":"include","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/include","url":"\/documentation\/openaikit\/transcriptionrequest\/include","kind":"symbol","type":"topic"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionRequest/init(file:fileName:model:chunkingStrategy:include:language:prompt:responseFormat:stream:temperature:timestampGranularities:)":{"abstract":[{"type":"text","text":"Creates a new transcription request."}],"type":"topic","role":"symbol","title":"init(file:fileName:model:chunkingStrategy:include:language:prompt:responseFormat:stream:temperature:timestampGranularities:)","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/init(file:fileName:model:chunkingStrategy:include:language:prompt:responseFormat:stream:temperature:timestampGranularities:)","kind":"symbol","url":"\/documentation\/openaikit\/transcriptionrequest\/init(file:filename:model:chunkingstrategy:include:language:prompt:responseformat:stream:temperature:timestampgranularities:)","fragments":[{"kind":"identifier","text":"init"},{"kind":"text","text":"("},{"kind":"externalParam","text":"file"},{"kind":"text","text":": "},{"preciseIdentifier":"s:20FoundationEssentials4DataV","kind":"typeIdentifier","text":"Data"},{"kind":"text","text":", "},{"text":"fileName","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"String","kind":"typeIdentifier","preciseIdentifier":"s:SS"},{"text":", ","kind":"text"},{"text":"model","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"String","kind":"typeIdentifier","preciseIdentifier":"s:SS"},{"kind":"text","text":", "},{"kind":"externalParam","text":"chunkingStrategy"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"ChunkingStrategy","preciseIdentifier":"s:9OpenAIKit16ChunkingStrategyO"},{"kind":"text","text":"?, "},{"kind":"externalParam","text":"include"},{"kind":"text","text":": ["},{"text":"String","preciseIdentifier":"s:SS","kind":"typeIdentifier"},{"text":"]?, ","kind":"text"},{"text":"language","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"String","preciseIdentifier":"s:SS","kind":"typeIdentifier"},{"text":"?, ","kind":"text"},{"text":"prompt","kind":"externalParam"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"String","preciseIdentifier":"s:SS"},{"kind":"text","text":"?, "},{"kind":"externalParam","text":"responseFormat"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"TranscriptionFormat","preciseIdentifier":"s:9OpenAIKit19TranscriptionFormatO"},{"kind":"text","text":"?, "},{"text":"stream","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"Bool","preciseIdentifier":"s:Sb","kind":"typeIdentifier"},{"text":"?, ","kind":"text"},{"text":"temperature","kind":"externalParam"},{"text":": ","kind":"text"},{"text":"Double","preciseIdentifier":"s:Sd","kind":"typeIdentifier"},{"kind":"text","text":"?, "},{"kind":"externalParam","text":"timestampGranularities"},{"kind":"text","text":": ["},{"kind":"typeIdentifier","text":"TimestampGranularity","preciseIdentifier":"s:9OpenAIKit20TimestampGranularityO"},{"kind":"text","text":"]?)"}]},"doc://OpenAIKit/documentation/OpenAIKit/TranslationRequest":{"navigatorTitle":[{"kind":"identifier","text":"TranslationRequest"}],"fragments":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"kind":"identifier","text":"TranslationRequest"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranslationRequest","abstract":[{"type":"text","text":"A request to translate audio into English text."}],"type":"topic","kind":"symbol","title":"TranslationRequest","role":"symbol","url":"\/documentation\/openaikit\/translationrequest"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionRequest/language":{"abstract":[{"type":"text","text":"The language of the audio in ISO-639-1 format."}],"role":"symbol","type":"topic","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/language","title":"language","url":"\/documentation\/openaikit\/transcriptionrequest\/language","kind":"symbol","fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"text":"language","kind":"identifier"},{"text":": ","kind":"text"},{"preciseIdentifier":"s:SS","text":"String","kind":"typeIdentifier"},{"text":"?","kind":"text"}]},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionRequest/model":{"fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"text":"model","kind":"identifier"},{"text":": ","kind":"text"},{"text":"String","preciseIdentifier":"s:SS","kind":"typeIdentifier"}],"role":"symbol","abstract":[{"type":"text","text":"The model to use for transcription."}],"title":"model","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/model","url":"\/documentation\/openaikit\/transcriptionrequest\/model","kind":"symbol","type":"topic"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionRequest":{"navigatorTitle":[{"text":"TranscriptionRequest","kind":"identifier"}],"fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"TranscriptionRequest","kind":"identifier"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","kind":"symbol","type":"topic","abstract":[{"text":"A request to transcribe audio into text using OpenAI’s Whisper model.","type":"text"}],"title":"TranscriptionRequest","role":"symbol","url":"\/documentation\/openaikit\/transcriptionrequest"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionRequest/temperature":{"abstract":[{"text":"Sampling temperature between 0 and 1.","type":"text"}],"role":"symbol","type":"topic","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/temperature","kind":"symbol","title":"temperature","url":"\/documentation\/openaikit\/transcriptionrequest\/temperature","fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"kind":"identifier","text":"temperature"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Double","preciseIdentifier":"s:Sd"},{"kind":"text","text":"?"}]}}}