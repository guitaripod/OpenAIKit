{"primaryContentSections":[{"kind":"declarations","declarations":[{"tokens":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"kind":"identifier","text":"temperature"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Double","preciseIdentifier":"s:Sd"},{"kind":"text","text":"?"}],"languages":["swift"],"platforms":["Linux"]}]},{"kind":"content","content":[{"level":2,"text":"Discussion","anchor":"discussion","type":"heading"},{"type":"paragraph","inlineContent":[{"text":"Higher values like 0.8 will make the output more random, while lower values like 0.2","type":"text"},{"text":" ","type":"text"},{"text":"will make it more focused and deterministic. Generally recommend altering this or","type":"text"},{"text":" ","type":"text"},{"isActive":true,"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/ChatCompletionRequest\/topP","type":"reference"},{"text":" but not both.","type":"text"}]}]}],"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/openaikit\/chatcompletionrequest\/temperature"]}],"hierarchy":{"paths":[["doc:\/\/OpenAIKit\/documentation\/OpenAIKit","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/ChatCompletionRequest"]]},"sections":[],"identifier":{"url":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/ChatCompletionRequest\/temperature","interfaceLanguage":"swift"},"kind":"symbol","schemaVersion":{"patch":0,"major":0,"minor":3},"abstract":[{"text":"The sampling temperature between 0 and 2.","type":"text"}],"seeAlsoSections":[{"generated":true,"identifiers":["doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/ChatCompletionRequest\/maxTokens","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/ChatCompletionRequest\/stop","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/ChatCompletionRequest\/responseFormat"],"anchor":"Response-Control","title":"Response Control"}],"metadata":{"externalID":"s:9OpenAIKit21ChatCompletionRequestV11temperatureSdSgvp","symbolKind":"property","modules":[{"name":"OpenAIKit"}],"roleHeading":"Instance Property","fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"text":"temperature","kind":"identifier"},{"text":": ","kind":"text"},{"text":"Double","kind":"typeIdentifier","preciseIdentifier":"s:Sd"},{"text":"?","kind":"text"}],"role":"symbol","title":"temperature"},"references":{"doc://OpenAIKit/documentation/OpenAIKit":{"abstract":[{"type":"text","text":"A powerful, type-safe Swift SDK for the OpenAI API with support for all major endpoints and platforms."}],"type":"topic","role":"collection","title":"OpenAIKit","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit","kind":"symbol","url":"\/documentation\/openaikit"},"doc://OpenAIKit/documentation/OpenAIKit/ChatCompletionRequest/stop":{"fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"kind":"identifier","text":"stop"},{"kind":"text","text":": "},{"preciseIdentifier":"s:9OpenAIKit12StopSequenceO","kind":"typeIdentifier","text":"StopSequence"},{"kind":"text","text":"?"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/ChatCompletionRequest\/stop","abstract":[{"text":"Up to 4 sequences where the API will stop generating further tokens.","type":"text"}],"kind":"symbol","type":"topic","title":"stop","role":"symbol","url":"\/documentation\/openaikit\/chatcompletionrequest\/stop"},"doc://OpenAIKit/documentation/OpenAIKit/ChatCompletionRequest/topP":{"abstract":[{"text":"Nucleus sampling parameter between 0 and 1.","type":"text"}],"type":"topic","role":"symbol","title":"topP","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/ChatCompletionRequest\/topP","kind":"symbol","url":"\/documentation\/openaikit\/chatcompletionrequest\/topp","fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"text":"topP","kind":"identifier"},{"text":": ","kind":"text"},{"text":"Double","kind":"typeIdentifier","preciseIdentifier":"s:Sd"},{"text":"?","kind":"text"}]},"doc://OpenAIKit/documentation/OpenAIKit/ChatCompletionRequest":{"navigatorTitle":[{"text":"ChatCompletionRequest","kind":"identifier"}],"fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"ChatCompletionRequest","kind":"identifier"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/ChatCompletionRequest","kind":"symbol","type":"topic","abstract":[{"type":"text","text":"A request to create a chat completion with OpenAIâ€™s chat models."}],"title":"ChatCompletionRequest","role":"symbol","url":"\/documentation\/openaikit\/chatcompletionrequest"},"doc://OpenAIKit/documentation/OpenAIKit/ChatCompletionRequest/temperature":{"fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"kind":"identifier","text":"temperature"},{"kind":"text","text":": "},{"preciseIdentifier":"s:Sd","kind":"typeIdentifier","text":"Double"},{"kind":"text","text":"?"}],"role":"symbol","abstract":[{"type":"text","text":"The sampling temperature between 0 and 2."}],"title":"temperature","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/ChatCompletionRequest\/temperature","url":"\/documentation\/openaikit\/chatcompletionrequest\/temperature","kind":"symbol","type":"topic"},"doc://OpenAIKit/documentation/OpenAIKit/ChatCompletionRequest/responseFormat":{"fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"kind":"identifier","text":"responseFormat"},{"kind":"text","text":": "},{"preciseIdentifier":"s:9OpenAIKit14ResponseFormatV","kind":"typeIdentifier","text":"ResponseFormat"},{"kind":"text","text":"?"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/ChatCompletionRequest\/responseFormat","kind":"symbol","type":"topic","abstract":[{"text":"The format that the model must output.","type":"text"}],"title":"responseFormat","role":"symbol","url":"\/documentation\/openaikit\/chatcompletionrequest\/responseformat"},"doc://OpenAIKit/documentation/OpenAIKit/ChatCompletionRequest/maxTokens":{"abstract":[{"type":"text","text":"The maximum number of tokens to generate in the completion."}],"type":"topic","role":"symbol","title":"maxTokens","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/ChatCompletionRequest\/maxTokens","kind":"symbol","url":"\/documentation\/openaikit\/chatcompletionrequest\/maxtokens","fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"kind":"identifier","text":"maxTokens"},{"kind":"text","text":": "},{"kind":"typeIdentifier","preciseIdentifier":"s:Si","text":"Int"},{"kind":"text","text":"?"}]}}}