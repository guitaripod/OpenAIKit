{"variants":[{"paths":["\/documentation\/openaikit\/audioendpoint\/transcriptions(_:)"],"traits":[{"interfaceLanguage":"swift"}]}],"kind":"symbol","sections":[],"hierarchy":{"paths":[["doc:\/\/OpenAIKit\/documentation\/OpenAIKit","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint"]]},"identifier":{"url":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint\/transcriptions(_:)","interfaceLanguage":"swift"},"schemaVersion":{"major":0,"patch":0,"minor":3},"metadata":{"fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"transcriptions"},{"kind":"text","text":"("},{"kind":"typeIdentifier","text":"TranscriptionRequest","preciseIdentifier":"s:9OpenAIKit20TranscriptionRequestV"},{"kind":"text","text":") "},{"kind":"keyword","text":"async"},{"kind":"text","text":" "},{"kind":"keyword","text":"throws"},{"kind":"text","text":" -> "},{"kind":"typeIdentifier","text":"TranscriptionResponse","preciseIdentifier":"s:9OpenAIKit21TranscriptionResponseV"}],"roleHeading":"Instance Method","role":"symbol","modules":[{"name":"OpenAIKit"}],"title":"transcriptions(_:)","externalID":"s:9OpenAIKit13AudioEndpointC14transcriptionsyAA21TranscriptionResponseVAA0F7RequestVYaKF","symbolKind":"method"},"primaryContentSections":[{"kind":"declarations","declarations":[{"tokens":[{"text":"func","kind":"keyword"},{"text":" ","kind":"text"},{"text":"transcriptions","kind":"identifier"},{"text":"(","kind":"text"},{"text":"_","kind":"externalParam"},{"text":" ","kind":"text"},{"text":"request","kind":"internalParam"},{"text":": ","kind":"text"},{"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","text":"TranscriptionRequest","kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit20TranscriptionRequestV"},{"text":") ","kind":"text"},{"text":"async","kind":"keyword"},{"text":" ","kind":"text"},{"text":"throws","kind":"keyword"},{"text":" -> ","kind":"text"},{"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","text":"TranscriptionResponse","kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit21TranscriptionResponseV"}],"platforms":["Linux"],"languages":["swift"]}]},{"kind":"parameters","parameters":[{"content":[{"type":"paragraph","inlineContent":[{"text":"A ","type":"text"},{"type":"reference","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","isActive":true},{"text":" containing the audio file and configuration options.","type":"text"}]}],"name":"request"}]},{"kind":"content","content":[{"text":"Return Value","level":2,"anchor":"return-value","type":"heading"},{"inlineContent":[{"text":"A ","type":"text"},{"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","isActive":true,"type":"reference"},{"text":" containing the transcribed text and optional metadata.","type":"text"}],"type":"paragraph"}]},{"kind":"content","content":[{"anchor":"discussion","level":2,"type":"heading","text":"Discussion"},{"inlineContent":[{"text":"This method uses OpenAI’s Whisper model to convert audio files into accurate transcriptions.","type":"text"},{"text":" ","type":"text"},{"text":"It supports multiple languages, various audio formats, and can provide detailed timing information.","type":"text"}],"type":"paragraph"},{"anchor":"Basic-Example","level":2,"type":"heading","text":"Basic Example"},{"code":["\/\/ Simple transcription","let audioData = try Data(contentsOf: audioFileURL)","let request = TranscriptionRequest(","    file: audioData,","    fileName: \"interview.mp3\"",")","let response = try await audioEndpoint.transcriptions(request)","print(response.text)"],"syntax":"swift","type":"codeListing"},{"anchor":"Advanced-Example-with-Timestamps","level":2,"type":"heading","text":"Advanced Example with Timestamps"},{"code":["\/\/ Detailed transcription with word-level timestamps","let request = TranscriptionRequest(","    file: audioData,","    fileName: \"podcast.mp3\",","    language: \"en\",  \/\/ Hint for better accuracy","    prompt: \"Technical podcast about Swift programming\",","    responseFormat: .verboseJson,","    timestampGranularities: [.word, .segment]",")","","let response = try await audioEndpoint.transcriptions(request)","","\/\/ Access detailed information","print(\"Detected language: \\(response.language ?? \"unknown\")\")","print(\"Duration: \\(response.duration ?? 0) seconds\")","","\/\/ Process word-level timestamps","for word in response.words ?? [] {","    print(\"\\(word.word) at \\(word.start)s\")","}"],"syntax":"swift","type":"codeListing"},{"anchor":"Creating-Subtitles","level":2,"type":"heading","text":"Creating Subtitles"},{"code":["\/\/ Generate SRT subtitles","let request = TranscriptionRequest(","    file: videoAudioData,","    fileName: \"video_audio.mp3\",","    responseFormat: .srt",")","let response = try await audioEndpoint.transcriptions(request)","try response.text.write(to: subtitlesURL, atomically: true, encoding: .utf8)"],"syntax":"swift","type":"codeListing"},{"style":"note","type":"aside","name":"Throws","content":[{"type":"paragraph","inlineContent":[{"type":"text","text":""},{"type":"reference","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError","isActive":true},{"type":"text","text":" if the transcription fails. Common errors include:"}]},{"items":[{"content":[{"inlineContent":[{"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/invalidFileData","isActive":true,"type":"reference"},{"text":": Audio file is corrupted or in an unsupported format","type":"text"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"type":"reference","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/apiError(_:)","isActive":true},{"text":": File too large (>25MB) or other API errors","type":"text"}]}]},{"content":[{"inlineContent":[{"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/rateLimitExceeded","isActive":true,"type":"reference"},{"type":"text","text":": Too many concurrent requests"}],"type":"paragraph"}]}],"type":"unorderedList"}]},{"style":"note","type":"aside","name":"Note","content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Supported audio formats include: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, and webm."},{"type":"text","text":" "},{"type":"text","text":"File uploads are limited to 25 MB."}]}]}]}],"abstract":[{"type":"text","text":"Transcribes audio into text in the original language."}],"seeAlsoSections":[{"identifiers":["doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionFormat","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TimestampGranularity"],"title":"Related Documentation","anchor":"Related-Documentation"},{"generated":true,"identifiers":["doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionFormat","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TimestampGranularity"],"title":"Transcribing Audio","anchor":"Transcribing-Audio"}],"references":{"doc://OpenAIKit/documentation/OpenAIKit/AudioEndpoint/transcriptions(_:)":{"kind":"symbol","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"transcriptions"},{"kind":"text","text":"("},{"kind":"typeIdentifier","text":"TranscriptionRequest","preciseIdentifier":"s:9OpenAIKit20TranscriptionRequestV"},{"kind":"text","text":") "},{"kind":"keyword","text":"async"},{"kind":"text","text":" "},{"kind":"keyword","text":"throws"},{"kind":"text","text":" -> "},{"kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit21TranscriptionResponseV","text":"TranscriptionResponse"}],"url":"\/documentation\/openaikit\/audioendpoint\/transcriptions(_:)","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint\/transcriptions(_:)","role":"symbol","title":"transcriptions(_:)","type":"topic","abstract":[{"text":"Transcribes audio into text in the original language.","type":"text"}]},"doc://OpenAIKit/documentation/OpenAIKit/AudioEndpoint":{"title":"AudioEndpoint","type":"topic","navigatorTitle":[{"kind":"identifier","text":"AudioEndpoint"}],"role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint","fragments":[{"kind":"keyword","text":"class"},{"kind":"text","text":" "},{"kind":"identifier","text":"AudioEndpoint"}],"url":"\/documentation\/openaikit\/audioendpoint","kind":"symbol","abstract":[{"text":"Provides access to OpenAI’s audio-related API endpoints.","type":"text"}]},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionRequest":{"navigatorTitle":[{"kind":"identifier","text":"TranscriptionRequest"}],"kind":"symbol","fragments":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"kind":"identifier","text":"TranscriptionRequest"}],"url":"\/documentation\/openaikit\/transcriptionrequest","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","role":"symbol","title":"TranscriptionRequest","type":"topic","abstract":[{"text":"A request to transcribe audio into text using OpenAI’s Whisper model.","type":"text"}]},"doc://OpenAIKit/documentation/OpenAIKit/OpenAIError/invalidFileData":{"fragments":[{"text":"case","kind":"keyword"},{"text":" ","kind":"text"},{"text":"invalidFileData","kind":"identifier"}],"title":"OpenAIError.invalidFileData","type":"topic","url":"\/documentation\/openaikit\/openaierror\/invalidfiledata","role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/invalidFileData","kind":"symbol","abstract":[{"text":"The provided file data is invalid or corrupted.","type":"text"}]},"doc://OpenAIKit/documentation/OpenAIKit/OpenAIError/rateLimitExceeded":{"fragments":[{"kind":"keyword","text":"case"},{"kind":"text","text":" "},{"kind":"identifier","text":"rateLimitExceeded"}],"title":"OpenAIError.rateLimitExceeded","type":"topic","url":"\/documentation\/openaikit\/openaierror\/ratelimitexceeded","role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/rateLimitExceeded","kind":"symbol","abstract":[{"text":"The API rate limit has been exceeded.","type":"text"}]},"doc://OpenAIKit/documentation/OpenAIKit/OpenAIError/apiError(_:)":{"fragments":[{"text":"case","kind":"keyword"},{"text":" ","kind":"text"},{"text":"apiError","kind":"identifier"},{"text":"(","kind":"text"},{"text":"APIError","preciseIdentifier":"s:9OpenAIKit8APIErrorV","kind":"typeIdentifier"},{"text":")","kind":"text"}],"title":"OpenAIError.apiError(_:)","type":"topic","url":"\/documentation\/openaikit\/openaierror\/apierror(_:)","role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/apiError(_:)","abstract":[{"text":"An error response was received from the OpenAI API.","type":"text"}],"kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionResponse":{"navigatorTitle":[{"text":"TranscriptionResponse","kind":"identifier"}],"kind":"symbol","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"TranscriptionResponse","kind":"identifier"}],"url":"\/documentation\/openaikit\/transcriptionresponse","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","role":"symbol","title":"TranscriptionResponse","type":"topic","abstract":[{"type":"text","text":"The response from an audio transcription request."}]},"doc://OpenAIKit/documentation/OpenAIKit/OpenAIError":{"kind":"symbol","type":"topic","role":"symbol","fragments":[{"kind":"keyword","text":"enum"},{"kind":"text","text":" "},{"kind":"identifier","text":"OpenAIError"}],"url":"\/documentation\/openaikit\/openaierror","abstract":[{"text":"The primary error type for all OpenAI API interactions.","type":"text"}],"navigatorTitle":[{"kind":"identifier","text":"OpenAIError"}],"title":"OpenAIError","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError"},"doc://OpenAIKit/documentation/OpenAIKit/TimestampGranularity":{"navigatorTitle":[{"kind":"identifier","text":"TimestampGranularity"}],"kind":"symbol","fragments":[{"kind":"keyword","text":"enum"},{"kind":"text","text":" "},{"kind":"identifier","text":"TimestampGranularity"}],"url":"\/documentation\/openaikit\/timestampgranularity","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TimestampGranularity","role":"symbol","title":"TimestampGranularity","abstract":[{"type":"text","text":"Granularity levels for timestamps in transcription responses."}],"type":"topic"},"doc://OpenAIKit/documentation/OpenAIKit":{"type":"topic","kind":"symbol","role":"collection","url":"\/documentation\/openaikit","abstract":[{"text":"A powerful, type-safe Swift SDK for the OpenAI API with support for all major endpoints and platforms.","type":"text"}],"title":"OpenAIKit","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionFormat":{"url":"\/documentation\/openaikit\/transcriptionformat","abstract":[{"type":"text","text":"Output formats for audio transcription."}],"navigatorTitle":[{"kind":"identifier","text":"TranscriptionFormat"}],"type":"topic","title":"TranscriptionFormat","fragments":[{"kind":"keyword","text":"enum"},{"kind":"text","text":" "},{"kind":"identifier","text":"TranscriptionFormat"}],"kind":"symbol","role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionFormat"}}}