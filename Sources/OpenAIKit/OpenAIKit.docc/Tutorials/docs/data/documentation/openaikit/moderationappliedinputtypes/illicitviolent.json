{"schemaVersion":{"minor":3,"patch":0,"major":0},"metadata":{"symbolKind":"property","title":"illicitViolent","modules":[{"name":"OpenAIKit"}],"fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"kind":"identifier","text":"illicitViolent"},{"kind":"text","text":": ["},{"kind":"typeIdentifier","preciseIdentifier":"s:SS","text":"String"},{"kind":"text","text":"]"}],"roleHeading":"Instance Property","externalID":"s:9OpenAIKit27ModerationAppliedInputTypesV14illicitViolentSaySSGvp","role":"symbol"},"primaryContentSections":[{"declarations":[{"tokens":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"text":"illicitViolent","kind":"identifier"},{"text":": [","kind":"text"},{"preciseIdentifier":"s:SS","text":"String","kind":"typeIdentifier"},{"text":"]","kind":"text"}],"languages":["swift"],"platforms":["Linux"]}],"kind":"declarations"}],"abstract":[{"type":"text","text":"Input types that triggered violent illicit content."}],"hierarchy":{"paths":[["doc:\/\/OpenAIKit\/documentation\/OpenAIKit","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/ModerationAppliedInputTypes"]]},"kind":"symbol","variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/openaikit\/moderationappliedinputtypes\/illicitviolent"]}],"sections":[],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/ModerationAppliedInputTypes\/illicitViolent"},"references":{"doc://OpenAIKit/documentation/OpenAIKit/ModerationAppliedInputTypes/illicitViolent":{"kind":"symbol","fragments":[{"text":"let","kind":"keyword"},{"text":" ","kind":"text"},{"text":"illicitViolent","kind":"identifier"},{"text":": [","kind":"text"},{"text":"String","preciseIdentifier":"s:SS","kind":"typeIdentifier"},{"text":"]","kind":"text"}],"url":"\/documentation\/openaikit\/moderationappliedinputtypes\/illicitviolent","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/ModerationAppliedInputTypes\/illicitViolent","role":"symbol","title":"illicitViolent","abstract":[{"text":"Input types that triggered violent illicit content.","type":"text"}],"type":"topic"},"doc://OpenAIKit/documentation/OpenAIKit":{"type":"topic","kind":"symbol","role":"collection","url":"\/documentation\/openaikit","abstract":[{"text":"A powerful, type-safe Swift SDK for the OpenAI API with support for all major endpoints and platforms.","type":"text"}],"title":"OpenAIKit","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit"},"doc://OpenAIKit/documentation/OpenAIKit/ModerationAppliedInputTypes":{"type":"topic","kind":"symbol","role":"symbol","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"ModerationAppliedInputTypes","kind":"identifier"}],"url":"\/documentation\/openaikit\/moderationappliedinputtypes","abstract":[{"type":"text","text":"For multimodal moderation, indicates which input types triggered each category."}],"navigatorTitle":[{"text":"ModerationAppliedInputTypes","kind":"identifier"}],"title":"ModerationAppliedInputTypes","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/ModerationAppliedInputTypes"}}}