{"metadata":{"symbolKind":"class","navigatorTitle":[{"kind":"identifier","text":"AudioEndpoint"}],"title":"AudioEndpoint","modules":[{"name":"OpenAIKit"}],"fragments":[{"kind":"keyword","text":"class"},{"kind":"text","text":" "},{"kind":"identifier","text":"AudioEndpoint"}],"roleHeading":"Class","externalID":"s:9OpenAIKit13AudioEndpointC","role":"symbol"},"schemaVersion":{"patch":0,"major":0,"minor":3},"relationshipsSections":[{"type":"conformsTo","identifiers":["doc:\/\/OpenAIKit\/s8SendableP"],"title":"Conforms To","kind":"relationships"}],"topicSections":[{"anchor":"Creating-Speech-from-Text","identifiers":["doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint\/speech(_:)","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/SpeechRequest","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/Voice","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioFormat"],"title":"Creating Speech from Text"},{"anchor":"Transcribing-Audio","identifiers":["doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint\/transcriptions(_:)","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionFormat","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TimestampGranularity"],"title":"Transcribing Audio"},{"anchor":"Translating-Audio","identifiers":["doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint\/translations(_:)","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranslationRequest","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranslationResponse"],"title":"Translating Audio"}],"abstract":[{"type":"text","text":"Provides access to OpenAI’s audio-related API endpoints."}],"seeAlsoSections":[{"generated":true,"anchor":"Audio","identifiers":["doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/SpeechRequest","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranslationRequest"],"title":"Audio"}],"primaryContentSections":[{"declarations":[{"languages":["swift"],"platforms":["Linux"],"tokens":[{"text":"final","kind":"keyword"},{"text":" ","kind":"text"},{"text":"class","kind":"keyword"},{"text":" ","kind":"text"},{"text":"AudioEndpoint","kind":"identifier"}]}],"kind":"declarations"},{"content":[{"level":2,"anchor":"overview","text":"Overview","type":"heading"},{"inlineContent":[{"type":"text","text":"The "},{"code":"AudioEndpoint","type":"codeVoice"},{"type":"text","text":" class handles text-to-speech generation, audio transcription,"},{"type":"text","text":" "},{"type":"text","text":"and audio translation operations. It provides a clean interface for working with"},{"type":"text","text":" "},{"type":"text","text":"OpenAI’s Whisper model for speech recognition and TTS models for speech synthesis."}],"type":"paragraph"},{"level":2,"anchor":"Overview","text":"Overview","type":"heading"},{"inlineContent":[{"text":"This endpoint supports three main audio operations:","type":"text"}],"type":"paragraph"},{"items":[{"content":[{"inlineContent":[{"type":"strong","inlineContent":[{"text":"Speech Generation","type":"text"}]},{"type":"text","text":": Convert text to lifelike spoken audio"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"inlineContent":[{"text":"Transcription","type":"text"}],"type":"strong"},{"text":": Convert audio to text in the same language","type":"text"}],"type":"paragraph"}]},{"content":[{"inlineContent":[{"type":"strong","inlineContent":[{"text":"Translation","type":"text"}]},{"text":": Convert audio in any language to English text","type":"text"}],"type":"paragraph"}]}],"type":"unorderedList"}],"kind":"content"}],"hierarchy":{"paths":[["doc:\/\/OpenAIKit\/documentation\/OpenAIKit"]]},"kind":"symbol","variants":[{"paths":["\/documentation\/openaikit\/audioendpoint"],"traits":[{"interfaceLanguage":"swift"}]}],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint"},"sections":[],"references":{"doc://OpenAIKit/documentation/OpenAIKit/TranslationResponse":{"type":"topic","kind":"symbol","role":"symbol","fragments":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"kind":"identifier","text":"TranslationResponse"}],"url":"\/documentation\/openaikit\/translationresponse","abstract":[{"text":"The response from an audio translation request.","type":"text"}],"navigatorTitle":[{"kind":"identifier","text":"TranslationResponse"}],"title":"TranslationResponse","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranslationResponse"},"doc://OpenAIKit/documentation/OpenAIKit/AudioEndpoint/speech(_:)":{"url":"\/documentation\/openaikit\/audioendpoint\/speech(_:)","abstract":[{"type":"text","text":"Generates audio from text using OpenAI’s text-to-speech models."}],"type":"topic","title":"speech(_:)","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"speech"},{"kind":"text","text":"("},{"kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit13SpeechRequestV","text":"SpeechRequest"},{"kind":"text","text":") "},{"kind":"keyword","text":"async"},{"kind":"text","text":" "},{"kind":"keyword","text":"throws"},{"kind":"text","text":" -> "},{"kind":"typeIdentifier","text":"Data","preciseIdentifier":"s:20FoundationEssentials4DataV"}],"kind":"symbol","role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint\/speech(_:)"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionFormat":{"url":"\/documentation\/openaikit\/transcriptionformat","abstract":[{"type":"text","text":"Output formats for audio transcription."}],"navigatorTitle":[{"kind":"identifier","text":"TranscriptionFormat"}],"type":"topic","title":"TranscriptionFormat","fragments":[{"kind":"keyword","text":"enum"},{"kind":"text","text":" "},{"kind":"identifier","text":"TranscriptionFormat"}],"kind":"symbol","role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionFormat"},"doc://OpenAIKit/documentation/OpenAIKit/AudioEndpoint":{"title":"AudioEndpoint","type":"topic","navigatorTitle":[{"kind":"identifier","text":"AudioEndpoint"}],"role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint","fragments":[{"kind":"keyword","text":"class"},{"kind":"text","text":" "},{"kind":"identifier","text":"AudioEndpoint"}],"url":"\/documentation\/openaikit\/audioendpoint","kind":"symbol","abstract":[{"text":"Provides access to OpenAI’s audio-related API endpoints.","type":"text"}]},"doc://OpenAIKit/documentation/OpenAIKit/TimestampGranularity":{"navigatorTitle":[{"kind":"identifier","text":"TimestampGranularity"}],"kind":"symbol","fragments":[{"kind":"keyword","text":"enum"},{"kind":"text","text":" "},{"kind":"identifier","text":"TimestampGranularity"}],"url":"\/documentation\/openaikit\/timestampgranularity","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TimestampGranularity","role":"symbol","title":"TimestampGranularity","abstract":[{"type":"text","text":"Granularity levels for timestamps in transcription responses."}],"type":"topic"},"doc://OpenAIKit/documentation/OpenAIKit/Voice":{"title":"Voice","type":"topic","navigatorTitle":[{"kind":"identifier","text":"Voice"}],"role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/Voice","fragments":[{"kind":"keyword","text":"enum"},{"kind":"text","text":" "},{"kind":"identifier","text":"Voice"}],"url":"\/documentation\/openaikit\/voice","kind":"symbol","abstract":[{"text":"Available voices for text-to-speech generation.","type":"text"}]},"doc://OpenAIKit/documentation/OpenAIKit":{"type":"topic","kind":"symbol","role":"collection","url":"\/documentation\/openaikit","abstract":[{"text":"A powerful, type-safe Swift SDK for the OpenAI API with support for all major endpoints and platforms.","type":"text"}],"title":"OpenAIKit","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit"},"doc://OpenAIKit/documentation/OpenAIKit/TranslationRequest":{"url":"\/documentation\/openaikit\/translationrequest","abstract":[{"text":"A request to translate audio into English text.","type":"text"}],"navigatorTitle":[{"kind":"identifier","text":"TranslationRequest"}],"type":"topic","title":"TranslationRequest","fragments":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"kind":"identifier","text":"TranslationRequest"}],"kind":"symbol","role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranslationRequest"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionRequest":{"navigatorTitle":[{"kind":"identifier","text":"TranscriptionRequest"}],"kind":"symbol","fragments":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"kind":"identifier","text":"TranscriptionRequest"}],"url":"\/documentation\/openaikit\/transcriptionrequest","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","role":"symbol","title":"TranscriptionRequest","type":"topic","abstract":[{"text":"A request to transcribe audio into text using OpenAI’s Whisper model.","type":"text"}]},"doc://OpenAIKit/documentation/OpenAIKit/AudioFormat":{"title":"AudioFormat","type":"topic","navigatorTitle":[{"kind":"identifier","text":"AudioFormat"}],"role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioFormat","fragments":[{"kind":"keyword","text":"enum"},{"kind":"text","text":" "},{"kind":"identifier","text":"AudioFormat"}],"url":"\/documentation\/openaikit\/audioformat","kind":"symbol","abstract":[{"text":"Supported audio formats for speech generation and transcription.","type":"text"}]},"doc://OpenAIKit/documentation/OpenAIKit/AudioEndpoint/transcriptions(_:)":{"kind":"symbol","fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"transcriptions"},{"kind":"text","text":"("},{"kind":"typeIdentifier","text":"TranscriptionRequest","preciseIdentifier":"s:9OpenAIKit20TranscriptionRequestV"},{"kind":"text","text":") "},{"kind":"keyword","text":"async"},{"kind":"text","text":" "},{"kind":"keyword","text":"throws"},{"kind":"text","text":" -> "},{"kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit21TranscriptionResponseV","text":"TranscriptionResponse"}],"url":"\/documentation\/openaikit\/audioendpoint\/transcriptions(_:)","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint\/transcriptions(_:)","role":"symbol","title":"transcriptions(_:)","type":"topic","abstract":[{"text":"Transcribes audio into text in the original language.","type":"text"}]},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionResponse":{"navigatorTitle":[{"text":"TranscriptionResponse","kind":"identifier"}],"kind":"symbol","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"TranscriptionResponse","kind":"identifier"}],"url":"\/documentation\/openaikit\/transcriptionresponse","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","role":"symbol","title":"TranscriptionResponse","type":"topic","abstract":[{"type":"text","text":"The response from an audio transcription request."}]},"doc://OpenAIKit/documentation/OpenAIKit/AudioEndpoint/translations(_:)":{"url":"\/documentation\/openaikit\/audioendpoint\/translations(_:)","abstract":[{"text":"Translates audio from any language into English text.","type":"text"}],"type":"topic","title":"translations(_:)","fragments":[{"text":"func","kind":"keyword"},{"text":" ","kind":"text"},{"text":"translations","kind":"identifier"},{"text":"(","kind":"text"},{"text":"TranslationRequest","kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit18TranslationRequestV"},{"text":") ","kind":"text"},{"kind":"keyword","text":"async"},{"kind":"text","text":" "},{"kind":"keyword","text":"throws"},{"kind":"text","text":" -> "},{"kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit19TranslationResponseV","text":"TranslationResponse"}],"kind":"symbol","role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint\/translations(_:)"},"doc://OpenAIKit/documentation/OpenAIKit/SpeechRequest":{"url":"\/documentation\/openaikit\/speechrequest","abstract":[{"text":"A request to generate audio from text using OpenAI’s text-to-speech models.","type":"text"}],"navigatorTitle":[{"text":"SpeechRequest","kind":"identifier"}],"type":"topic","title":"SpeechRequest","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"SpeechRequest","kind":"identifier"}],"kind":"symbol","role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/SpeechRequest"},"doc://OpenAIKit/s8SendableP":{"title":"Swift.Sendable","type":"unresolvable","identifier":"doc:\/\/OpenAIKit\/s8SendableP"}}}