{"metadata":{"role":"project","categoryPathComponent":"OpenAIKit-Tutorials","title":"Transcribing Audio","category":"OpenAIKit"},"identifier":{"url":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/08-Transcribing-Audio","interfaceLanguage":"swift"},"hierarchy":{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit-Tutorials","paths":[["doc:\/\/OpenAIKit\/tutorials\/OpenAIKit-Tutorials","doc:\/\/OpenAIKit\/tutorials\/OpenAIKit-Tutorials\/$volume","doc:\/\/OpenAIKit\/tutorials\/OpenAIKit-Tutorials\/Multimodal-AI"]],"modules":[{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit-Tutorials\/Getting-Started","projects":[{"sections":[{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/01-Setting-Up-OpenAIKit#Install-OpenAIKit","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/01-Setting-Up-OpenAIKit#Obtain-an-API-Key","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/01-Setting-Up-OpenAIKit#Configure-OpenAIKit","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/01-Setting-Up-OpenAIKit#Set-Environment-Variables","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/01-Setting-Up-OpenAIKit#Check-Your-Understanding","kind":"assessment"}],"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/01-Setting-Up-OpenAIKit"},{"sections":[{"kind":"task","reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/02-Your-First-Chat-Completion#Create-a-Simple-Chat-Request"},{"kind":"task","reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/02-Your-First-Chat-Completion#Understanding-Chat-Messages"},{"kind":"task","reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/02-Your-First-Chat-Completion#Customizing-Model-Parameters"},{"kind":"task","reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/02-Your-First-Chat-Completion#Building-a-Chat-Interface"},{"kind":"assessment","reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/02-Your-First-Chat-Completion#Check-Your-Understanding"}],"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/02-Your-First-Chat-Completion"},{"sections":[{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/04-Handling-Errors#Understanding-OpenAIKit-Errors","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/04-Handling-Errors#Implementing-Retry-Logic","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/04-Handling-Errors#User-Friendly-Error-Messages","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/04-Handling-Errors#Building-a-Robust-Error-Handler","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/04-Handling-Errors#Check-Your-Understanding","kind":"assessment"}],"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/04-Handling-Errors"}]},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit-Tutorials\/Chat-Completions","projects":[{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/05-Building-Conversations","sections":[{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/05-Building-Conversations#Managing-Conversation-Context","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/05-Building-Conversations#Implementing-Conversation-Memory","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/05-Building-Conversations#Creating-Dynamic-Personas","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/05-Building-Conversations#Advanced-Conversation-Patterns","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/05-Building-Conversations#Building-a-Complete-Chatbot","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/05-Building-Conversations#Check-Your-Understanding","kind":"assessment"}]},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/06-Streaming-Responses","sections":[{"kind":"task","reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/06-Streaming-Responses#Understanding-Streaming"},{"kind":"task","reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/06-Streaming-Responses#Building-a-Streaming-UI"},{"kind":"task","reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/06-Streaming-Responses#Handling-Stream-Interruptions"},{"kind":"task","reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/06-Streaming-Responses#Advanced-Streaming-Features"},{"kind":"task","reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/06-Streaming-Responses#Cross-Platform-Streaming"},{"kind":"assessment","reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/06-Streaming-Responses#Check-Your-Understanding"}]},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/03-Working-With-Functions","sections":[{"kind":"task","reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/03-Working-With-Functions#Understanding-Function-Calling"},{"kind":"task","reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/03-Working-With-Functions#Implementing-the-Weather-Function"},{"kind":"task","reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/03-Working-With-Functions#Handling-Function-Calls"},{"kind":"task","reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/03-Working-With-Functions#Building-the-Complete-Assistant"},{"kind":"task","reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/03-Working-With-Functions#Advanced-Function-Patterns"},{"kind":"assessment","reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/03-Working-With-Functions#Check-Your-Understanding"}]}]},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit-Tutorials\/Multimodal-AI","projects":[{"sections":[{"kind":"task","reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/07-Generating-Images#Understanding-Image-Models"}],"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/07-Generating-Images"},{"sections":[{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/08-Transcribing-Audio#Basic-Audio-Transcription","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/08-Transcribing-Audio#Advanced-Transcription-Options","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/08-Transcribing-Audio#Audio-Translation","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/08-Transcribing-Audio#Building-a-Voice-Notes-App","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/08-Transcribing-Audio#Handling-Large-Audio-Files","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/08-Transcribing-Audio#Check-Your-Understanding","kind":"assessment"}],"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/08-Transcribing-Audio"},{"sections":[{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Building-Semantic-Search#Understanding-Embeddings","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Building-Semantic-Search#Vector-Similarity-Search","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Building-Semantic-Search#Building-a-Vector-Database","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Building-Semantic-Search#Semantic-Search-Engine","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Building-Semantic-Search#Building-a-Knowledge-Base-App","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Building-Semantic-Search#Advanced-Techniques","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Building-Semantic-Search#Check-Your-Understanding","kind":"assessment"}],"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Building-Semantic-Search"}]},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit-Tutorials\/Advanced-Research","projects":[{"sections":[{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Deep-Research-Analysis#Introduction-to-DeepResearch","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Deep-Research-Analysis#Web-Search-Research","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Deep-Research-Analysis#Code-Interpreter-for-Data-Analysis","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Deep-Research-Analysis#Working-with-MCP-Servers","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Deep-Research-Analysis#Streaming-Research-Responses","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Deep-Research-Analysis#Best-Practices-for-Research-Prompting","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Deep-Research-Analysis#Security-and-Privacy-Considerations","kind":"task"},{"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Deep-Research-Analysis#Check-Your-Understanding","kind":"assessment"}],"reference":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Deep-Research-Analysis"}]}]},"variants":[{"paths":["\/tutorials\/openaikit\/08-transcribing-audio"],"traits":[{"interfaceLanguage":"swift"}]}],"schemaVersion":{"major":0,"minor":3,"patch":0},"sections":[{"estimatedTimeInMinutes":12,"kind":"hero","content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Use Whisper to transcribe audio files into text with high accuracy across multiple languages."}]},{"type":"paragraph","inlineContent":[{"text":"Build a voice note app that converts speech to text with translation capabilities.","type":"text"}]}],"title":"Transcribing Audio","chapter":"Multimodal AI"},{"kind":"tasks","tasks":[{"title":"Basic Audio Transcription","contentSection":[{"kind":"contentAndMedia","content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Learn how to transcribe audio files using the Whisper model."}]}],"mediaPosition":"trailing"}],"stepsSection":[{"runtimePreview":null,"media":null,"type":"step","content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Create a new file for audio transcription."}]}],"caption":[],"code":"audio-01-empty.swift"},{"runtimePreview":null,"media":null,"type":"step","content":[{"inlineContent":[{"type":"text","text":"Import OpenAIKit and AVFoundation for audio handling."}],"type":"paragraph"}],"caption":[],"code":"audio-02-imports.swift"},{"runtimePreview":null,"media":null,"type":"step","content":[{"type":"paragraph","inlineContent":[{"text":"Create a transcription function that accepts an audio file.","type":"text"}]}],"caption":[],"code":"audio-03-function.swift"},{"runtimePreview":null,"media":null,"type":"step","content":[{"inlineContent":[{"type":"text","text":"Build a transcription request with the audio data."}],"type":"paragraph"}],"caption":[],"code":"audio-04-request.swift"},{"runtimePreview":null,"media":null,"type":"step","content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Send the request and extract the transcribed text."}]}],"caption":[],"code":"audio-05-response.swift"}],"anchor":"Basic-Audio-Transcription"},{"title":"Advanced Transcription Options","contentSection":[{"kind":"contentAndMedia","content":[{"type":"paragraph","inlineContent":[{"text":"Explore advanced features like language detection, timestamps, and response formats.","type":"text"}]}],"mediaPosition":"trailing"}],"stepsSection":[{"content":[{"inlineContent":[{"text":"Add language specification for better accuracy.","type":"text"}],"type":"paragraph"}],"caption":[],"type":"step","media":null,"code":null,"runtimePreview":null},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Enable timestamp generation for subtitles."}]}],"caption":[],"type":"step","media":null,"code":null,"runtimePreview":null},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Use different response formats (json, text, srt, vtt)."}]}],"caption":[],"type":"step","media":null,"code":null,"runtimePreview":null},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Add prompt context for domain-specific vocabulary."}]}],"caption":[],"type":"step","media":null,"code":null,"runtimePreview":null},{"content":[{"inlineContent":[{"text":"Implement temperature control for transcription certainty.","type":"text"}],"type":"paragraph"}],"caption":[],"type":"step","media":null,"code":null,"runtimePreview":null}],"anchor":"Advanced-Transcription-Options"},{"title":"Audio Translation","contentSection":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Translate audio from any supported language directly to English.","type":"text"}]}],"kind":"contentAndMedia","mediaPosition":"trailing"}],"stepsSection":[{"content":[{"inlineContent":[{"text":"Create a translation function using the translations endpoint.","type":"text"}],"type":"paragraph"}],"runtimePreview":null,"media":null,"caption":[],"code":"translate-01-function.swift","type":"step"},{"content":[{"inlineContent":[{"type":"text","text":"Build a translation request with audio data."}],"type":"paragraph"}],"runtimePreview":null,"media":null,"caption":[],"code":null,"type":"step"},{"content":[{"type":"paragraph","inlineContent":[{"text":"Handle the translated English text response.","type":"text"}]}],"runtimePreview":null,"media":null,"caption":[],"code":null,"type":"step"},{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Create a language detection system."}]}],"runtimePreview":null,"media":null,"caption":[],"code":"translate-04-detection.swift","type":"step"}],"anchor":"Audio-Translation"},{"title":"Building a Voice Notes App","contentSection":[{"content":[{"inlineContent":[{"text":"Create a complete voice notes application with recording and transcription.","type":"text"}],"type":"paragraph"}],"kind":"contentAndMedia","mediaPosition":"trailing"}],"stepsSection":[{"code":"app-01-recorder.swift","runtimePreview":null,"content":[{"inlineContent":[{"type":"text","text":"Create an audio recorder using AVAudioRecorder."}],"type":"paragraph"}],"type":"step","media":null,"caption":[]},{"code":"app-02-interface.swift","runtimePreview":null,"content":[{"inlineContent":[{"type":"text","text":"Build a recording interface with waveform visualization."}],"type":"paragraph"}],"type":"step","media":null,"caption":[]},{"code":null,"runtimePreview":null,"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Add automatic transcription after recording."}]}],"type":"step","media":null,"caption":[]},{"code":null,"runtimePreview":null,"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Implement voice note storage with Core Data."}]}],"type":"step","media":null,"caption":[]},{"code":null,"runtimePreview":null,"content":[{"inlineContent":[{"type":"text","text":"Add search and filtering by transcribed content."}],"type":"paragraph"}],"type":"step","media":null,"caption":[]},{"code":"app-06-export.swift","runtimePreview":null,"content":[{"type":"paragraph","inlineContent":[{"text":"Create export options for notes and transcripts.","type":"text"}]}],"type":"step","media":null,"caption":[]}],"anchor":"Building-a-Voice-Notes-App"},{"title":"Handling Large Audio Files","contentSection":[{"mediaPosition":"trailing","kind":"contentAndMedia","content":[{"inlineContent":[{"type":"text","text":"Learn strategies for processing long audio files within API limits."}],"type":"paragraph"}]}],"stepsSection":[{"type":"step","media":null,"caption":[],"code":"chunk-01-split.swift","runtimePreview":null,"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Implement audio file chunking for large files."}]}]},{"type":"step","media":null,"caption":[],"code":null,"runtimePreview":null,"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Create overlap between chunks for context."}]}]},{"type":"step","media":null,"caption":[],"code":null,"runtimePreview":null,"content":[{"type":"paragraph","inlineContent":[{"text":"Process chunks in parallel for speed.","type":"text"}]}]},{"type":"step","media":null,"caption":[],"code":null,"runtimePreview":null,"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Merge transcriptions intelligently."}]}]},{"type":"step","media":null,"caption":[],"code":"chunk-05-progress.swift","runtimePreview":null,"content":[{"type":"paragraph","inlineContent":[{"text":"Add progress tracking for long operations.","type":"text"}]}]}],"anchor":"Handling-Large-Audio-Files"}]},{"kind":"assessments","assessments":[{"content":[],"choices":[{"isCorrect":false,"justification":[{"type":"paragraph","inlineContent":[{"type":"text","text":"The limit is higher than this."}]}],"content":[{"type":"paragraph","inlineContent":[{"text":"10 MB","type":"text"}]}]},{"isCorrect":true,"justification":[{"inlineContent":[{"type":"text","text":"Whisper API accepts files up to 25 MB."}],"type":"paragraph"}],"content":[{"inlineContent":[{"type":"text","text":"25 MB"}],"type":"paragraph"}]},{"isCorrect":false,"justification":[{"type":"paragraph","inlineContent":[{"type":"text","text":"This exceeds the API limit."}]}],"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"100 MB"}]}]}],"type":"multiple-choice","title":[{"type":"paragraph","inlineContent":[{"text":"What’s the maximum file size for Whisper API?","type":"text"}]}]},{"content":[],"choices":[{"justification":[{"inlineContent":[{"text":"Whisper supports many audio formats.","type":"text"}],"type":"paragraph"}],"isCorrect":false,"content":[{"inlineContent":[{"text":"Only MP3","type":"text"}],"type":"paragraph"}]},{"justification":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Whisper supports a wide variety of audio formats."}]}],"isCorrect":true,"content":[{"type":"paragraph","inlineContent":[{"text":"MP3, MP4, M4A, WAV, WEBM, and more","type":"text"}]}]},{"justification":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Whisper supports both compressed and uncompressed formats."}]}],"isCorrect":false,"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Only uncompressed formats like WAV"}]}]}],"type":"multiple-choice","title":[{"inlineContent":[{"type":"text","text":"What audio formats does Whisper support?"}],"type":"paragraph"}]}],"anchor":"Check-Your-Understanding"},{"abstract":[{"type":"text","text":"Create intelligent search systems using embeddings to find semantically similar content."}],"kind":"callToAction","featuredEyebrow":"Tutorial","title":"Building Semantic Search","action":{"overridingTitle":"Get started","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Building-Semantic-Search","overridingTitleInlineContent":[{"text":"Get started","type":"text"}],"type":"reference","isActive":true}}],"kind":"project","references":{"doc://OpenAIKit/tutorials/OpenAIKit/02-Your-First-Chat-Completion#Check-Your-Understanding":{"title":"Check Your Understanding","type":"link","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/02-Your-First-Chat-Completion#Check-Your-Understanding","titleInlineContent":[{"type":"text","text":"Check Your Understanding"}],"url":"\/tutorials\/openaikit\/02-your-first-chat-completion#Check-Your-Understanding"},"chunk-01-split.swift":{"syntax":"swift","highlights":[],"fileName":"AudioChunking.swift","fileType":"swift","type":"file","identifier":"chunk-01-split.swift","content":["import Foundation","import AVFoundation","import OpenAIKit","","\/\/ MARK: - Audio Chunker","","class AudioChunker {","    private let maxChunkSize: Int = 25 * 1024 * 1024  \/\/ 25MB (OpenAI limit)","    private let optimalChunkDuration: TimeInterval = 600  \/\/ 10 minutes","    ","    struct AudioChunk {","        let id: UUID","        let index: Int","        let data: Data","        let startTime: TimeInterval","        let endTime: TimeInterval","        let duration: TimeInterval","        ","        var size: Int {","            data.count","        }","        ","        var formattedTimeRange: String {","            let startMinutes = Int(startTime) \/ 60","            let startSeconds = Int(startTime) % 60","            let endMinutes = Int(endTime) \/ 60","            let endSeconds = Int(endTime) % 60","            ","            return String(format: \"%02d:%02d - %02d:%02d\", ","                         startMinutes, startSeconds, endMinutes, endSeconds)","        }","    }","    ","    \/\/ Split audio file into chunks","    func splitAudioFile(at url: URL) async throws -> [AudioChunk] {","        let asset = AVAsset(url: url)","        ","        \/\/ Check if we need to split","        let fileSize = try FileManager.default.attributesOfItem(atPath: url.path)[.size] as? Int ?? 0","        if fileSize <= maxChunkSize {","            \/\/ File is small enough, return as single chunk","            let data = try Data(contentsOf: url)","            let duration = CMTimeGetSeconds(asset.duration)","            ","            return [AudioChunk(","                id: UUID(),","                index: 0,","                data: data,","                startTime: 0,","                endTime: duration,","                duration: duration","            )]","        }","        ","        \/\/ Split into chunks","        return try await splitLargeAudioFile(asset: asset, url: url)","    }","    ","    private func splitLargeAudioFile(asset: AVAsset, url: URL) async throws -> [AudioChunk] {","        var chunks: [AudioChunk] = []","        let totalDuration = CMTimeGetSeconds(asset.duration)","        ","        \/\/ Calculate chunk duration based on file size and duration","        let fileSize = try FileManager.default.attributesOfItem(atPath: url.path)[.size] as? Int ?? 0","        let bytesPerSecond = Double(fileSize) \/ totalDuration","        let maxChunkDuration = Double(maxChunkSize) \/ bytesPerSecond","        let chunkDuration = min(optimalChunkDuration, maxChunkDuration)","        ","        var currentTime: TimeInterval = 0","        var chunkIndex = 0","        ","        while currentTime < totalDuration {","            let endTime = min(currentTime + chunkDuration, totalDuration)","            ","            \/\/ Extract chunk","            let chunkData = try await extractAudioChunk(","                from: asset,","                startTime: currentTime,","                endTime: endTime","            )","            ","            let chunk = AudioChunk(","                id: UUID(),","                index: chunkIndex,","                data: chunkData,","                startTime: currentTime,","                endTime: endTime,","                duration: endTime - currentTime","            )","            ","            chunks.append(chunk)","            ","            currentTime = endTime","            chunkIndex += 1","        }","        ","        return chunks","    }","    ","    private func extractAudioChunk(","        from asset: AVAsset,","        startTime: TimeInterval,","        endTime: TimeInterval","    ) async throws -> Data {","        \/\/ Create composition","        let composition = AVMutableComposition()","        ","        guard let audioTrack = asset.tracks(withMediaType: .audio).first else {","            throw ChunkError.noAudioTrack","        }","        ","        let compositionTrack = composition.addMutableTrack(","            withMediaType: .audio,","            preferredTrackID: kCMPersistentTrackID_Invalid","        )","        ","        let startCMTime = CMTime(seconds: startTime, preferredTimescale: 1000)","        let endCMTime = CMTime(seconds: endTime, preferredTimescale: 1000)","        let timeRange = CMTimeRange(start: startCMTime, end: endCMTime)","        ","        try compositionTrack?.insertTimeRange(","            timeRange,","            of: audioTrack,","            at: .zero","        )","        ","        \/\/ Export to temporary file","        let tempURL = FileManager.default.temporaryDirectory","            .appendingPathComponent(UUID().uuidString)","            .appendingPathExtension(\"m4a\")","        ","        let exportSession = AVAssetExportSession(","            asset: composition,","            presetName: AVAssetExportPresetAppleM4A","        )","        ","        exportSession?.outputURL = tempURL","        exportSession?.outputFileType = .m4a","        ","        await exportSession?.export()","        ","        guard exportSession?.status == .completed else {","            throw ChunkError.exportFailed(exportSession?.error)","        }","        ","        \/\/ Read exported data","        let data = try Data(contentsOf: tempURL)","        ","        \/\/ Clean up","        try? FileManager.default.removeItem(at: tempURL)","        ","        return data","    }","    ","    \/\/ Estimate number of chunks needed","    func estimateChunkCount(for url: URL) throws -> Int {","        let fileSize = try FileManager.default.attributesOfItem(atPath: url.path)[.size] as? Int ?? 0","        ","        if fileSize <= maxChunkSize {","            return 1","        }","        ","        return Int(ceil(Double(fileSize) \/ Double(maxChunkSize)))","    }","    ","    \/\/ Calculate optimal chunk size for a given duration","    func calculateOptimalChunkSize(","        totalDuration: TimeInterval,","        fileSize: Int","    ) -> (chunkDuration: TimeInterval, estimatedChunks: Int) {","        let bytesPerSecond = Double(fileSize) \/ totalDuration","        let maxChunkDuration = Double(maxChunkSize) \/ bytesPerSecond","        let chunkDuration = min(optimalChunkDuration, maxChunkDuration)","        let estimatedChunks = Int(ceil(totalDuration \/ chunkDuration))","        ","        return (chunkDuration, estimatedChunks)","    }","}","","\/\/ MARK: - Chunk Manager","","class AudioChunkManager {","    private let chunker = AudioChunker()","    private var chunks: [AudioChunker.AudioChunk] = []","    private var processedChunks: Set<UUID> = []","    ","    func prepareAudioFile(_ url: URL) async throws -> ChunkingResult {","        let startTime = Date()","        ","        \/\/ Get file info","        let asset = AVAsset(url: url)","        let duration = CMTimeGetSeconds(asset.duration)","        let fileSize = try FileManager.default.attributesOfItem(atPath: url.path)[.size] as? Int ?? 0","        ","        \/\/ Split into chunks","        chunks = try await chunker.splitAudioFile(at: url)","        ","        let processingTime = Date().timeIntervalSince(startTime)","        ","        return ChunkingResult(","            originalFile: url,","            chunks: chunks,","            totalDuration: duration,","            totalSize: fileSize,","            processingTime: processingTime","        )","    }","    ","    func getChunk(at index: Int) -> AudioChunker.AudioChunk? {","        guard index >= 0 && index < chunks.count else { return nil }","        return chunks[index]","    }","    ","    func markChunkAsProcessed(_ chunkId: UUID) {","        processedChunks.insert(chunkId)","    }","    ","    func isChunkProcessed(_ chunkId: UUID) -> Bool {","        processedChunks.contains(chunkId)","    }","    ","    func reset() {","        chunks.removeAll()","        processedChunks.removeAll()","    }","    ","    var totalChunks: Int {","        chunks.count","    }","    ","    var processedCount: Int {","        processedChunks.count","    }","    ","    var progress: Double {","        guard totalChunks > 0 else { return 0 }","        return Double(processedCount) \/ Double(totalChunks)","    }","}","","\/\/ MARK: - Models","","struct ChunkingResult {","    let originalFile: URL","    let chunks: [AudioChunker.AudioChunk]","    let totalDuration: TimeInterval","    let totalSize: Int","    let processingTime: TimeInterval","    ","    var averageChunkSize: Int {","        guard !chunks.isEmpty else { return 0 }","        return totalSize \/ chunks.count","    }","    ","    var formattedSize: String {","        ByteCountFormatter.string(fromByteCount: Int64(totalSize), countStyle: .file)","    }","}","","enum ChunkError: LocalizedError {","    case noAudioTrack","    case exportFailed(Error?)","    case invalidTimeRange","    ","    var errorDescription: String? {","        switch self {","        case .noAudioTrack:","            return \"No audio track found in the file\"","        case .exportFailed(let error):","            return \"Failed to export audio chunk: \\(error?.localizedDescription ?? \"Unknown error\")\"","        case .invalidTimeRange:","            return \"Invalid time range specified for chunk\"","        }","    }","}"]},"doc://OpenAIKit/tutorials/OpenAIKit/09-Deep-Research-Analysis#Introduction-to-DeepResearch":{"type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Deep-Research-Analysis#Introduction-to-DeepResearch","role":"pseudoSymbol","title":"Introduction to DeepResearch","abstract":[{"type":"text","text":"Leverage DeepResearch to perform comprehensive research with web search, code interpretation, and custom data sources."}],"url":"\/tutorials\/openaikit\/09-deep-research-analysis#Introduction-to-DeepResearch","kind":"section"},"doc://OpenAIKit/tutorials/OpenAIKit/06-Streaming-Responses#Understanding-Streaming":{"identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/06-Streaming-Responses#Understanding-Streaming","type":"section","role":"pseudoSymbol","title":"Understanding Streaming","abstract":[{"type":"text","text":"Implement real-time streaming to create responsive chat experiences that display responses as they’re generated."}],"url":"\/tutorials\/openaikit\/06-streaming-responses#Understanding-Streaming","kind":"section"},"doc://OpenAIKit/tutorials/OpenAIKit/09-Deep-Research-Analysis#Security-and-Privacy-Considerations":{"title":"Security and Privacy Considerations","abstract":[{"type":"text","text":"Leverage DeepResearch to perform comprehensive research with web search, code interpretation, and custom data sources."}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Deep-Research-Analysis#Security-and-Privacy-Considerations","url":"\/tutorials\/openaikit\/09-deep-research-analysis#Security-and-Privacy-Considerations"},"doc://OpenAIKit/tutorials/OpenAIKit/04-Handling-Errors#Building-a-Robust-Error-Handler":{"identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/04-Handling-Errors#Building-a-Robust-Error-Handler","type":"section","role":"pseudoSymbol","title":"Building a Robust Error Handler","abstract":[{"type":"text","text":"Learn how to gracefully handle errors and edge cases when working with the OpenAI API."}],"url":"\/tutorials\/openaikit\/04-handling-errors#Building-a-Robust-Error-Handler","kind":"section"},"doc://OpenAIKit/tutorials/OpenAIKit/08-Transcribing-Audio#Building-a-Voice-Notes-App":{"type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/08-Transcribing-Audio#Building-a-Voice-Notes-App","role":"pseudoSymbol","title":"Building a Voice Notes App","abstract":[{"type":"text","text":"Use Whisper to transcribe audio files into text with high accuracy across multiple languages."}],"url":"\/tutorials\/openaikit\/08-transcribing-audio#Building-a-Voice-Notes-App","kind":"section"},"doc://OpenAIKit/tutorials/OpenAIKit/01-Setting-Up-OpenAIKit":{"type":"topic","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/01-Setting-Up-OpenAIKit","role":"project","title":"Setting Up OpenAIKit","abstract":[{"type":"text","text":"Configure OpenAIKit in your Swift project and authenticate with the OpenAI API."}],"estimatedTime":"10min","url":"\/tutorials\/openaikit\/01-setting-up-openaikit","kind":"project"},"doc://OpenAIKit/tutorials/OpenAIKit/01-Setting-Up-OpenAIKit#Set-Environment-Variables":{"identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/01-Setting-Up-OpenAIKit#Set-Environment-Variables","type":"section","role":"pseudoSymbol","title":"Set Environment Variables","abstract":[{"type":"text","text":"Configure OpenAIKit in your Swift project and authenticate with the OpenAI API."}],"url":"\/tutorials\/openaikit\/01-setting-up-openaikit#Set-Environment-Variables","kind":"section"},"doc://OpenAIKit/tutorials/OpenAIKit/08-Transcribing-Audio#Audio-Translation":{"title":"Audio Translation","abstract":[{"type":"text","text":"Use Whisper to transcribe audio files into text with high accuracy across multiple languages."}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/08-Transcribing-Audio#Audio-Translation","url":"\/tutorials\/openaikit\/08-transcribing-audio#Audio-Translation"},"doc://OpenAIKit/tutorials/OpenAIKit/05-Building-Conversations#Building-a-Complete-Chatbot":{"type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/05-Building-Conversations#Building-a-Complete-Chatbot","role":"pseudoSymbol","title":"Building a Complete Chatbot","abstract":[{"type":"text","text":"Create sophisticated conversational AI experiences by managing context, memory, and multi-turn interactions."}],"url":"\/tutorials\/openaikit\/05-building-conversations#Building-a-Complete-Chatbot","kind":"section"},"doc://OpenAIKit/tutorials/OpenAIKit/03-Working-With-Functions#Advanced-Function-Patterns":{"type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/03-Working-With-Functions#Advanced-Function-Patterns","role":"pseudoSymbol","title":"Advanced Function Patterns","abstract":[{"type":"text","text":"Extend GPT’s capabilities by defining custom functions that the model can call to perform actions or retrieve information."}],"url":"\/tutorials\/openaikit\/03-working-with-functions#Advanced-Function-Patterns","kind":"section"},"doc://OpenAIKit/tutorials/OpenAIKit/07-Generating-Images#Understanding-Image-Models":{"type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/07-Generating-Images#Understanding-Image-Models","role":"pseudoSymbol","title":"Understanding Image Models","abstract":[{"type":"text","text":"Master image generation using DALL-E 2, DALL-E 3, and the advanced GPT Image 1 model. Learn to select the right model, handle errors professionally, and build production-ready image generation features."}],"url":"\/tutorials\/openaikit\/07-generating-images#Understanding-Image-Models","kind":"section"},"doc://OpenAIKit/tutorials/OpenAIKit/09-Deep-Research-Analysis":{"type":"topic","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Deep-Research-Analysis","role":"project","title":"Deep Research and Analysis","abstract":[{"type":"text","text":"Leverage DeepResearch to perform comprehensive research with web search, code interpretation, and custom data sources."}],"estimatedTime":"25min","url":"\/tutorials\/openaikit\/09-deep-research-analysis","kind":"project"},"audio-01-empty.swift":{"fileName":"AudioTranscriber.swift","type":"file","syntax":"swift","content":["\/\/ AudioTranscriber.swift"],"identifier":"audio-01-empty.swift","fileType":"swift","highlights":[]},"doc://OpenAIKit/tutorials/OpenAIKit/02-Your-First-Chat-Completion#Create-a-Simple-Chat-Request":{"title":"Create a Simple Chat Request","abstract":[{"type":"text","text":"Make your first API call to generate text using OpenAI’s chat completion models."}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/02-Your-First-Chat-Completion#Create-a-Simple-Chat-Request","url":"\/tutorials\/openaikit\/02-your-first-chat-completion#Create-a-Simple-Chat-Request"},"doc://OpenAIKit/tutorials/OpenAIKit/04-Handling-Errors#Implementing-Retry-Logic":{"title":"Implementing Retry Logic","abstract":[{"type":"text","text":"Learn how to gracefully handle errors and edge cases when working with the OpenAI API."}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/04-Handling-Errors#Implementing-Retry-Logic","url":"\/tutorials\/openaikit\/04-handling-errors#Implementing-Retry-Logic"},"doc://OpenAIKit/tutorials/OpenAIKit/06-Streaming-Responses#Advanced-Streaming-Features":{"title":"Advanced Streaming Features","abstract":[{"type":"text","text":"Implement real-time streaming to create responsive chat experiences that display responses as they’re generated."}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/06-Streaming-Responses#Advanced-Streaming-Features","url":"\/tutorials\/openaikit\/06-streaming-responses#Advanced-Streaming-Features"},"doc://OpenAIKit/tutorials/OpenAIKit/08-Transcribing-Audio":{"title":"Transcribing Audio","abstract":[{"type":"text","text":"Use Whisper to transcribe audio files into text with high accuracy across multiple languages."}],"role":"project","kind":"project","type":"topic","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/08-Transcribing-Audio","url":"\/tutorials\/openaikit\/08-transcribing-audio","estimatedTime":"12min"},"doc://OpenAIKit/tutorials/OpenAIKit-Tutorials/Multimodal-AI":{"title":"Multimodal AI","abstract":[],"role":"article","kind":"article","type":"topic","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit-Tutorials\/Multimodal-AI","url":"\/tutorials\/openaikit-tutorials\/multimodal-ai"},"doc://OpenAIKit/tutorials/OpenAIKit/09-Deep-Research-Analysis#Web-Search-Research":{"type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Deep-Research-Analysis#Web-Search-Research","role":"pseudoSymbol","title":"Web Search Research","abstract":[{"type":"text","text":"Leverage DeepResearch to perform comprehensive research with web search, code interpretation, and custom data sources."}],"url":"\/tutorials\/openaikit\/09-deep-research-analysis#Web-Search-Research","kind":"section"},"doc://OpenAIKit/tutorials/OpenAIKit/05-Building-Conversations#Managing-Conversation-Context":{"type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/05-Building-Conversations#Managing-Conversation-Context","role":"pseudoSymbol","title":"Managing Conversation Context","abstract":[{"type":"text","text":"Create sophisticated conversational AI experiences by managing context, memory, and multi-turn interactions."}],"url":"\/tutorials\/openaikit\/05-building-conversations#Managing-Conversation-Context","kind":"section"},"doc://OpenAIKit/tutorials/OpenAIKit/09-Building-Semantic-Search#Check-Your-Understanding":{"type":"link","title":"Check Your Understanding","titleInlineContent":[{"text":"Check Your Understanding","type":"text"}],"identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Building-Semantic-Search#Check-Your-Understanding","url":"\/tutorials\/openaikit\/09-building-semantic-search#Check-Your-Understanding"},"doc://OpenAIKit/tutorials/OpenAIKit/05-Building-Conversations":{"title":"Building Conversations","abstract":[{"type":"text","text":"Create sophisticated conversational AI experiences by managing context, memory, and multi-turn interactions."}],"role":"project","kind":"project","type":"topic","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/05-Building-Conversations","url":"\/tutorials\/openaikit\/05-building-conversations","estimatedTime":"18min"},"doc://OpenAIKit/tutorials/OpenAIKit/02-Your-First-Chat-Completion#Building-a-Chat-Interface":{"title":"Building a Chat Interface","abstract":[{"type":"text","text":"Make your first API call to generate text using OpenAI’s chat completion models."}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/02-Your-First-Chat-Completion#Building-a-Chat-Interface","url":"\/tutorials\/openaikit\/02-your-first-chat-completion#Building-a-Chat-Interface"},"doc://OpenAIKit/tutorials/OpenAIKit/07-Generating-Images":{"title":"Generating Images with AI","abstract":[{"type":"text","text":"Master image generation using DALL-E 2, DALL-E 3, and the advanced GPT Image 1 model. Learn to select the right model, handle errors professionally, and build production-ready image generation features."}],"role":"project","kind":"project","type":"topic","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/07-Generating-Images","url":"\/tutorials\/openaikit\/07-generating-images","estimatedTime":"25min"},"doc://OpenAIKit/tutorials/OpenAIKit/05-Building-Conversations#Creating-Dynamic-Personas":{"title":"Creating Dynamic Personas","abstract":[{"type":"text","text":"Create sophisticated conversational AI experiences by managing context, memory, and multi-turn interactions."}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/05-Building-Conversations#Creating-Dynamic-Personas","url":"\/tutorials\/openaikit\/05-building-conversations#Creating-Dynamic-Personas"},"doc://OpenAIKit/tutorials/OpenAIKit/08-Transcribing-Audio#Check-Your-Understanding":{"title":"Check Your Understanding","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/08-Transcribing-Audio#Check-Your-Understanding","titleInlineContent":[{"text":"Check Your Understanding","type":"text"}],"url":"\/tutorials\/openaikit\/08-transcribing-audio#Check-Your-Understanding","type":"link"},"audio-03-function.swift":{"syntax":"swift","highlights":[{"line":5},{"line":6},{"line":7},{"line":8},{"line":9},{"line":10},{"line":11},{"line":12},{"line":13}],"fileName":"AudioTranscriber.swift","fileType":"swift","type":"file","identifier":"audio-03-function.swift","content":["\/\/ AudioTranscriber.swift","import Foundation","import OpenAIKit","import AVFoundation","","class AudioTranscriber {","    let openAI = OpenAIManager.shared.client","    ","    func transcribe(audioFileURL: URL) async throws -> String {","        \/\/ Implementation here","        return \"\"","    }","}"]},"doc://OpenAIKit/tutorials/OpenAIKit/06-Streaming-Responses#Cross-Platform-Streaming":{"title":"Cross-Platform Streaming","abstract":[{"type":"text","text":"Implement real-time streaming to create responsive chat experiences that display responses as they’re generated."}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/06-Streaming-Responses#Cross-Platform-Streaming","url":"\/tutorials\/openaikit\/06-streaming-responses#Cross-Platform-Streaming"},"doc://OpenAIKit/tutorials/OpenAIKit/04-Handling-Errors#Understanding-OpenAIKit-Errors":{"title":"Understanding OpenAIKit Errors","abstract":[{"type":"text","text":"Learn how to gracefully handle errors and edge cases when working with the OpenAI API."}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/04-Handling-Errors#Understanding-OpenAIKit-Errors","url":"\/tutorials\/openaikit\/04-handling-errors#Understanding-OpenAIKit-Errors"},"doc://OpenAIKit/tutorials/OpenAIKit/04-Handling-Errors#User-Friendly-Error-Messages":{"identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/04-Handling-Errors#User-Friendly-Error-Messages","type":"section","role":"pseudoSymbol","title":"User-Friendly Error Messages","abstract":[{"type":"text","text":"Learn how to gracefully handle errors and edge cases when working with the OpenAI API."}],"url":"\/tutorials\/openaikit\/04-handling-errors#User-Friendly-Error-Messages","kind":"section"},"doc://OpenAIKit/tutorials/OpenAIKit/06-Streaming-Responses#Building-a-Streaming-UI":{"identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/06-Streaming-Responses#Building-a-Streaming-UI","type":"section","role":"pseudoSymbol","title":"Building a Streaming UI","abstract":[{"text":"Implement real-time streaming to create responsive chat experiences that display responses as they’re generated.","type":"text"}],"url":"\/tutorials\/openaikit\/06-streaming-responses#Building-a-Streaming-UI","kind":"section"},"doc://OpenAIKit/tutorials/OpenAIKit/01-Setting-Up-OpenAIKit#Configure-OpenAIKit":{"type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/01-Setting-Up-OpenAIKit#Configure-OpenAIKit","role":"pseudoSymbol","title":"Configure OpenAIKit","abstract":[{"type":"text","text":"Configure OpenAIKit in your Swift project and authenticate with the OpenAI API."}],"url":"\/tutorials\/openaikit\/01-setting-up-openaikit#Configure-OpenAIKit","kind":"section"},"doc://OpenAIKit/tutorials/OpenAIKit/01-Setting-Up-OpenAIKit#Check-Your-Understanding":{"title":"Check Your Understanding","titleInlineContent":[{"type":"text","text":"Check Your Understanding"}],"url":"\/tutorials\/openaikit\/01-setting-up-openaikit#Check-Your-Understanding","type":"link","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/01-Setting-Up-OpenAIKit#Check-Your-Understanding"},"doc://OpenAIKit/tutorials/OpenAIKit/05-Building-Conversations#Implementing-Conversation-Memory":{"identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/05-Building-Conversations#Implementing-Conversation-Memory","type":"section","role":"pseudoSymbol","title":"Implementing Conversation Memory","abstract":[{"type":"text","text":"Create sophisticated conversational AI experiences by managing context, memory, and multi-turn interactions."}],"url":"\/tutorials\/openaikit\/05-building-conversations#Implementing-Conversation-Memory","kind":"section"},"doc://OpenAIKit/tutorials/OpenAIKit/03-Working-With-Functions#Understanding-Function-Calling":{"title":"Understanding Function Calling","abstract":[{"type":"text","text":"Extend GPT’s capabilities by defining custom functions that the model can call to perform actions or retrieve information."}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/03-Working-With-Functions#Understanding-Function-Calling","url":"\/tutorials\/openaikit\/03-working-with-functions#Understanding-Function-Calling"},"doc://OpenAIKit/tutorials/OpenAIKit/09-Building-Semantic-Search#Semantic-Search-Engine":{"type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Building-Semantic-Search#Semantic-Search-Engine","role":"pseudoSymbol","title":"Semantic Search Engine","abstract":[{"type":"text","text":"Create intelligent search systems using embeddings to find semantically similar content."}],"url":"\/tutorials\/openaikit\/09-building-semantic-search#Semantic-Search-Engine","kind":"section"},"doc://OpenAIKit/tutorials/OpenAIKit/06-Streaming-Responses":{"identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/06-Streaming-Responses","type":"topic","role":"project","title":"Streaming Responses","abstract":[{"text":"Implement real-time streaming to create responsive chat experiences that display responses as they’re generated.","type":"text"}],"estimatedTime":"15min","url":"\/tutorials\/openaikit\/06-streaming-responses","kind":"project"},"doc://OpenAIKit/tutorials/OpenAIKit/05-Building-Conversations#Advanced-Conversation-Patterns":{"title":"Advanced Conversation Patterns","abstract":[{"text":"Create sophisticated conversational AI experiences by managing context, memory, and multi-turn interactions.","type":"text"}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/05-Building-Conversations#Advanced-Conversation-Patterns","url":"\/tutorials\/openaikit\/05-building-conversations#Advanced-Conversation-Patterns"},"doc://OpenAIKit/tutorials/OpenAIKit/01-Setting-Up-OpenAIKit#Obtain-an-API-Key":{"identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/01-Setting-Up-OpenAIKit#Obtain-an-API-Key","type":"section","role":"pseudoSymbol","title":"Obtain an API Key","abstract":[{"type":"text","text":"Configure OpenAIKit in your Swift project and authenticate with the OpenAI API."}],"url":"\/tutorials\/openaikit\/01-setting-up-openaikit#Obtain-an-API-Key","kind":"section"},"doc://OpenAIKit/tutorials/OpenAIKit/02-Your-First-Chat-Completion#Understanding-Chat-Messages":{"title":"Understanding Chat Messages","abstract":[{"type":"text","text":"Make your first API call to generate text using OpenAI’s chat completion models."}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/02-Your-First-Chat-Completion#Understanding-Chat-Messages","url":"\/tutorials\/openaikit\/02-your-first-chat-completion#Understanding-Chat-Messages"},"doc://OpenAIKit/tutorials/OpenAIKit/09-Deep-Research-Analysis#Code-Interpreter-for-Data-Analysis":{"type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Deep-Research-Analysis#Code-Interpreter-for-Data-Analysis","role":"pseudoSymbol","title":"Code Interpreter for Data Analysis","abstract":[{"type":"text","text":"Leverage DeepResearch to perform comprehensive research with web search, code interpretation, and custom data sources."}],"url":"\/tutorials\/openaikit\/09-deep-research-analysis#Code-Interpreter-for-Data-Analysis","kind":"section"},"translate-01-function.swift":{"fileName":"AudioTranslator.swift","type":"file","syntax":"swift","content":["import OpenAIKit","import Foundation","","\/\/ MARK: - Audio Translation Function","","func translateAudio(from audioURL: URL) async throws -> String {","    let openAI = OpenAIKit(apiKey: \"your-api-key\")","    ","    \/\/ Load audio file data","    let audioData = try Data(contentsOf: audioURL)","    ","    \/\/ Create translation request","    let translationRequest = AudioTranslationRequest(","        file: audioData,","        model: \"whisper-1\",","        prompt: nil,  \/\/ Optional: context to help translation","        responseFormat: .json,","        temperature: 0  \/\/ Lower temperature for more consistent translations","    )","    ","    \/\/ Send the request","    let response = try await openAI.createAudioTranslation(request: translationRequest)","    ","    \/\/ Return the translated text","    return response.text","}","","\/\/ MARK: - Translation Manager","","class AudioTranslationManager {","    private let openAI: OpenAIKit","    ","    init(apiKey: String) {","        self.openAI = OpenAIKit(apiKey: apiKey)","    }","    ","    func translate(","        audioFile: URL,","        contextPrompt: String? = nil","    ) async throws -> TranslationResult {","        let startTime = Date()","        ","        \/\/ Load and validate audio","        let audioData = try Data(contentsOf: audioFile)","        ","        \/\/ Check file size (max 25MB)","        let maxSize = 25 * 1024 * 1024","        guard audioData.count <= maxSize else {","            throw TranslationError.fileTooLarge","        }","        ","        \/\/ Create request with context","        let request = AudioTranslationRequest(","            file: audioData,","            model: \"whisper-1\",","            prompt: contextPrompt,","            responseFormat: .verboseJson","        )","        ","        \/\/ Perform translation","        let response = try await openAI.createAudioTranslation(request: request)","        ","        let processingTime = Date().timeIntervalSince(startTime)","        ","        return TranslationResult(","            text: response.text,","            sourceLanguage: response.language ?? \"unknown\",","            duration: response.duration ?? 0,","            processingTime: processingTime,","            segments: response.segments ?? []","        )","    }","    ","    \/\/ Translate with automatic language detection","    func translateWithDetection(","        audioFile: URL","    ) async throws -> (translation: String, detectedLanguage: String) {","        \/\/ First transcribe to detect language","        let transcriptionRequest = AudioTranscriptionRequest(","            file: try Data(contentsOf: audioFile),","            model: \"whisper-1\",","            responseFormat: .verboseJson","        )","        ","        let transcriptionResponse = try await openAI.createAudioTranscription(","            request: transcriptionRequest","        )","        ","        let detectedLanguage = transcriptionResponse.language ?? \"unknown\"","        ","        \/\/ If already in English, return transcription","        if detectedLanguage.lowercased() == \"en\" || detectedLanguage.lowercased() == \"english\" {","            return (transcriptionResponse.text, detectedLanguage)","        }","        ","        \/\/ Otherwise, translate to English","        let translationRequest = AudioTranslationRequest(","            file: try Data(contentsOf: audioFile),","            model: \"whisper-1\"","        )","        ","        let translationResponse = try await openAI.createAudioTranslation(","            request: translationRequest","        )","        ","        return (translationResponse.text, detectedLanguage)","    }","}","","\/\/ MARK: - Models","","struct TranslationResult {","    let text: String","    let sourceLanguage: String","    let duration: Double","    let processingTime: TimeInterval","    let segments: [TranscriptionSegment]","    ","    var averageConfidence: Double {","        guard !segments.isEmpty else { return 0 }","        let totalConfidence = segments.reduce(0) { $0 + ($1.avgLogprob ?? 0) }","        return totalConfidence \/ Double(segments.count)","    }","}","","struct TranscriptionSegment: Codable {","    let id: Int","    let start: Double","    let end: Double","    let text: String","    let avgLogprob: Double?","}","","enum TranslationError: Error {","    case fileTooLarge","    case unsupportedFormat","    case processingFailed","    case languageNotSupported","}"],"identifier":"translate-01-function.swift","fileType":"swift","highlights":[]},"doc://OpenAIKit/tutorials/OpenAIKit/06-Streaming-Responses#Handling-Stream-Interruptions":{"title":"Handling Stream Interruptions","abstract":[{"type":"text","text":"Implement real-time streaming to create responsive chat experiences that display responses as they’re generated."}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/06-Streaming-Responses#Handling-Stream-Interruptions","url":"\/tutorials\/openaikit\/06-streaming-responses#Handling-Stream-Interruptions"},"doc://OpenAIKit/tutorials/OpenAIKit/09-Building-Semantic-Search#Vector-Similarity-Search":{"type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Building-Semantic-Search#Vector-Similarity-Search","role":"pseudoSymbol","title":"Vector Similarity Search","abstract":[{"type":"text","text":"Create intelligent search systems using embeddings to find semantically similar content."}],"url":"\/tutorials\/openaikit\/09-building-semantic-search#Vector-Similarity-Search","kind":"section"},"doc://OpenAIKit/tutorials/OpenAIKit/09-Building-Semantic-Search#Building-a-Knowledge-Base-App":{"title":"Building a Knowledge Base App","abstract":[{"type":"text","text":"Create intelligent search systems using embeddings to find semantically similar content."}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Building-Semantic-Search#Building-a-Knowledge-Base-App","url":"\/tutorials\/openaikit\/09-building-semantic-search#Building-a-Knowledge-Base-App"},"doc://OpenAIKit/tutorials/OpenAIKit/02-Your-First-Chat-Completion#Customizing-Model-Parameters":{"type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/02-Your-First-Chat-Completion#Customizing-Model-Parameters","role":"pseudoSymbol","title":"Customizing Model Parameters","abstract":[{"type":"text","text":"Make your first API call to generate text using OpenAI’s chat completion models."}],"url":"\/tutorials\/openaikit\/02-your-first-chat-completion#Customizing-Model-Parameters","kind":"section"},"audio-05-response.swift":{"syntax":"swift","highlights":[{"line":21},{"line":31},{"line":32},{"line":34},{"line":35},{"line":36},{"line":37},{"line":38},{"line":39},{"line":40},{"line":41},{"line":42},{"line":43},{"line":44},{"line":45},{"line":46},{"line":47},{"line":48}],"fileName":"AudioTranscriber.swift","fileType":"swift","type":"file","identifier":"audio-05-response.swift","content":["\/\/ AudioTranscriber.swift","import Foundation","import OpenAIKit","import AVFoundation","","class AudioTranscriber {","    let openAI = OpenAIManager.shared.client","    ","    func transcribe(audioFileURL: URL) async throws -> String {","        guard let openAI = openAI else {","            throw OpenAIError.missingAPIKey","        }","        ","        \/\/ Read audio file data","        let audioData = try Data(contentsOf: audioFileURL)","        ","        let request = TranscriptionRequest(","            file: FileUpload(","                data: audioData,","                filename: audioFileURL.lastPathComponent,","                contentType: contentType(for: audioFileURL)","            ),","            model: Models.Audio.whisper1,","            language: nil,","            prompt: nil,","            responseFormat: .json,","            temperature: nil,","            timestampGranularities: nil","        )","        ","        let response = try await openAI.audio.transcriptions(request)","        return response.text","    }","    ","    private func contentType(for url: URL) -> String {","        switch url.pathExtension.lowercased() {","        case \"mp3\":","            return \"audio\/mpeg\"","        case \"mp4\", \"m4a\":","            return \"audio\/mp4\"","        case \"wav\":","            return \"audio\/wav\"","        case \"webm\":","            return \"audio\/webm\"","        default:","            return \"audio\/mpeg\"","        }","    }","}"]},"doc://OpenAIKit/tutorials/OpenAIKit/01-Setting-Up-OpenAIKit#Install-OpenAIKit":{"title":"Install OpenAIKit","abstract":[{"text":"Configure OpenAIKit in your Swift project and authenticate with the OpenAI API.","type":"text"}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/01-Setting-Up-OpenAIKit#Install-OpenAIKit","url":"\/tutorials\/openaikit\/01-setting-up-openaikit#Install-OpenAIKit"},"doc://OpenAIKit/tutorials/OpenAIKit-Tutorials/Advanced-Research":{"type":"topic","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit-Tutorials\/Advanced-Research","role":"article","title":"Advanced Research","abstract":[],"url":"\/tutorials\/openaikit-tutorials\/advanced-research","kind":"article"},"doc://OpenAIKit/tutorials/OpenAIKit/09-Building-Semantic-Search#Building-a-Vector-Database":{"title":"Building a Vector Database","abstract":[{"type":"text","text":"Create intelligent search systems using embeddings to find semantically similar content."}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Building-Semantic-Search#Building-a-Vector-Database","url":"\/tutorials\/openaikit\/09-building-semantic-search#Building-a-Vector-Database"},"audio-04-request.swift":{"fileName":"AudioTranscriber.swift","type":"file","syntax":"swift","identifier":"audio-04-request.swift","content":["\/\/ AudioTranscriber.swift","import Foundation","import OpenAIKit","import AVFoundation","","class AudioTranscriber {","    let openAI = OpenAIManager.shared.client","    ","    func transcribe(audioFileURL: URL) async throws -> String {","        guard let openAI = openAI else {","            throw OpenAIError.missingAPIKey","        }","        ","        \/\/ Read audio file data","        let audioData = try Data(contentsOf: audioFileURL)","        ","        let request = TranscriptionRequest(","            file: FileUpload(","                data: audioData,","                filename: audioFileURL.lastPathComponent,","                contentType: \"audio\/mpeg\"","            ),","            model: Models.Audio.whisper1,","            language: nil,","            prompt: nil,","            responseFormat: .json,","            temperature: nil,","            timestampGranularities: nil","        )","        ","        \/\/ Send request next","        return \"\"","    }","}"],"fileType":"swift","highlights":[{"line":10},{"line":11},{"line":12},{"line":13},{"line":14},{"line":15},{"line":16},{"line":17},{"line":18},{"line":19},{"line":20},{"line":21},{"line":22},{"line":23},{"line":24},{"line":25},{"line":26},{"line":27},{"line":28},{"line":29},{"line":30},{"line":31}]},"doc://OpenAIKit/tutorials/OpenAIKit/09-Deep-Research-Analysis#Best-Practices-for-Research-Prompting":{"title":"Best Practices for Research Prompting","abstract":[{"type":"text","text":"Leverage DeepResearch to perform comprehensive research with web search, code interpretation, and custom data sources."}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Deep-Research-Analysis#Best-Practices-for-Research-Prompting","url":"\/tutorials\/openaikit\/09-deep-research-analysis#Best-Practices-for-Research-Prompting"},"doc://OpenAIKit/tutorials/OpenAIKit/09-Deep-Research-Analysis#Streaming-Research-Responses":{"type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Deep-Research-Analysis#Streaming-Research-Responses","role":"pseudoSymbol","title":"Streaming Research Responses","abstract":[{"type":"text","text":"Leverage DeepResearch to perform comprehensive research with web search, code interpretation, and custom data sources."}],"url":"\/tutorials\/openaikit\/09-deep-research-analysis#Streaming-Research-Responses","kind":"section"},"doc://OpenAIKit/tutorials/OpenAIKit/03-Working-With-Functions":{"identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/03-Working-With-Functions","type":"topic","role":"project","title":"Working with Functions","abstract":[{"type":"text","text":"Extend GPT’s capabilities by defining custom functions that the model can call to perform actions or retrieve information."}],"estimatedTime":"20min","url":"\/tutorials\/openaikit\/03-working-with-functions","kind":"project"},"app-01-recorder.swift":{"syntax":"swift","highlights":[],"fileName":"VoiceNotesApp.swift","fileType":"swift","type":"file","identifier":"app-01-recorder.swift","content":["import SwiftUI","import AVFoundation","import OpenAIKit","","\/\/ MARK: - Audio Recorder","","class AudioRecorder: NSObject, ObservableObject {","    @Published var isRecording = false","    @Published var recordingTime: TimeInterval = 0","    @Published var audioLevel: Float = 0","    @Published var recordings: [Recording] = []","    ","    private var audioRecorder: AVAudioRecorder?","    private var recordingSession = AVAudioSession.sharedInstance()","    private var timer: Timer?","    private var currentRecordingURL: URL?","    ","    override init() {","        super.init()","        setupRecordingSession()","        loadRecordings()","    }","    ","    private func setupRecordingSession() {","        do {","            try recordingSession.setCategory(.playAndRecord, mode: .default)","            try recordingSession.setActive(true)","            ","            recordingSession.requestRecordPermission { allowed in","                DispatchQueue.main.async {","                    if !allowed {","                        print(\"Recording permission denied\")","                    }","                }","            }","        } catch {","            print(\"Failed to set up recording session: \\(error)\")","        }","    }","    ","    func startRecording() {","        let recordingURL = getNewRecordingURL()","        currentRecordingURL = recordingURL","        ","        let settings = [","            AVFormatIDKey: Int(kAudioFormatMPEG4AAC),","            AVSampleRateKey: 44100,","            AVNumberOfChannelsKey: 1,","            AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue","        ]","        ","        do {","            audioRecorder = try AVAudioRecorder(url: recordingURL, settings: settings)","            audioRecorder?.delegate = self","            audioRecorder?.isMeteringEnabled = true","            audioRecorder?.record()","            ","            isRecording = true","            recordingTime = 0","            ","            \/\/ Start timer for recording time and level monitoring","            timer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in","                self.updateRecordingStatus()","            }","        } catch {","            print(\"Failed to start recording: \\(error)\")","        }","    }","    ","    func stopRecording() {","        audioRecorder?.stop()","        timer?.invalidate()","        timer = nil","        isRecording = false","        ","        if let url = currentRecordingURL {","            let recording = Recording(","                id: UUID(),","                url: url,","                date: Date(),","                duration: recordingTime,","                name: \"Recording \\(recordings.count + 1)\"","            )","            recordings.insert(recording, at: 0)","            saveRecordings()","        }","        ","        currentRecordingURL = nil","        audioLevel = 0","    }","    ","    func pauseRecording() {","        if isRecording {","            audioRecorder?.pause()","            timer?.invalidate()","        }","    }","    ","    func resumeRecording() {","        if audioRecorder?.isRecording == false {","            audioRecorder?.record()","            timer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in","                self.updateRecordingStatus()","            }","        }","    }","    ","    private func updateRecordingStatus() {","        guard let recorder = audioRecorder, recorder.isRecording else { return }","        ","        recordingTime = recorder.currentTime","        recorder.updateMeters()","        ","        let normalizedLevel = normalizeLevel(recorder.averagePower(forChannel: 0))","        audioLevel = normalizedLevel","    }","    ","    private func normalizeLevel(_ level: Float) -> Float {","        \/\/ Convert decibels to normalized value (0.0 to 1.0)","        let minDb: Float = -60","        let maxDb: Float = 0","        ","        if level < minDb {","            return 0.0","        } else if level >= maxDb {","            return 1.0","        } else {","            return (level - minDb) \/ (maxDb - minDb)","        }","    }","    ","    private func getNewRecordingURL() -> URL {","        let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]","        let fileName = \"recording_\\(Date().timeIntervalSince1970).m4a\"","        return documentsPath.appendingPathComponent(fileName)","    }","    ","    func deleteRecording(_ recording: Recording) {","        do {","            try FileManager.default.removeItem(at: recording.url)","            recordings.removeAll { $0.id == recording.id }","            saveRecordings()","        } catch {","            print(\"Failed to delete recording: \\(error)\")","        }","    }","    ","    func renameRecording(_ recording: Recording, to newName: String) {","        if let index = recordings.firstIndex(where: { $0.id == recording.id }) {","            recordings[index].name = newName","            saveRecordings()","        }","    }","    ","    \/\/ MARK: - Persistence","    ","    private func saveRecordings() {","        let encoder = JSONEncoder()","        if let encoded = try? encoder.encode(recordings) {","            UserDefaults.standard.set(encoded, forKey: \"recordings\")","        }","    }","    ","    private func loadRecordings() {","        if let data = UserDefaults.standard.data(forKey: \"recordings\"),","           let decoded = try? JSONDecoder().decode([Recording].self, from: data) {","            recordings = decoded.filter { recording in","                \/\/ Verify file still exists","                FileManager.default.fileExists(atPath: recording.url.path)","            }","        }","    }","}","","\/\/ MARK: - AVAudioRecorderDelegate","","extension AudioRecorder: AVAudioRecorderDelegate {","    func audioRecorderDidFinishRecording(_ recorder: AVAudioRecorder, successfully flag: Bool) {","        if !flag {","            print(\"Recording failed\")","        }","    }","}","","\/\/ MARK: - Recording Model","","struct Recording: Identifiable, Codable {","    let id: UUID","    let url: URL","    let date: Date","    let duration: TimeInterval","    var name: String","    var transcription: String?","    var isTranscribing: Bool = false","    ","    var formattedDuration: String {","        let minutes = Int(duration) \/ 60","        let seconds = Int(duration) % 60","        return String(format: \"%02d:%02d\", minutes, seconds)","    }","    ","    var formattedDate: String {","        let formatter = DateFormatter()","        formatter.dateStyle = .medium","        formatter.timeStyle = .short","        return formatter.string(from: date)","    }","}","","\/\/ MARK: - Audio Player","","class AudioPlayer: ObservableObject {","    @Published var isPlaying = false","    @Published var currentTime: TimeInterval = 0","    @Published var duration: TimeInterval = 0","    ","    private var audioPlayer: AVAudioPlayer?","    private var timer: Timer?","    ","    func play(_ recording: Recording) {","        do {","            audioPlayer = try AVAudioPlayer(contentsOf: recording.url)","            audioPlayer?.delegate = self","            audioPlayer?.play()","            ","            isPlaying = true","            duration = audioPlayer?.duration ?? 0","            ","            timer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in","                self.updatePlaybackStatus()","            }","        } catch {","            print(\"Failed to play recording: \\(error)\")","        }","    }","    ","    func pause() {","        audioPlayer?.pause()","        isPlaying = false","        timer?.invalidate()","    }","    ","    func resume() {","        audioPlayer?.play()","        isPlaying = true","        ","        timer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in","            self.updatePlaybackStatus()","        }","    }","    ","    func stop() {","        audioPlayer?.stop()","        isPlaying = false","        currentTime = 0","        timer?.invalidate()","    }","    ","    func seek(to time: TimeInterval) {","        audioPlayer?.currentTime = time","        currentTime = time","    }","    ","    private func updatePlaybackStatus() {","        currentTime = audioPlayer?.currentTime ?? 0","        ","        if currentTime >= duration {","            stop()","        }","    }","}","","extension AudioPlayer: AVAudioPlayerDelegate {","    func audioPlayerDidFinishPlaying(_ player: AVAudioPlayer, successfully flag: Bool) {","        stop()","    }","}"]},"doc://OpenAIKit/tutorials/OpenAIKit/03-Working-With-Functions#Handling-Function-Calls":{"title":"Handling Function Calls","abstract":[{"type":"text","text":"Extend GPT’s capabilities by defining custom functions that the model can call to perform actions or retrieve information."}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/03-Working-With-Functions#Handling-Function-Calls","url":"\/tutorials\/openaikit\/03-working-with-functions#Handling-Function-Calls"},"chunk-05-progress.swift":{"fileName":"AudioChunking.swift","type":"file","syntax":"swift","content":["import SwiftUI","import OpenAIKit","import Combine","","\/\/ MARK: - Chunk Progress Tracker","","class ChunkProgressTracker: ObservableObject {","    @Published var overallProgress: Double = 0","    @Published var currentChunk: Int = 0","    @Published var totalChunks: Int = 0","    @Published var currentChunkProgress: Double = 0","    @Published var status: ProcessingStatus = .idle","    @Published var processingSpeed: Double = 0  \/\/ Chunks per minute","    @Published var estimatedTimeRemaining: TimeInterval?","    @Published var errors: [ChunkError] = []","    ","    private var startTime: Date?","    private var processedChunks: Set<Int> = []","    private var chunkStartTimes: [Int: Date] = [:]","    ","    enum ProcessingStatus {","        case idle","        case preparing","        case processing(chunkIndex: Int)","        case merging","        case completed","        case failed(Error)","        ","        var description: String {","            switch self {","            case .idle:","                return \"Ready\"","            case .preparing:","                return \"Preparing audio...\"","            case .processing(let index):","                return \"Processing chunk \\(index + 1)...\"","            case .merging:","                return \"Merging results...\"","            case .completed:","                return \"Completed\"","            case .failed(let error):","                return \"Failed: \\(error.localizedDescription)\"","            }","        }","    }","    ","    func startProcessing(totalChunks: Int) {","        self.totalChunks = totalChunks","        self.currentChunk = 0","        self.overallProgress = 0","        self.status = .preparing","        self.startTime = Date()","        self.processedChunks.removeAll()","        self.chunkStartTimes.removeAll()","        self.errors.removeAll()","    }","    ","    func startChunk(_ index: Int) {","        currentChunk = index","        currentChunkProgress = 0","        status = .processing(chunkIndex: index)","        chunkStartTimes[index] = Date()","        updateEstimates()","    }","    ","    func updateChunkProgress(_ progress: Double, for index: Int) {","        guard index == currentChunk else { return }","        currentChunkProgress = progress","        updateOverallProgress()","    }","    ","    func completeChunk(_ index: Int) {","        processedChunks.insert(index)","        if index == currentChunk {","            currentChunkProgress = 1.0","        }","        updateOverallProgress()","        updateEstimates()","    }","    ","    func failChunk(_ index: Int, error: Error) {","        let chunkError = ChunkError(","            chunkIndex: index,","            error: error,","            timestamp: Date()","        )","        errors.append(chunkError)","        ","        \/\/ Continue with next chunk","        if index == currentChunk && index < totalChunks - 1 {","            startChunk(index + 1)","        }","    }","    ","    func startMerging() {","        status = .merging","        currentChunkProgress = 0","    }","    ","    func complete() {","        status = .completed","        overallProgress = 1.0","        estimatedTimeRemaining = nil","    }","    ","    func fail(with error: Error) {","        status = .failed(error)","    }","    ","    private func updateOverallProgress() {","        let completedProgress = Double(processedChunks.count) \/ Double(max(totalChunks, 1))","        let currentProgress = currentChunkProgress \/ Double(max(totalChunks, 1))","        overallProgress = completedProgress + currentProgress","    }","    ","    private func updateEstimates() {","        guard let startTime = startTime,","              !processedChunks.isEmpty else {","            return","        }","        ","        let elapsedTime = Date().timeIntervalSince(startTime)","        let chunksPerSecond = Double(processedChunks.count) \/ elapsedTime","        processingSpeed = chunksPerSecond * 60  \/\/ Convert to chunks per minute","        ","        let remainingChunks = totalChunks - processedChunks.count","        if remainingChunks > 0 && chunksPerSecond > 0 {","            estimatedTimeRemaining = Double(remainingChunks) \/ chunksPerSecond","        } else {","            estimatedTimeRemaining = nil","        }","    }","    ","    var formattedTimeRemaining: String {","        guard let time = estimatedTimeRemaining else {","            return \"Calculating...\"","        }","        ","        let minutes = Int(time) \/ 60","        let seconds = Int(time) % 60","        ","        if minutes > 0 {","            return \"\\(minutes)m \\(seconds)s remaining\"","        } else {","            return \"\\(seconds)s remaining\"","        }","    }","    ","    var successRate: Double {","        guard totalChunks > 0 else { return 0 }","        let failedCount = errors.count","        let successCount = processedChunks.count - failedCount","        return Double(successCount) \/ Double(processedChunks.count)","    }","}","","\/\/ MARK: - Progress View","","struct ChunkProgressView: View {","    @ObservedObject var tracker: ChunkProgressTracker","    @State private var showingErrors = false","    ","    var body: some View {","        VStack(spacing: 20) {","            \/\/ Status Header","            HStack {","                Image(systemName: statusIcon)","                    .foregroundColor(statusColor)","                    .font(.title2)","                ","                Text(tracker.status.description)","                    .font(.headline)","                ","                Spacer()","                ","                if !tracker.errors.isEmpty {","                    Button(action: { showingErrors = true }) {","                        Label(\"\\(tracker.errors.count)\", systemImage: \"exclamationmark.triangle\")","                            .foregroundColor(.orange)","                    }","                }","            }","            ","            \/\/ Overall Progress","            VStack(alignment: .leading, spacing: 8) {","                HStack {","                    Text(\"Overall Progress\")","                        .font(.subheadline)","                        .foregroundColor(.secondary)","                    ","                    Spacer()","                    ","                    Text(\"\\(Int(tracker.overallProgress * 100))%\")","                        .font(.subheadline)","                        .monospacedDigit()","                }","                ","                ProgressView(value: tracker.overallProgress)","                    .progressViewStyle(LinearProgressViewStyle(tint: .blue))","            }","            ","            \/\/ Chunk Progress","            if case .processing = tracker.status {","                VStack(alignment: .leading, spacing: 8) {","                    HStack {","                        Text(\"Chunk \\(tracker.currentChunk + 1) of \\(tracker.totalChunks)\")","                            .font(.subheadline)","                            .foregroundColor(.secondary)","                        ","                        Spacer()","                        ","                        Text(\"\\(Int(tracker.currentChunkProgress * 100))%\")","                            .font(.subheadline)","                            .monospacedDigit()","                    }","                    ","                    ProgressView(value: tracker.currentChunkProgress)","                        .progressViewStyle(LinearProgressViewStyle(tint: .green))","                }","            }","            ","            \/\/ Statistics","            HStack(spacing: 30) {","                \/\/ Processing Speed","                VStack(alignment: .leading) {","                    Text(\"Speed\")","                        .font(.caption)","                        .foregroundColor(.secondary)","                    Text(\"\\(tracker.processingSpeed, specifier: \"%.1f\") chunks\/min\")","                        .font(.caption)","                        .monospacedDigit()","                }","                ","                \/\/ Time Remaining","                VStack(alignment: .leading) {","                    Text(\"Time Remaining\")","                        .font(.caption)","                        .foregroundColor(.secondary)","                    Text(tracker.formattedTimeRemaining)","                        .font(.caption)","                        .monospacedDigit()","                }","                ","                \/\/ Success Rate","                if tracker.processedChunks.count > 0 {","                    VStack(alignment: .leading) {","                        Text(\"Success Rate\")","                            .font(.caption)","                            .foregroundColor(.secondary)","                        Text(\"\\(Int(tracker.successRate * 100))%\")","                            .font(.caption)","                            .monospacedDigit()","                    }","                }","                ","                Spacer()","            }","            ","            \/\/ Visual Progress Indicator","            ChunkVisualizer(","                totalChunks: tracker.totalChunks,","                processedChunks: tracker.processedChunks,","                currentChunk: tracker.currentChunk,","                errors: Set(tracker.errors.map { $0.chunkIndex })","            )","            .frame(height: 40)","        }","        .padding()","        .background(Color(UIColor.secondarySystemBackground))","        .cornerRadius(12)","        .sheet(isPresented: $showingErrors) {","            ErrorListView(errors: tracker.errors)","        }","    }","    ","    private var statusIcon: String {","        switch tracker.status {","        case .idle:","            return \"circle\"","        case .preparing:","            return \"gear\"","        case .processing:","            return \"waveform\"","        case .merging:","            return \"arrow.triangle.merge\"","        case .completed:","            return \"checkmark.circle.fill\"","        case .failed:","            return \"xmark.circle.fill\"","        }","    }","    ","    private var statusColor: Color {","        switch tracker.status {","        case .idle:","            return .gray","        case .preparing, .processing, .merging:","            return .blue","        case .completed:","            return .green","        case .failed:","            return .red","        }","    }","}","","\/\/ MARK: - Chunk Visualizer","","struct ChunkVisualizer: View {","    let totalChunks: Int","    let processedChunks: Set<Int>","    let currentChunk: Int","    let errors: Set<Int>","    ","    var body: some View {","        GeometryReader { geometry in","            HStack(spacing: 2) {","                ForEach(0..<totalChunks, id: \\.self) { index in","                    RoundedRectangle(cornerRadius: 2)","                        .fill(chunkColor(for: index))","                        .frame(width: max(2, (geometry.size.width - CGFloat(totalChunks - 1) * 2) \/ CGFloat(totalChunks)))","                        .overlay(","                            RoundedRectangle(cornerRadius: 2)","                                .stroke(index == currentChunk ? Color.white : Color.clear, lineWidth: 2)","                        )","                }","            }","        }","    }","    ","    private func chunkColor(for index: Int) -> Color {","        if errors.contains(index) {","            return .red","        } else if processedChunks.contains(index) {","            return .green","        } else if index == currentChunk {","            return .blue","        } else {","            return .gray.opacity(0.3)","        }","    }","}","","\/\/ MARK: - Error List View","","struct ErrorListView: View {","    let errors: [ChunkError]","    @Environment(\\.dismiss) private var dismiss","    ","    var body: some View {","        NavigationView {","            List(errors) { error in","                VStack(alignment: .leading, spacing: 4) {","                    HStack {","                        Text(\"Chunk \\(error.chunkIndex + 1)\")","                            .font(.headline)","                        Spacer()","                        Text(error.timestamp, style: .time)","                            .font(.caption)","                            .foregroundColor(.secondary)","                    }","                    ","                    Text(error.error.localizedDescription)","                        .font(.subheadline)","                        .foregroundColor(.secondary)","                        .lineLimit(2)","                }","                .padding(.vertical, 4)","            }","            .navigationTitle(\"Processing Errors\")","            .navigationBarTitleDisplayMode(.inline)","            .toolbar {","                ToolbarItem(placement: .navigationBarTrailing) {","                    Button(\"Done\") {","                        dismiss()","                    }","                }","            }","        }","    }","}","","\/\/ MARK: - Models","","struct ChunkError: Identifiable {","    let id = UUID()","    let chunkIndex: Int","    let error: Error","    let timestamp: Date","}","","\/\/ MARK: - Progress Manager","","class ChunkProgressManager {","    private let tracker = ChunkProgressTracker()","    private var cancellables = Set<AnyCancellable>()","    ","    func processAudioWithProgress(","        url: URL,","        options: ProcessingOptions,","        completion: @escaping (Result<MergedTranscriptionResult, Error>) -> Void","    ) {","        Task {","            do {","                \/\/ Prepare chunks","                tracker.startProcessing(totalChunks: 0)","                ","                let chunkManager = AudioChunkManager()","                let chunkingResult = try await chunkManager.prepareAudioFile(url)","                ","                tracker.startProcessing(totalChunks: chunkingResult.chunks.count)","                ","                \/\/ Process chunks","                let processor = ChunkProcessor(apiKey: AppSettings.shared.getAPIKey() ?? \"\")","                var results: [ChunkTranscriptionResult] = []","                ","                for (index, chunk) in chunkingResult.chunks.enumerated() {","                    tracker.startChunk(index)","                    ","                    do {","                        let result = try await processor.processChunkWithRetry(","                            chunk,","                            options: options","                        )","                        results.append(result)","                        tracker.completeChunk(index)","                    } catch {","                        tracker.failChunk(index, error: error)","                        \/\/ Continue with next chunk","                    }","                }","                ","                \/\/ Merge results","                tracker.startMerging()","                let merged = processor.mergeChunkResults(results)","                ","                tracker.complete()","                completion(.success(merged))","                ","            } catch {","                tracker.fail(with: error)","                completion(.failure(error))","            }","        }","    }","}"],"identifier":"chunk-05-progress.swift","fileType":"swift","highlights":[]},"doc://OpenAIKit/tutorials/OpenAIKit/09-Deep-Research-Analysis#Working-with-MCP-Servers":{"title":"Working with MCP Servers","abstract":[{"type":"text","text":"Leverage DeepResearch to perform comprehensive research with web search, code interpretation, and custom data sources."}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Deep-Research-Analysis#Working-with-MCP-Servers","url":"\/tutorials\/openaikit\/09-deep-research-analysis#Working-with-MCP-Servers"},"doc://OpenAIKit/tutorials/OpenAIKit/05-Building-Conversations#Check-Your-Understanding":{"url":"\/tutorials\/openaikit\/05-building-conversations#Check-Your-Understanding","titleInlineContent":[{"type":"text","text":"Check Your Understanding"}],"identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/05-Building-Conversations#Check-Your-Understanding","type":"link","title":"Check Your Understanding"},"doc://OpenAIKit/tutorials/OpenAIKit/06-Streaming-Responses#Check-Your-Understanding":{"titleInlineContent":[{"text":"Check Your Understanding","type":"text"}],"url":"\/tutorials\/openaikit\/06-streaming-responses#Check-Your-Understanding","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/06-Streaming-Responses#Check-Your-Understanding","type":"link","title":"Check Your Understanding"},"doc://OpenAIKit/tutorials/OpenAIKit/09-Deep-Research-Analysis#Check-Your-Understanding":{"title":"Check Your Understanding","titleInlineContent":[{"type":"text","text":"Check Your Understanding"}],"url":"\/tutorials\/openaikit\/09-deep-research-analysis#Check-Your-Understanding","type":"link","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Deep-Research-Analysis#Check-Your-Understanding"},"doc://OpenAIKit/tutorials/OpenAIKit/08-Transcribing-Audio#Advanced-Transcription-Options":{"title":"Advanced Transcription Options","abstract":[{"type":"text","text":"Use Whisper to transcribe audio files into text with high accuracy across multiple languages."}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/08-Transcribing-Audio#Advanced-Transcription-Options","url":"\/tutorials\/openaikit\/08-transcribing-audio#Advanced-Transcription-Options"},"doc://OpenAIKit/tutorials/OpenAIKit/03-Working-With-Functions#Building-the-Complete-Assistant":{"title":"Building the Complete Assistant","abstract":[{"type":"text","text":"Extend GPT’s capabilities by defining custom functions that the model can call to perform actions or retrieve information."}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/03-Working-With-Functions#Building-the-Complete-Assistant","url":"\/tutorials\/openaikit\/03-working-with-functions#Building-the-Complete-Assistant"},"doc://OpenAIKit/tutorials/OpenAIKit/08-Transcribing-Audio#Basic-Audio-Transcription":{"type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/08-Transcribing-Audio#Basic-Audio-Transcription","role":"pseudoSymbol","title":"Basic Audio Transcription","abstract":[{"type":"text","text":"Use Whisper to transcribe audio files into text with high accuracy across multiple languages."}],"url":"\/tutorials\/openaikit\/08-transcribing-audio#Basic-Audio-Transcription","kind":"section"},"doc://OpenAIKit/tutorials/OpenAIKit/04-Handling-Errors":{"title":"Handling Errors","abstract":[{"type":"text","text":"Learn how to gracefully handle errors and edge cases when working with the OpenAI API."}],"role":"project","kind":"project","type":"topic","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/04-Handling-Errors","url":"\/tutorials\/openaikit\/04-handling-errors","estimatedTime":"12min"},"doc://OpenAIKit/tutorials/OpenAIKit/02-Your-First-Chat-Completion":{"type":"topic","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/02-Your-First-Chat-Completion","role":"project","title":"Your First Chat Completion","abstract":[{"type":"text","text":"Make your first API call to generate text using OpenAI’s chat completion models."}],"estimatedTime":"15min","url":"\/tutorials\/openaikit\/02-your-first-chat-completion","kind":"project"},"app-06-export.swift":{"syntax":"swift","highlights":[],"fileName":"VoiceNotesApp.swift","fileType":"swift","type":"file","identifier":"app-06-export.swift","content":["import SwiftUI","import OpenAIKit","import UniformTypeIdentifiers","","\/\/ MARK: - Export Manager","","class ExportManager: ObservableObject {","    @Published var isExporting = false","    @Published var exportProgress: Double = 0","    @Published var exportError: Error?","    ","    enum ExportFormat {","        case txt","        case srt","        case vtt","        case json","        case csv","        case pdf","        ","        var fileExtension: String {","            switch self {","            case .txt: return \"txt\"","            case .srt: return \"srt\"","            case .vtt: return \"vtt\"","            case .json: return \"json\"","            case .csv: return \"csv\"","            case .pdf: return \"pdf\"","            }","        }","        ","        var contentType: UTType {","            switch self {","            case .txt: return .plainText","            case .srt: return .plainText","            case .vtt: return .plainText","            case .json: return .json","            case .csv: return .commaSeparatedText","            case .pdf: return .pdf","            }","        }","    }","    ","    func exportRecording(","        _ recording: Recording,","        format: ExportFormat,","        includeMetadata: Bool = true","    ) async throws -> URL {","        isExporting = true","        exportProgress = 0","        ","        defer {","            isExporting = false","        }","        ","        let content: String","        ","        switch format {","        case .txt:","            content = try createTextExport(recording, includeMetadata: includeMetadata)","        case .srt:","            content = try createSRTExport(recording)","        case .vtt:","            content = try createVTTExport(recording)","        case .json:","            content = try createJSONExport(recording)","        case .csv:","            content = try createCSVExport(recording)","        case .pdf:","            return try await createPDFExport(recording)","        }","        ","        \/\/ Save to temporary file","        let fileName = \"\\(recording.name).\\(format.fileExtension)\"","        let tempURL = FileManager.default.temporaryDirectory.appendingPathComponent(fileName)","        ","        try content.write(to: tempURL, atomically: true, encoding: .utf8)","        ","        exportProgress = 1.0","        return tempURL","    }","    ","    func exportMultipleRecordings(","        _ recordings: [Recording],","        format: ExportFormat","    ) async throws -> URL {","        isExporting = true","        exportProgress = 0","        ","        defer {","            isExporting = false","        }","        ","        var exportedFiles: [URL] = []","        ","        for (index, recording) in recordings.enumerated() {","            let fileURL = try await exportRecording(recording, format: format)","            exportedFiles.append(fileURL)","            ","            exportProgress = Double(index + 1) \/ Double(recordings.count)","        }","        ","        \/\/ Create zip archive","        let zipURL = try createZipArchive(from: exportedFiles, name: \"recordings_export\")","        ","        \/\/ Clean up temporary files","        for url in exportedFiles {","            try? FileManager.default.removeItem(at: url)","        }","        ","        return zipURL","    }","    ","    \/\/ MARK: - Export Formats","    ","    private func createTextExport(_ recording: Recording, includeMetadata: Bool) throws -> String {","        var content = \"\"","        ","        if includeMetadata {","            content += \"Recording: \\(recording.name)\\n\"","            content += \"Date: \\(recording.formattedDate)\\n\"","            content += \"Duration: \\(recording.formattedDuration)\\n\"","            content += \"\\n---\\n\\n\"","        }","        ","        content += recording.transcription ?? \"No transcription available\"","        ","        return content","    }","    ","    private func createSRTExport(_ recording: Recording) throws -> String {","        guard let segments = loadSegments(for: recording), !segments.isEmpty else {","            throw ExportError.noTimestamps","        }","        ","        var srt = \"\"","        ","        for (index, segment) in segments.enumerated() {","            srt += \"\\(index + 1)\\n\"","            srt += \"\\(formatSRTTime(segment.start ?? 0)) --> \\(formatSRTTime(segment.end ?? 0))\\n\"","            srt += \"\\(segment.text)\\n\\n\"","        }","        ","        return srt","    }","    ","    private func createVTTExport(_ recording: Recording) throws -> String {","        guard let segments = loadSegments(for: recording), !segments.isEmpty else {","            throw ExportError.noTimestamps","        }","        ","        var vtt = \"WEBVTT\\n\\n\"","        ","        for segment in segments {","            vtt += \"\\(formatVTTTime(segment.start ?? 0)) --> \\(formatVTTTime(segment.end ?? 0))\\n\"","            vtt += \"\\(segment.text)\\n\\n\"","        }","        ","        return vtt","    }","    ","    private func createJSONExport(_ recording: Recording) throws -> String {","        let exportData = RecordingExportData(","            name: recording.name,","            date: recording.date,","            duration: recording.duration,","            transcription: recording.transcription,","            segments: loadSegments(for: recording)","        )","        ","        let encoder = JSONEncoder()","        encoder.outputFormatting = .prettyPrinted","        encoder.dateEncodingStrategy = .iso8601","        ","        let data = try encoder.encode(exportData)","        return String(data: data, encoding: .utf8) ?? \"{}\"","    }","    ","    private func createCSVExport(_ recording: Recording) throws -> String {","        var csv = \"Time,Text\\n\"","        ","        if let segments = loadSegments(for: recording) {","            for segment in segments {","                let time = formatTime(segment.start ?? 0)","                let text = segment.text.replacingOccurrences(of: \"\\\"\", with: \"\\\"\\\"\")","                csv += \"\\\"\\(time)\\\",\\\"\\(text)\\\"\\n\"","            }","        } else {","            csv += \"\\\"00:00\\\",\\\"\\(recording.transcription ?? \"\")\\\"\\n\"","        }","        ","        return csv","    }","    ","    private func createPDFExport(_ recording: Recording) async throws -> URL {","        \/\/ Create PDF using Core Graphics","        let pdfURL = FileManager.default.temporaryDirectory","            .appendingPathComponent(\"\\(recording.name).pdf\")","        ","        let pageRect = CGRect(x: 0, y: 0, width: 612, height: 792) \/\/ Letter size","        let renderer = UIGraphicsPDFRenderer(bounds: pageRect)","        ","        let data = renderer.pdfData { context in","            context.beginPage()","            ","            let attributes: [NSAttributedString.Key: Any] = [","                .font: UIFont.systemFont(ofSize: 24, weight: .bold)","            ]","            ","            let titleRect = CGRect(x: 50, y: 50, width: 512, height: 40)","            recording.name.draw(in: titleRect, withAttributes: attributes)","            ","            \/\/ Add metadata","            let metadataAttributes: [NSAttributedString.Key: Any] = [","                .font: UIFont.systemFont(ofSize: 12),","                .foregroundColor: UIColor.gray","            ]","            ","            let metadata = \"Date: \\(recording.formattedDate) | Duration: \\(recording.formattedDuration)\"","            let metadataRect = CGRect(x: 50, y: 100, width: 512, height: 20)","            metadata.draw(in: metadataRect, withAttributes: metadataAttributes)","            ","            \/\/ Add transcription","            let textAttributes: [NSAttributedString.Key: Any] = [","                .font: UIFont.systemFont(ofSize: 12)","            ]","            ","            let text = recording.transcription ?? \"No transcription available\"","            let textRect = CGRect(x: 50, y: 140, width: 512, height: 600)","            text.draw(in: textRect, withAttributes: textAttributes)","        }","        ","        try data.write(to: pdfURL)","        return pdfURL","    }","    ","    \/\/ MARK: - Helper Functions","    ","    private func loadSegments(for recording: Recording) -> [TranscriptionSegment]? {","        \/\/ In a real app, you'd load segments from storage","        \/\/ For now, return nil to indicate no segments available","        return nil","    }","    ","    private func formatSRTTime(_ time: TimeInterval) -> String {","        let hours = Int(time) \/ 3600","        let minutes = (Int(time) % 3600) \/ 60","        let seconds = Int(time) % 60","        let milliseconds = Int((time.truncatingRemainder(dividingBy: 1)) * 1000)","        ","        return String(format: \"%02d:%02d:%02d,%03d\", hours, minutes, seconds, milliseconds)","    }","    ","    private func formatVTTTime(_ time: TimeInterval) -> String {","        let hours = Int(time) \/ 3600","        let minutes = (Int(time) % 3600) \/ 60","        let seconds = Int(time) % 60","        let milliseconds = Int((time.truncatingRemainder(dividingBy: 1)) * 1000)","        ","        return String(format: \"%02d:%02d:%02d.%03d\", hours, minutes, seconds, milliseconds)","    }","    ","    private func formatTime(_ time: TimeInterval) -> String {","        let minutes = Int(time) \/ 60","        let seconds = Int(time) % 60","        return String(format: \"%02d:%02d\", minutes, seconds)","    }","    ","    private func createZipArchive(from files: [URL], name: String) throws -> URL {","        \/\/ Simple implementation - in production use a proper zip library","        let zipURL = FileManager.default.temporaryDirectory","            .appendingPathComponent(\"\\(name).zip\")","        ","        \/\/ For now, just return the first file","        \/\/ In a real app, you'd create a proper zip archive","        if let firstFile = files.first {","            try FileManager.default.copyItem(at: firstFile, to: zipURL)","        }","        ","        return zipURL","    }","}","","\/\/ MARK: - Export View","","struct ExportView: View {","    let recording: Recording","    @StateObject private var exportManager = ExportManager()","    @State private var selectedFormat: ExportManager.ExportFormat = .txt","    @State private var includeMetadata = true","    @State private var showingShareSheet = false","    @State private var exportedURL: URL?","    @Environment(\\.dismiss) private var dismiss","    ","    var body: some View {","        NavigationView {","            Form {","                Section(\"Export Format\") {","                    ForEach(exportFormats, id: \\.0) { format, description in","                        HStack {","                            VStack(alignment: .leading) {","                                Text(description)","                                    .font(.headline)","                                Text(format.fileExtension.uppercased())","                                    .font(.caption)","                                    .foregroundColor(.secondary)","                            }","                            ","                            Spacer()","                            ","                            if selectedFormat == format {","                                Image(systemName: \"checkmark.circle.fill\")","                                    .foregroundColor(.blue)","                            }","                        }","                        .contentShape(Rectangle())","                        .onTapGesture {","                            selectedFormat = format","                        }","                    }","                }","                ","                Section(\"Options\") {","                    Toggle(\"Include Metadata\", isOn: $includeMetadata)","                        .disabled(selectedFormat == .srt || selectedFormat == .vtt)","                }","                ","                Section {","                    Button(action: performExport) {","                        if exportManager.isExporting {","                            HStack {","                                ProgressView()","                                    .progressViewStyle(CircularProgressViewStyle())","                                Text(\"Exporting...\")","                            }","                        } else {","                            Label(\"Export Recording\", systemImage: \"square.and.arrow.up\")","                        }","                    }","                    .disabled(exportManager.isExporting)","                }","            }","            .navigationTitle(\"Export\")","            .navigationBarTitleDisplayMode(.inline)","            .toolbar {","                ToolbarItem(placement: .navigationBarLeading) {","                    Button(\"Cancel\") {","                        dismiss()","                    }","                }","            }","            .alert(\"Export Error\", isPresented: .constant(exportManager.exportError != nil)) {","                Button(\"OK\") {","                    exportManager.exportError = nil","                }","            } message: {","                Text(exportManager.exportError?.localizedDescription ?? \"Unknown error\")","            }","            .sheet(isPresented: $showingShareSheet) {","                if let url = exportedURL {","                    ShareSheet(items: [url])","                }","            }","        }","    }","    ","    private var exportFormats: [(ExportManager.ExportFormat, String)] {","        [","            (.txt, \"Plain Text\"),","            (.srt, \"SubRip Subtitle\"),","            (.vtt, \"WebVTT Subtitle\"),","            (.json, \"JSON Data\"),","            (.csv, \"Spreadsheet\"),","            (.pdf, \"PDF Document\")","        ]","    }","    ","    private func performExport() {","        Task {","            do {","                let url = try await exportManager.exportRecording(","                    recording,","                    format: selectedFormat,","                    includeMetadata: includeMetadata","                )","                ","                await MainActor.run {","                    exportedURL = url","                    showingShareSheet = true","                }","            } catch {","                await MainActor.run {","                    exportManager.exportError = error","                }","            }","        }","    }","}","","\/\/ MARK: - Share Sheet","","struct ShareSheet: UIViewControllerRepresentable {","    let items: [Any]","    ","    func makeUIViewController(context: Context) -> UIActivityViewController {","        UIActivityViewController(activityItems: items, applicationActivities: nil)","    }","    ","    func updateUIViewController(_ uiViewController: UIActivityViewController, context: Context) {}","}","","\/\/ MARK: - Models","","struct RecordingExportData: Codable {","    let name: String","    let date: Date","    let duration: TimeInterval","    let transcription: String?","    let segments: [TranscriptionSegment]?","}","","enum ExportError: LocalizedError {","    case noTimestamps","    case exportFailed","    ","    var errorDescription: String? {","        switch self {","        case .noTimestamps:","            return \"This format requires timestamp information, which is not available for this recording.\"","        case .exportFailed:","            return \"Failed to export the recording. Please try again.\"","        }","    }","}"]},"app-02-interface.swift":{"fileName":"VoiceNotesApp.swift","type":"file","syntax":"swift","content":["import OpenAIKit","import Foundation","","\/\/ Search interface implementation","class SemanticSearchInterface {","    let openAI: OpenAI","    let vectorStore: VectorStore","    let queryProcessor: QueryProcessor","    ","    init(apiKey: String) {","        self.openAI = OpenAI(apiKey: apiKey)","        self.vectorStore = VectorStore()","        self.queryProcessor = QueryProcessor(openAI: openAI)","    }","    ","    \/\/ Main search function","    func search(query: String, filters: SearchFilters? = nil) async throws -> SearchResponse {","        \/\/ Process and enhance query","        let processedQuery = try await queryProcessor.process(query)","        ","        \/\/ Generate embedding for search query","        let queryEmbedding = try await generateEmbedding(for: processedQuery.enhancedQuery)","        ","        \/\/ Search vector store","        var results = try await vectorStore.search(","            embedding: queryEmbedding,","            limit: filters?.limit ?? 10","        )","        ","        \/\/ Apply filters","        if let filters = filters {","            results = applyFilters(results, filters: filters)","        }","        ","        \/\/ Re-rank results using LLM","        let rerankedResults = try await rerankResults(","            query: processedQuery.enhancedQuery,","            results: results","        )","        ","        \/\/ Generate search response","        return SearchResponse(","            query: query,","            processedQuery: processedQuery,","            results: rerankedResults,","            totalResults: rerankedResults.count,","            searchTime: Date()","        )","    }","    ","    \/\/ Generate embedding for text","    private func generateEmbedding(for text: String) async throws -> [Double] {","        let request = CreateEmbeddingRequest(","            model: .textEmbeddingAda002,","            input: .text(text)","        )","        ","        let response = try await openAI.embeddings.create(request)","        return response.data.first?.embedding ?? []","    }","    ","    \/\/ Apply search filters","    private func applyFilters(_ results: [SearchResult], filters: SearchFilters) -> [SearchResult] {","        return results.filter { result in","            let metadata = result.document.metadata","            ","            \/\/ Category filter","            if let category = filters.category,","               metadata.category != category {","                return false","            }","            ","            \/\/ Author filter","            if let author = filters.author,","               !metadata.author.lowercased().contains(author.lowercased()) {","                return false","            }","            ","            \/\/ Tags filter","            if let tags = filters.tags,","               Set(metadata.tags).intersection(tags).isEmpty {","                return false","            }","            ","            \/\/ Score threshold","            if let minScore = filters.minScore,","               result.score < minScore {","                return false","            }","            ","            return true","        }","    }","    ","    \/\/ Re-rank results using LLM","    private func rerankResults(query: String, results: [SearchResult]) async throws -> [RankedSearchResult] {","        guard !results.isEmpty else { return [] }","        ","        \/\/ Create re-ranking prompt","        let prompt = \"\"\"","        Query: \"\\(query)\"","        ","        Please rank the following search results from most to least relevant.","        Consider both semantic similarity and practical usefulness.","        ","        Results:","        \\(results.enumerated().map { index, result in","            \"\\(index + 1). \\(result.document.metadata.title)\\n   \\(result.document.content.prefix(200))...\"","        }.joined(separator: \"\\n\\n\"))","        ","        Return a JSON array of indices in order of relevance.","        \"\"\"","        ","        let request = CreateChatCompletionRequest(","            model: .gpt4,","            messages: [","                .system(\"You are a search result ranking expert.\"),","                .user(prompt)","            ],","            responseFormat: .jsonObject","        )","        ","        let response = try await openAI.chat.completions.create(request)","        ","        \/\/ Parse ranking and create ranked results","        var rankedResults: [RankedSearchResult] = []","        ","        \/\/ For simplicity, use original order with enhanced scoring","        for (index, result) in results.enumerated() {","            rankedResults.append(RankedSearchResult(","                searchResult: result,","                rank: index + 1,","                relevanceScore: result.score * (1.0 - Double(index) * 0.05),","                explanation: generateExplanation(query: query, result: result)","            ))","        }","        ","        return rankedResults","    }","    ","    \/\/ Generate relevance explanation","    private func generateExplanation(query: String, result: SearchResult) -> String {","        \/\/ Simple explanation based on score","        if result.score > 0.9 {","            return \"Highly relevant - strong semantic match\"","        } else if result.score > 0.7 {","            return \"Good match - relevant content\"","        } else {","            return \"Partial match - some relevant information\"","        }","    }","}","","\/\/ Query processor for enhancing search queries","class QueryProcessor {","    let openAI: OpenAI","    ","    init(openAI: OpenAI) {","        self.openAI = openAI","    }","    ","    func process(_ query: String) async throws -> ProcessedQuery {","        \/\/ Expand query with synonyms and related terms","        let expandedQuery = try await expandQuery(query)","        ","        \/\/ Extract intent and entities","        let intent = try await extractIntent(query)","        ","        return ProcessedQuery(","            originalQuery: query,","            enhancedQuery: expandedQuery,","            intent: intent,","            keywords: extractKeywords(query)","        )","    }","    ","    private func expandQuery(_ query: String) async throws -> String {","        let request = CreateChatCompletionRequest(","            model: .gpt4,","            messages: [","                .system(\"Expand the search query with relevant synonyms and related terms.\"),","                .user(\"Query: \\(query)\\nExpanded query:\")","            ],","            temperature: 0.3,","            maxTokens: 100","        )","        ","        let response = try await openAI.chat.completions.create(request)","        return response.choices.first?.message.content ?? query","    }","    ","    private func extractIntent(_ query: String) async throws -> SearchIntent {","        \/\/ Simple intent classification","        if query.lowercased().contains(\"how\") || query.lowercased().contains(\"what\") {","            return .informational","        } else if query.lowercased().contains(\"find\") || query.lowercased().contains(\"locate\") {","            return .navigational","        } else {","            return .exploratory","        }","    }","    ","    private func extractKeywords(_ query: String) -> [String] {","        \/\/ Simple keyword extraction","        let stopWords = Set([\"the\", \"is\", \"at\", \"which\", \"on\", \"a\", \"an\", \"and\", \"or\", \"but\"])","        return query.lowercased()","            .components(separatedBy: .whitespacesAndNewlines)","            .filter { !stopWords.contains($0) && $0.count > 2 }","    }","}","","\/\/ Search models","struct SearchFilters {","    let category: String?","    let author: String?","    let tags: Set<String>?","    let minScore: Double?","    let limit: Int","}","","struct ProcessedQuery {","    let originalQuery: String","    let enhancedQuery: String","    let intent: SearchIntent","    let keywords: [String]","}","","enum SearchIntent {","    case informational","    case navigational","    case exploratory","}","","struct SearchResponse {","    let query: String","    let processedQuery: ProcessedQuery","    let results: [RankedSearchResult]","    let totalResults: Int","    let searchTime: Date","}","","struct RankedSearchResult {","    let searchResult: SearchResult","    let rank: Int","    let relevanceScore: Double","    let explanation: String","}","","\/\/ Usage example","func demonstrateSearch() async throws {","    let searchInterface = SemanticSearchInterface(apiKey: \"your-api-key\")","    ","    \/\/ Simple search","    let response = try await searchInterface.search(","        query: \"machine learning algorithms\"","    )","    ","    print(\"Search Results for: \\(response.query)\")","    print(\"Enhanced Query: \\(response.processedQuery.enhancedQuery)\")","    print(\"\\nResults:\")","    ","    for result in response.results {","        print(\"\\n\\(result.rank). \\(result.searchResult.document.metadata.title)\")","        print(\"   Score: \\(result.relevanceScore)\")","        print(\"   \\(result.explanation)\")","    }","    ","    \/\/ Search with filters","    let filteredResponse = try await searchInterface.search(","        query: \"neural networks\",","        filters: SearchFilters(","            category: \"Technology\",","            author: nil,","            tags: Set([\"AI\", \"Deep Learning\"]),","            minScore: 0.7,","            limit: 5","        )","    )","    ","    print(\"\\n\\nFiltered Search Results: \\(filteredResponse.totalResults) results\")","}"],"identifier":"app-02-interface.swift","fileType":"swift","highlights":[{"line":2},{"line":4},{"line":5},{"line":6},{"line":7},{"line":8},{"line":10},{"line":11},{"line":12},{"line":13},{"line":16},{"line":17},{"line":18},{"line":19},{"line":20},{"line":21},{"line":22},{"line":23},{"line":24},{"line":25},{"line":26},{"line":27},{"line":28},{"line":29},{"line":30},{"line":31},{"line":32},{"line":34},{"line":35},{"line":36},{"line":37},{"line":38},{"line":39},{"line":40},{"line":41},{"line":42},{"line":43},{"line":44},{"line":45},{"line":46},{"line":47},{"line":48},{"line":51},{"line":52},{"line":53},{"line":54},{"line":55},{"line":56},{"line":58},{"line":59},{"line":60},{"line":61},{"line":62},{"line":63},{"line":64},{"line":65},{"line":67},{"line":68},{"line":69},{"line":70},{"line":71},{"line":73},{"line":74},{"line":75},{"line":76},{"line":78},{"line":79},{"line":80},{"line":81},{"line":82},{"line":83},{"line":84},{"line":85},{"line":86},{"line":87},{"line":88},{"line":89},{"line":90},{"line":91},{"line":95},{"line":96},{"line":97},{"line":99},{"line":100},{"line":101},{"line":102},{"line":103},{"line":104},{"line":105},{"line":106},{"line":107},{"line":108},{"line":109},{"line":110},{"line":111},{"line":112},{"line":113},{"line":114},{"line":115},{"line":116},{"line":117},{"line":118},{"line":119},{"line":120},{"line":121},{"line":122},{"line":123},{"line":124},{"line":125},{"line":126},{"line":127},{"line":128},{"line":129},{"line":130},{"line":131},{"line":132},{"line":133},{"line":134},{"line":135},{"line":138},{"line":141},{"line":142},{"line":143},{"line":144},{"line":145},{"line":146},{"line":147},{"line":148},{"line":149},{"line":152},{"line":153},{"line":154},{"line":155},{"line":156},{"line":158},{"line":159},{"line":162},{"line":163},{"line":164},{"line":166},{"line":167},{"line":169},{"line":170},{"line":171},{"line":172},{"line":173},{"line":174},{"line":177},{"line":178},{"line":179},{"line":180},{"line":181},{"line":182},{"line":183},{"line":184},{"line":185},{"line":186},{"line":188},{"line":189},{"line":192},{"line":193},{"line":194},{"line":195},{"line":196},{"line":197},{"line":198},{"line":199},{"line":203},{"line":204},{"line":205},{"line":206},{"line":207},{"line":208},{"line":212},{"line":213},{"line":214},{"line":215},{"line":216},{"line":217},{"line":218},{"line":219},{"line":221},{"line":222},{"line":223},{"line":224},{"line":225},{"line":228},{"line":229},{"line":230},{"line":231},{"line":232},{"line":234},{"line":235},{"line":236},{"line":237},{"line":238},{"line":239},{"line":242},{"line":243},{"line":244},{"line":245},{"line":246},{"line":247},{"line":249},{"line":250},{"line":251},{"line":253},{"line":254},{"line":255},{"line":256},{"line":258},{"line":259},{"line":260},{"line":262},{"line":263},{"line":264},{"line":265},{"line":268},{"line":269},{"line":270},{"line":271},{"line":272},{"line":273},{"line":274},{"line":275},{"line":276},{"line":277},{"line":278},{"line":280}]},"doc://OpenAIKit/tutorials/OpenAIKit-Tutorials/Getting-Started":{"type":"topic","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit-Tutorials\/Getting-Started","role":"article","title":"Getting Started","abstract":[],"url":"\/tutorials\/openaikit-tutorials\/getting-started","kind":"article"},"doc://OpenAIKit/tutorials/OpenAIKit-Tutorials/Chat-Completions":{"title":"Chat Completions","abstract":[],"role":"article","kind":"article","type":"topic","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit-Tutorials\/Chat-Completions","url":"\/tutorials\/openaikit-tutorials\/chat-completions"},"doc://OpenAIKit/tutorials/OpenAIKit/04-Handling-Errors#Check-Your-Understanding":{"type":"link","title":"Check Your Understanding","titleInlineContent":[{"type":"text","text":"Check Your Understanding"}],"identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/04-Handling-Errors#Check-Your-Understanding","url":"\/tutorials\/openaikit\/04-handling-errors#Check-Your-Understanding"},"doc://OpenAIKit/tutorials/OpenAIKit/09-Building-Semantic-Search#Understanding-Embeddings":{"title":"Understanding Embeddings","abstract":[{"text":"Create intelligent search systems using embeddings to find semantically similar content.","type":"text"}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Building-Semantic-Search#Understanding-Embeddings","url":"\/tutorials\/openaikit\/09-building-semantic-search#Understanding-Embeddings"},"audio-02-imports.swift":{"syntax":"swift","highlights":[{"line":2},{"line":3},{"line":4}],"fileName":"AudioTranscriber.swift","fileType":"swift","type":"file","identifier":"audio-02-imports.swift","content":["\/\/ AudioTranscriber.swift","import Foundation","import OpenAIKit","import AVFoundation"]},"doc://OpenAIKit/tutorials/OpenAIKit/09-Building-Semantic-Search#Advanced-Techniques":{"title":"Advanced Techniques","abstract":[{"type":"text","text":"Create intelligent search systems using embeddings to find semantically similar content."}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Building-Semantic-Search#Advanced-Techniques","url":"\/tutorials\/openaikit\/09-building-semantic-search#Advanced-Techniques"},"doc://OpenAIKit/tutorials/OpenAIKit/03-Working-With-Functions#Check-Your-Understanding":{"title":"Check Your Understanding","titleInlineContent":[{"text":"Check Your Understanding","type":"text"}],"url":"\/tutorials\/openaikit\/03-working-with-functions#Check-Your-Understanding","type":"link","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/03-Working-With-Functions#Check-Your-Understanding"},"doc://OpenAIKit/tutorials/OpenAIKit/03-Working-With-Functions#Implementing-the-Weather-Function":{"type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/03-Working-With-Functions#Implementing-the-Weather-Function","role":"pseudoSymbol","title":"Implementing the Weather Function","abstract":[{"type":"text","text":"Extend GPT’s capabilities by defining custom functions that the model can call to perform actions or retrieve information."}],"url":"\/tutorials\/openaikit\/03-working-with-functions#Implementing-the-Weather-Function","kind":"section"},"doc://OpenAIKit/tutorials/OpenAIKit/08-Transcribing-Audio#Handling-Large-Audio-Files":{"title":"Handling Large Audio Files","abstract":[{"type":"text","text":"Use Whisper to transcribe audio files into text with high accuracy across multiple languages."}],"role":"pseudoSymbol","kind":"section","type":"section","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/08-Transcribing-Audio#Handling-Large-Audio-Files","url":"\/tutorials\/openaikit\/08-transcribing-audio#Handling-Large-Audio-Files"},"doc://OpenAIKit/tutorials/OpenAIKit/09-Building-Semantic-Search":{"identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit\/09-Building-Semantic-Search","type":"topic","role":"project","title":"Building Semantic Search","abstract":[{"type":"text","text":"Create intelligent search systems using embeddings to find semantically similar content."}],"estimatedTime":"20min","url":"\/tutorials\/openaikit\/09-building-semantic-search","kind":"project"},"translate-04-detection.swift":{"fileName":"AudioTranslator.swift","type":"file","syntax":"swift","content":["import OpenAIKit","import Foundation","import AVFoundation","","\/\/ MARK: - Language Detection","","class AudioLanguageDetector {","    private let openAI: OpenAIKit","    private let sampleDuration: TimeInterval = 10.0  \/\/ Use first 10 seconds for detection","    ","    init(apiKey: String) {","        self.openAI = OpenAIKit(apiKey: apiKey)","    }","    ","    \/\/ Detect language from audio file","    func detectLanguage(","        from audioURL: URL,","        useSample: Bool = true","    ) async throws -> LanguageDetectionResult {","        let startTime = Date()","        ","        \/\/ Extract sample if requested (for large files)","        let audioData: Data","        if useSample {","            audioData = try extractAudioSample(from: audioURL, duration: sampleDuration)","        } else {","            audioData = try Data(contentsOf: audioURL)","        }","        ","        \/\/ Use transcription to detect language","        let request = AudioTranscriptionRequest(","            file: audioData,","            model: \"whisper-1\",","            responseFormat: .verboseJson,","            temperature: 0  \/\/ Low temperature for accuracy","        )","        ","        let response = try await openAI.createAudioTranscription(request: request)","        ","        let detectionTime = Date().timeIntervalSince(startTime)","        ","        \/\/ Parse detected language","        let detectedLanguage = parseLanguage(from: response.language ?? \"unknown\")","        ","        \/\/ Calculate confidence based on response","        let confidence = calculateConfidence(","            response: response,","            expectedLanguage: detectedLanguage","        )","        ","        return LanguageDetectionResult(","            detectedLanguage: detectedLanguage,","            confidence: confidence,","            alternativeLanguages: findAlternativeLanguages(","                text: response.text,","                primaryLanguage: detectedLanguage","            ),","            sampleText: String(response.text.prefix(200)),","            detectionTime: detectionTime,","            audioFeatures: extractAudioFeatures(from: audioURL)","        )","    }","    ","    \/\/ Batch language detection for multiple files","    func detectLanguages(","        from audioURLs: [URL]","    ) async throws -> [BatchDetectionResult] {","        var results: [BatchDetectionResult] = []","        ","        await withTaskGroup(of: BatchDetectionResult.self) { group in","            for audioURL in audioURLs {","                group.addTask {","                    do {","                        let detection = try await self.detectLanguage(","                            from: audioURL,","                            useSample: true","                        )","                        ","                        return BatchDetectionResult(","                            fileURL: audioURL,","                            detection: detection,","                            error: nil","                        )","                    } catch {","                        return BatchDetectionResult(","                            fileURL: audioURL,","                            detection: nil,","                            error: error","                        )","                    }","                }","            }","            ","            for await result in group {","                results.append(result)","            }","        }","        ","        return results","    }","    ","    \/\/ Extract audio sample for faster detection","    private func extractAudioSample(","        from url: URL,","        duration: TimeInterval","    ) throws -> Data {","        let asset = AVAsset(url: url)","        ","        \/\/ Get audio duration","        let assetDuration = CMTimeGetSeconds(asset.duration)","        let sampleDuration = min(duration, assetDuration)","        ","        \/\/ For now, just read the whole file","        \/\/ In production, you'd use AVAssetReader to extract a sample","        let data = try Data(contentsOf: url)","        ","        \/\/ Rough approximation: take first portion of data","        let sampleSize = Int(Double(data.count) * (sampleDuration \/ assetDuration))","        return data.prefix(sampleSize)","    }","    ","    private func parseLanguage(from detectedString: String) -> WhisperLanguage? {","        \/\/ Try to match the detected string to our enum","        let normalized = detectedString.lowercased().trimmingCharacters(in: .whitespaces)","        ","        \/\/ First try direct code match","        if let language = WhisperLanguage(rawValue: normalized) {","            return language","        }","        ","        \/\/ Then try matching by display name","        return WhisperLanguage.allCases.first { language in","            language.displayName.lowercased() == normalized","        }","    }","    ","    private func calculateConfidence(","        response: AudioTranscriptionResponse,","        expectedLanguage: WhisperLanguage?","    ) -> Double {","        var confidence = 0.8  \/\/ Base confidence","        ","        \/\/ Boost if segments have high log probabilities","        if let segments = response.segments {","            let avgLogprobs = segments.compactMap { $0.avgLogprob }","            if !avgLogprobs.isEmpty {","                let avgLogprob = avgLogprobs.reduce(0, +) \/ Double(avgLogprobs.count)","                confidence = min(max(exp(avgLogprob), 0.5), 1.0)","            }","        }","        ","        \/\/ Reduce confidence if no valid language detected","        if expectedLanguage == nil {","            confidence *= 0.7","        }","        ","        return confidence","    }","    ","    private func findAlternativeLanguages(","        text: String,","        primaryLanguage: WhisperLanguage?","    ) -> [(language: WhisperLanguage, probability: Double)] {","        \/\/ Simple heuristic: check for common words\/patterns","        var alternatives: [(WhisperLanguage, Double)] = []","        ","        for language in WhisperLanguage.allCases {","            if language == primaryLanguage { continue }","            ","            if let hints = LanguageDetectionHelper.languageHints[language] {","                let matches = hints.filter { hint in","                    text.localizedCaseInsensitiveContains(hint)","                }.count","                ","                if matches > 0 {","                    let probability = Double(matches) \/ Double(hints.count) * 0.5","                    alternatives.append((language, probability))","                }","            }","        }","        ","        return alternatives","            .sorted { $0.1 > $1.1 }","            .prefix(3)","            .map { ($0.0, $0.1) }","    }","    ","    private func extractAudioFeatures(from url: URL) -> AudioFeatures {","        \/\/ Extract basic audio features","        let asset = AVAsset(url: url)","        ","        var duration: TimeInterval = 0","        var bitRate: Int = 0","        var sampleRate: Double = 0","        var channels: Int = 0","        ","        if let track = asset.tracks(withMediaType: .audio).first {","            duration = CMTimeGetSeconds(asset.duration)","            bitRate = Int(track.estimatedDataRate)","            ","            if let formatDescriptions = track.formatDescriptions as? [CMFormatDescription],","               let formatDescription = formatDescriptions.first {","                if let streamBasicDescription = CMAudioFormatDescriptionGetStreamBasicDescription(formatDescription) {","                    sampleRate = streamBasicDescription.pointee.mSampleRate","                    channels = Int(streamBasicDescription.pointee.mChannelsPerFrame)","                }","            }","        }","        ","        return AudioFeatures(","            duration: duration,","            bitRate: bitRate,","            sampleRate: sampleRate,","            channels: channels","        )","    }","}","","\/\/ MARK: - Models","","struct LanguageDetectionResult {","    let detectedLanguage: WhisperLanguage?","    let confidence: Double","    let alternativeLanguages: [(language: WhisperLanguage, probability: Double)]","    let sampleText: String","    let detectionTime: TimeInterval","    let audioFeatures: AudioFeatures","    ","    var isReliable: Bool {","        confidence > 0.8","    }","}","","struct BatchDetectionResult {","    let fileURL: URL","    let detection: LanguageDetectionResult?","    let error: Error?","    ","    var isSuccess: Bool {","        detection != nil && error == nil","    }","}","","struct AudioFeatures {","    let duration: TimeInterval","    let bitRate: Int","    let sampleRate: Double","    let channels: Int","    ","    var quality: AudioQuality {","        if sampleRate >= 44100 && bitRate >= 128000 {","            return .high","        } else if sampleRate >= 22050 && bitRate >= 64000 {","            return .medium","        } else {","            return .low","        }","    }","    ","    enum AudioQuality {","        case high","        case medium","        case low","    }","}","","\/\/ MARK: - Language Detection Cache","","class LanguageDetectionCache {","    private var cache: [URL: CachedDetection] = [:]","    private let maxCacheSize = 100","    private let cacheExpiration: TimeInterval = 3600  \/\/ 1 hour","    ","    struct CachedDetection {","        let result: LanguageDetectionResult","        let timestamp: Date","        ","        var isExpired: Bool {","            Date().timeIntervalSince(timestamp) > 3600","        }","    }","    ","    func get(for url: URL) -> LanguageDetectionResult? {","        guard let cached = cache[url],","              !cached.isExpired else {","            return nil","        }","        return cached.result","    }","    ","    func set(_ result: LanguageDetectionResult, for url: URL) {","        cache[url] = CachedDetection(result: result, timestamp: Date())","        ","        \/\/ Maintain cache size","        if cache.count > maxCacheSize {","            removeOldestEntries()","        }","    }","    ","    private func removeOldestEntries() {","        let sorted = cache.sorted { $0.value.timestamp < $1.value.timestamp }","        let toRemove = sorted.prefix(cache.count - maxCacheSize)","        ","        for (url, _) in toRemove {","            cache.removeValue(forKey: url)","        }","    }","    ","    func clear() {","        cache.removeAll()","    }","}","","\/\/ MARK: - Multi-Language Detection","","class MultiLanguageDetector {","    private let detector: AudioLanguageDetector","    private let cache = LanguageDetectionCache()","    ","    init(apiKey: String) {","        self.detector = AudioLanguageDetector(apiKey: apiKey)","    }","    ","    \/\/ Detect if audio contains multiple languages","    func detectMultipleLanguages(","        from audioURL: URL,","        segmentDuration: TimeInterval = 30.0","    ) async throws -> MultiLanguageDetectionResult {","        \/\/ This is a simplified version","        \/\/ In production, you'd segment the audio and detect each segment","        ","        let primaryDetection = try await detector.detectLanguage(from: audioURL)","        ","        \/\/ For now, return a simple result","        return MultiLanguageDetectionResult(","            primaryLanguage: primaryDetection.detectedLanguage,","            segments: [","                LanguageSegment(","                    startTime: 0,","                    endTime: primaryDetection.audioFeatures.duration,","                    language: primaryDetection.detectedLanguage,","                    confidence: primaryDetection.confidence","                )","            ],","            hasMultipleLanguages: false","        )","    }","}","","struct MultiLanguageDetectionResult {","    let primaryLanguage: WhisperLanguage?","    let segments: [LanguageSegment]","    let hasMultipleLanguages: Bool","}","","struct LanguageSegment {","    let startTime: TimeInterval","    let endTime: TimeInterval","    let language: WhisperLanguage?","    let confidence: Double","}"],"identifier":"translate-04-detection.swift","fileType":"swift","highlights":[]},"doc://OpenAIKit/tutorials/OpenAIKit-Tutorials":{"title":"Welcome to OpenAIKit","abstract":[{"type":"text","text":"Learn how to integrate OpenAI’s powerful AI models into your Swift applications with OpenAIKit."}],"role":"overview","kind":"overview","type":"topic","identifier":"doc:\/\/OpenAIKit\/tutorials\/OpenAIKit-Tutorials","url":"\/tutorials\/openaikit-tutorials"}}}