{"primaryContentSections":[{"declarations":[{"languages":["swift"],"tokens":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"kind":"identifier","text":"model"},{"kind":"text","text":": "},{"kind":"typeIdentifier","preciseIdentifier":"s:SS","text":"String"}],"platforms":["Linux"]}],"kind":"declarations"},{"content":[{"text":"Discussion","type":"heading","level":2,"anchor":"discussion"},{"inlineContent":[{"text":"Currently only “whisper-1” is available.","type":"text"}],"type":"paragraph"}],"kind":"content"}],"identifier":{"url":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/model","interfaceLanguage":"swift"},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/openaikit\/transcriptionrequest\/model"]}],"sections":[],"metadata":{"fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"text":"model","kind":"identifier"},{"text":": ","kind":"text"},{"text":"String","preciseIdentifier":"s:SS","kind":"typeIdentifier"}],"roleHeading":"Instance Property","title":"model","externalID":"s:9OpenAIKit20TranscriptionRequestV5modelSSvp","role":"symbol","modules":[{"name":"OpenAIKit"}],"symbolKind":"property"},"schemaVersion":{"major":0,"patch":0,"minor":3},"hierarchy":{"paths":[["doc:\/\/OpenAIKit\/documentation\/OpenAIKit","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest"]]},"abstract":[{"text":"The model to use for transcription.","type":"text"}],"kind":"symbol","references":{"doc://OpenAIKit/documentation/OpenAIKit":{"kind":"symbol","abstract":[{"text":"A powerful, type-safe Swift SDK for the OpenAI API with support for all major endpoints and platforms.","type":"text"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit","role":"collection","title":"OpenAIKit","url":"\/documentation\/openaikit","type":"topic"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionRequest/model":{"type":"topic","abstract":[{"type":"text","text":"The model to use for transcription."}],"fragments":[{"kind":"keyword","text":"let"},{"kind":"text","text":" "},{"kind":"identifier","text":"model"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"String","preciseIdentifier":"s:SS"}],"url":"\/documentation\/openaikit\/transcriptionrequest\/model","title":"model","role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest\/model","kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionRequest":{"title":"TranscriptionRequest","navigatorTitle":[{"text":"TranscriptionRequest","kind":"identifier"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","kind":"symbol","abstract":[{"type":"text","text":"A request to transcribe audio into text using OpenAI’s Whisper model."}],"url":"\/documentation\/openaikit\/transcriptionrequest","type":"topic","role":"symbol","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"TranscriptionRequest","kind":"identifier"}]}}}