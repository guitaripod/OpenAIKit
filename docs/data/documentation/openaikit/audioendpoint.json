{"primaryContentSections":[{"declarations":[{"tokens":[{"text":"final","kind":"keyword"},{"text":" ","kind":"text"},{"text":"class","kind":"keyword"},{"text":" ","kind":"text"},{"text":"AudioEndpoint","kind":"identifier"}],"languages":["swift"],"platforms":["Linux"]}],"kind":"declarations"},{"kind":"content","content":[{"text":"Overview","type":"heading","anchor":"overview","level":2},{"type":"paragraph","inlineContent":[{"type":"text","text":"The "},{"type":"codeVoice","code":"AudioEndpoint"},{"type":"text","text":" class handles text-to-speech generation, audio transcription,"},{"type":"text","text":" "},{"type":"text","text":"and audio translation operations. It provides a clean interface for working with"},{"type":"text","text":" "},{"type":"text","text":"OpenAI’s Whisper model for speech recognition and TTS models for speech synthesis."}]},{"text":"Overview","type":"heading","anchor":"Overview","level":2},{"type":"paragraph","inlineContent":[{"text":"This endpoint supports three main audio operations:","type":"text"}]},{"type":"unorderedList","items":[{"content":[{"type":"paragraph","inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Speech Generation"}]},{"type":"text","text":": Convert text to lifelike spoken audio"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"inlineContent":[{"text":"Transcription","type":"text"}],"type":"strong"},{"type":"text","text":": Convert audio to text in the same language"}]}]},{"content":[{"inlineContent":[{"inlineContent":[{"type":"text","text":"Translation"}],"type":"strong"},{"text":": Convert audio in any language to English text","type":"text"}],"type":"paragraph"}]}]}]}],"identifier":{"url":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint","interfaceLanguage":"swift"},"variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/openaikit\/audioendpoint"]}],"seeAlsoSections":[{"title":"Audio","generated":true,"identifiers":["doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/SpeechRequest","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranslationRequest"],"anchor":"Audio"}],"topicSections":[{"title":"Creating Speech from Text","identifiers":["doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint\/speech(_:)","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/SpeechRequest","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/Voice","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioFormat"],"anchor":"Creating-Speech-from-Text"},{"title":"Transcribing Audio","identifiers":["doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint\/transcriptions(_:)","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionFormat","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TimestampGranularity"],"anchor":"Transcribing-Audio"},{"title":"Translating Audio","identifiers":["doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint\/translations(_:)","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranslationRequest","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranslationResponse"],"anchor":"Translating-Audio"}],"sections":[],"metadata":{"fragments":[{"text":"class","kind":"keyword"},{"text":" ","kind":"text"},{"text":"AudioEndpoint","kind":"identifier"}],"roleHeading":"Class","title":"AudioEndpoint","externalID":"s:9OpenAIKit13AudioEndpointC","navigatorTitle":[{"text":"AudioEndpoint","kind":"identifier"}],"role":"symbol","modules":[{"name":"OpenAIKit"}],"symbolKind":"class"},"relationshipsSections":[{"title":"Conforms To","type":"conformsTo","kind":"relationships","identifiers":["doc:\/\/OpenAIKit\/s8SendableP"]}],"schemaVersion":{"minor":3,"patch":0,"major":0},"hierarchy":{"paths":[["doc:\/\/OpenAIKit\/documentation\/OpenAIKit"]]},"abstract":[{"text":"Provides access to OpenAI’s audio-related API endpoints.","type":"text"}],"kind":"symbol","references":{"doc://OpenAIKit/s8SendableP":{"title":"Swift.Sendable","identifier":"doc:\/\/OpenAIKit\/s8SendableP","type":"unresolvable"},"doc://OpenAIKit/documentation/OpenAIKit/TranslationResponse":{"title":"TranslationResponse","navigatorTitle":[{"text":"TranslationResponse","kind":"identifier"}],"type":"topic","kind":"symbol","abstract":[{"text":"The response from an audio translation request.","type":"text"}],"url":"\/documentation\/openaikit\/translationresponse","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranslationResponse","role":"symbol","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"TranslationResponse","kind":"identifier"}]},"doc://OpenAIKit/documentation/OpenAIKit/AudioEndpoint/speech(_:)":{"type":"topic","abstract":[{"text":"Generates audio from text using OpenAI’s text-to-speech models.","type":"text"}],"fragments":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"speech"},{"kind":"text","text":"("},{"kind":"typeIdentifier","text":"SpeechRequest","preciseIdentifier":"s:9OpenAIKit13SpeechRequestV"},{"kind":"text","text":") "},{"text":"async","kind":"keyword"},{"text":" ","kind":"text"},{"text":"throws","kind":"keyword"},{"text":" -> ","kind":"text"},{"text":"Data","kind":"typeIdentifier","preciseIdentifier":"s:20FoundationEssentials4DataV"}],"url":"\/documentation\/openaikit\/audioendpoint\/speech(_:)","title":"speech(_:)","role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint\/speech(_:)","kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit":{"kind":"symbol","abstract":[{"text":"A powerful, type-safe Swift SDK for the OpenAI API with support for all major endpoints and platforms.","type":"text"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit","role":"collection","title":"OpenAIKit","url":"\/documentation\/openaikit","type":"topic"},"doc://OpenAIKit/documentation/OpenAIKit/AudioEndpoint/transcriptions(_:)":{"title":"transcriptions(_:)","type":"topic","kind":"symbol","abstract":[{"type":"text","text":"Transcribes audio into text in the original language."}],"url":"\/documentation\/openaikit\/audioendpoint\/transcriptions(_:)","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint\/transcriptions(_:)","role":"symbol","fragments":[{"text":"func","kind":"keyword"},{"text":" ","kind":"text"},{"text":"transcriptions","kind":"identifier"},{"text":"(","kind":"text"},{"text":"TranscriptionRequest","kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit20TranscriptionRequestV"},{"text":") ","kind":"text"},{"text":"async","kind":"keyword"},{"text":" ","kind":"text"},{"text":"throws","kind":"keyword"},{"text":" -> ","kind":"text"},{"text":"TranscriptionResponse","kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit21TranscriptionResponseV"}]},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionResponse":{"navigatorTitle":[{"text":"TranscriptionResponse","kind":"identifier"}],"type":"topic","abstract":[{"text":"The response from an audio transcription request.","type":"text"}],"fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"TranscriptionResponse","kind":"identifier"}],"url":"\/documentation\/openaikit\/transcriptionresponse","title":"TranscriptionResponse","role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionRequest":{"title":"TranscriptionRequest","navigatorTitle":[{"text":"TranscriptionRequest","kind":"identifier"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","kind":"symbol","abstract":[{"type":"text","text":"A request to transcribe audio into text using OpenAI’s Whisper model."}],"url":"\/documentation\/openaikit\/transcriptionrequest","type":"topic","role":"symbol","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"TranscriptionRequest","kind":"identifier"}]},"doc://OpenAIKit/documentation/OpenAIKit/Voice":{"navigatorTitle":[{"text":"Voice","kind":"identifier"}],"type":"topic","abstract":[{"text":"Available voices for text-to-speech generation.","type":"text"}],"fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"Voice","kind":"identifier"}],"url":"\/documentation\/openaikit\/voice","title":"Voice","role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/Voice","kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit/AudioFormat":{"title":"AudioFormat","navigatorTitle":[{"text":"AudioFormat","kind":"identifier"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioFormat","kind":"symbol","type":"topic","url":"\/documentation\/openaikit\/audioformat","abstract":[{"text":"Supported audio formats for speech generation and transcription.","type":"text"}],"role":"symbol","fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"AudioFormat","kind":"identifier"}]},"doc://OpenAIKit/documentation/OpenAIKit/TimestampGranularity":{"navigatorTitle":[{"text":"TimestampGranularity","kind":"identifier"}],"type":"topic","abstract":[{"type":"text","text":"Granularity levels for timestamps in transcription responses."}],"fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"TimestampGranularity","kind":"identifier"}],"url":"\/documentation\/openaikit\/timestampgranularity","title":"TimestampGranularity","role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TimestampGranularity","kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionFormat":{"title":"TranscriptionFormat","navigatorTitle":[{"text":"TranscriptionFormat","kind":"identifier"}],"type":"topic","kind":"symbol","abstract":[{"text":"Output formats for audio transcription.","type":"text"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionFormat","url":"\/documentation\/openaikit\/transcriptionformat","role":"symbol","fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"TranscriptionFormat","kind":"identifier"}]},"doc://OpenAIKit/documentation/OpenAIKit/AudioEndpoint/translations(_:)":{"type":"topic","abstract":[{"text":"Translates audio from any language into English text.","type":"text"}],"fragments":[{"text":"func","kind":"keyword"},{"text":" ","kind":"text"},{"text":"translations","kind":"identifier"},{"text":"(","kind":"text"},{"text":"TranslationRequest","kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit18TranslationRequestV"},{"text":") ","kind":"text"},{"kind":"keyword","text":"async"},{"kind":"text","text":" "},{"kind":"keyword","text":"throws"},{"kind":"text","text":" -> "},{"kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit19TranslationResponseV","text":"TranslationResponse"}],"url":"\/documentation\/openaikit\/audioendpoint\/translations(_:)","title":"translations(_:)","role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint\/translations(_:)","kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit/SpeechRequest":{"title":"SpeechRequest","navigatorTitle":[{"text":"SpeechRequest","kind":"identifier"}],"type":"topic","kind":"symbol","abstract":[{"text":"A request to generate audio from text using OpenAI’s text-to-speech models.","type":"text"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/SpeechRequest","url":"\/documentation\/openaikit\/speechrequest","role":"symbol","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"SpeechRequest","kind":"identifier"}]},"doc://OpenAIKit/documentation/OpenAIKit/TranslationRequest":{"navigatorTitle":[{"text":"TranslationRequest","kind":"identifier"}],"type":"topic","abstract":[{"text":"A request to translate audio into English text.","type":"text"}],"fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"TranslationRequest","kind":"identifier"}],"url":"\/documentation\/openaikit\/translationrequest","title":"TranslationRequest","role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranslationRequest","kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit/AudioEndpoint":{"title":"AudioEndpoint","navigatorTitle":[{"kind":"identifier","text":"AudioEndpoint"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint","kind":"symbol","type":"topic","url":"\/documentation\/openaikit\/audioendpoint","abstract":[{"type":"text","text":"Provides access to OpenAI’s audio-related API endpoints."}],"role":"symbol","fragments":[{"kind":"keyword","text":"class"},{"kind":"text","text":" "},{"kind":"identifier","text":"AudioEndpoint"}]}}}