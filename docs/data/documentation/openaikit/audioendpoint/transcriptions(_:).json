{"sections":[],"seeAlsoSections":[{"title":"Related Documentation","identifiers":["doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionFormat","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TimestampGranularity"],"anchor":"Related-Documentation"},{"title":"Transcribing Audio","identifiers":["doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionFormat","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TimestampGranularity"],"generated":true,"anchor":"Transcribing-Audio"}],"hierarchy":{"paths":[["doc:\/\/OpenAIKit\/documentation\/OpenAIKit","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint"]]},"primaryContentSections":[{"kind":"declarations","declarations":[{"platforms":["Linux"],"languages":["swift"],"tokens":[{"text":"func","kind":"keyword"},{"text":" ","kind":"text"},{"text":"transcriptions","kind":"identifier"},{"text":"(","kind":"text"},{"text":"_","kind":"externalParam"},{"text":" ","kind":"text"},{"text":"request","kind":"internalParam"},{"text":": ","kind":"text"},{"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","text":"TranscriptionRequest","kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit20TranscriptionRequestV"},{"text":") ","kind":"text"},{"text":"async","kind":"keyword"},{"text":" ","kind":"text"},{"text":"throws","kind":"keyword"},{"text":" -> ","kind":"text"},{"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","text":"TranscriptionResponse","kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit21TranscriptionResponseV"}]}]},{"parameters":[{"content":[{"inlineContent":[{"type":"text","text":"A "},{"type":"reference","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","isActive":true},{"type":"text","text":" containing the audio file and configuration options."}],"type":"paragraph"}],"name":"request"}],"kind":"parameters"},{"kind":"content","content":[{"anchor":"return-value","level":2,"text":"Return Value","type":"heading"},{"inlineContent":[{"text":"A ","type":"text"},{"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","isActive":true,"type":"reference"},{"text":" containing the transcribed text and optional metadata.","type":"text"}],"type":"paragraph"}]},{"kind":"content","content":[{"type":"heading","anchor":"discussion","level":2,"text":"Discussion"},{"type":"paragraph","inlineContent":[{"text":"This method uses OpenAI’s Whisper model to convert audio files into accurate transcriptions.","type":"text"},{"text":" ","type":"text"},{"text":"It supports multiple languages, various audio formats, and can provide detailed timing information.","type":"text"}]},{"type":"heading","anchor":"Basic-Example","level":2,"text":"Basic Example"},{"type":"codeListing","code":["\/\/ Simple transcription","let audioData = try Data(contentsOf: audioFileURL)","let request = TranscriptionRequest(","    file: audioData,","    fileName: \"interview.mp3\"",")","let response = try await audioEndpoint.transcriptions(request)","print(response.text)"],"syntax":"swift"},{"type":"heading","anchor":"Advanced-Example-with-Timestamps","level":2,"text":"Advanced Example with Timestamps"},{"type":"codeListing","code":["\/\/ Detailed transcription with word-level timestamps","let request = TranscriptionRequest(","    file: audioData,","    fileName: \"podcast.mp3\",","    language: \"en\",  \/\/ Hint for better accuracy","    prompt: \"Technical podcast about Swift programming\",","    responseFormat: .verboseJson,","    timestampGranularities: [.word, .segment]",")","","let response = try await audioEndpoint.transcriptions(request)","","\/\/ Access detailed information","print(\"Detected language: \\(response.language ?? \"unknown\")\")","print(\"Duration: \\(response.duration ?? 0) seconds\")","","\/\/ Process word-level timestamps","for word in response.words ?? [] {","    print(\"\\(word.word) at \\(word.start)s\")","}"],"syntax":"swift"},{"type":"heading","anchor":"Creating-Subtitles","level":2,"text":"Creating Subtitles"},{"type":"codeListing","code":["\/\/ Generate SRT subtitles","let request = TranscriptionRequest(","    file: videoAudioData,","    fileName: \"video_audio.mp3\",","    responseFormat: .srt",")","let response = try await audioEndpoint.transcriptions(request)","try response.text.write(to: subtitlesURL, atomically: true, encoding: .utf8)"],"syntax":"swift"},{"type":"aside","name":"Throws","style":"note","content":[{"inlineContent":[{"type":"text","text":""},{"type":"reference","isActive":true,"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError"},{"type":"text","text":" if the transcription fails. Common errors include:"}],"type":"paragraph"},{"items":[{"content":[{"type":"paragraph","inlineContent":[{"isActive":true,"type":"reference","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/invalidFileData"},{"type":"text","text":": Audio file is corrupted or in an unsupported format"}]}]},{"content":[{"type":"paragraph","inlineContent":[{"isActive":true,"type":"reference","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/apiError(_:)"},{"type":"text","text":": File too large (>25MB) or other API errors"}]}]},{"content":[{"inlineContent":[{"type":"reference","isActive":true,"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/rateLimitExceeded"},{"type":"text","text":": Too many concurrent requests"}],"type":"paragraph"}]}],"type":"unorderedList"}]},{"type":"aside","name":"Note","style":"note","content":[{"type":"paragraph","inlineContent":[{"text":"Supported audio formats include: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, and webm.","type":"text"},{"text":" ","type":"text"},{"text":"File uploads are limited to 25 MB.","type":"text"}]}]}]}],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint\/transcriptions(_:)"},"variants":[{"paths":["\/documentation\/openaikit\/audioendpoint\/transcriptions(_:)"],"traits":[{"interfaceLanguage":"swift"}]}],"schemaVersion":{"major":0,"minor":3,"patch":0},"abstract":[{"text":"Transcribes audio into text in the original language.","type":"text"}],"kind":"symbol","metadata":{"modules":[{"name":"OpenAIKit"}],"externalID":"s:9OpenAIKit13AudioEndpointC14transcriptionsyAA21TranscriptionResponseVAA0F7RequestVYaKF","symbolKind":"method","role":"symbol","title":"transcriptions(_:)","fragments":[{"text":"func","kind":"keyword"},{"text":" ","kind":"text"},{"text":"transcriptions","kind":"identifier"},{"text":"(","kind":"text"},{"text":"TranscriptionRequest","preciseIdentifier":"s:9OpenAIKit20TranscriptionRequestV","kind":"typeIdentifier"},{"text":") ","kind":"text"},{"text":"async","kind":"keyword"},{"text":" ","kind":"text"},{"text":"throws","kind":"keyword"},{"kind":"text","text":" -> "},{"kind":"typeIdentifier","text":"TranscriptionResponse","preciseIdentifier":"s:9OpenAIKit21TranscriptionResponseV"}],"roleHeading":"Instance Method"},"references":{"doc://OpenAIKit/documentation/OpenAIKit/OpenAIError/apiError(_:)":{"url":"\/documentation\/openaikit\/openaierror\/apierror(_:)","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/apiError(_:)","title":"OpenAIError.apiError(_:)","role":"symbol","fragments":[{"kind":"keyword","text":"case"},{"kind":"text","text":" "},{"kind":"identifier","text":"apiError"},{"kind":"text","text":"("},{"kind":"typeIdentifier","text":"APIError","preciseIdentifier":"s:9OpenAIKit8APIErrorV"},{"kind":"text","text":")"}],"abstract":[{"type":"text","text":"An error response was received from the OpenAI API."}],"kind":"symbol","type":"topic"},"doc://OpenAIKit/documentation/OpenAIKit/OpenAIError":{"navigatorTitle":[{"text":"OpenAIError","kind":"identifier"}],"title":"OpenAIError","abstract":[{"type":"text","text":"The primary error type for all OpenAI API interactions."}],"role":"symbol","kind":"symbol","type":"topic","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError","url":"\/documentation\/openaikit\/openaierror","fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"OpenAIError","kind":"identifier"}]},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionFormat":{"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionFormat","type":"topic","role":"symbol","title":"TranscriptionFormat","abstract":[{"type":"text","text":"Output formats for audio transcription."}],"fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"TranscriptionFormat","kind":"identifier"}],"url":"\/documentation\/openaikit\/transcriptionformat","navigatorTitle":[{"text":"TranscriptionFormat","kind":"identifier"}],"kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionResponse":{"navigatorTitle":[{"text":"TranscriptionResponse","kind":"identifier"}],"title":"TranscriptionResponse","abstract":[{"text":"The response from an audio transcription request.","type":"text"}],"role":"symbol","kind":"symbol","type":"topic","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","url":"\/documentation\/openaikit\/transcriptionresponse","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"TranscriptionResponse","kind":"identifier"}]},"doc://OpenAIKit/documentation/OpenAIKit/OpenAIError/rateLimitExceeded":{"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/rateLimitExceeded","type":"topic","role":"symbol","title":"OpenAIError.rateLimitExceeded","abstract":[{"type":"text","text":"The API rate limit has been exceeded."}],"fragments":[{"text":"case","kind":"keyword"},{"text":" ","kind":"text"},{"text":"rateLimitExceeded","kind":"identifier"}],"url":"\/documentation\/openaikit\/openaierror\/ratelimitexceeded","kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit/AudioEndpoint":{"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint","type":"topic","role":"symbol","title":"AudioEndpoint","abstract":[{"text":"Provides access to OpenAI’s audio-related API endpoints.","type":"text"}],"fragments":[{"text":"class","kind":"keyword"},{"text":" ","kind":"text"},{"text":"AudioEndpoint","kind":"identifier"}],"url":"\/documentation\/openaikit\/audioendpoint","navigatorTitle":[{"text":"AudioEndpoint","kind":"identifier"}],"kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit/OpenAIError/invalidFileData":{"title":"OpenAIError.invalidFileData","abstract":[{"text":"The provided file data is invalid or corrupted.","type":"text"}],"role":"symbol","kind":"symbol","type":"topic","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/invalidFileData","url":"\/documentation\/openaikit\/openaierror\/invalidfiledata","fragments":[{"text":"case","kind":"keyword"},{"text":" ","kind":"text"},{"text":"invalidFileData","kind":"identifier"}]},"doc://OpenAIKit/documentation/OpenAIKit/AudioEndpoint/transcriptions(_:)":{"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint\/transcriptions(_:)","type":"topic","role":"symbol","title":"transcriptions(_:)","abstract":[{"text":"Transcribes audio into text in the original language.","type":"text"}],"fragments":[{"text":"func","kind":"keyword"},{"text":" ","kind":"text"},{"text":"transcriptions","kind":"identifier"},{"text":"(","kind":"text"},{"preciseIdentifier":"s:9OpenAIKit20TranscriptionRequestV","text":"TranscriptionRequest","kind":"typeIdentifier"},{"text":") ","kind":"text"},{"text":"async","kind":"keyword"},{"text":" ","kind":"text"},{"text":"throws","kind":"keyword"},{"text":" -> ","kind":"text"},{"text":"TranscriptionResponse","kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit21TranscriptionResponseV"}],"url":"\/documentation\/openaikit\/audioendpoint\/transcriptions(_:)","kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit/TimestampGranularity":{"type":"topic","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TimestampGranularity","role":"symbol","title":"TimestampGranularity","abstract":[{"type":"text","text":"Granularity levels for timestamps in transcription responses."}],"fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"TimestampGranularity","kind":"identifier"}],"url":"\/documentation\/openaikit\/timestampgranularity","navigatorTitle":[{"text":"TimestampGranularity","kind":"identifier"}],"kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit":{"url":"\/documentation\/openaikit","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit","title":"OpenAIKit","role":"collection","abstract":[{"text":"A powerful, type-safe Swift SDK for the OpenAI API with support for all major endpoints and platforms.","type":"text"}],"kind":"symbol","type":"topic"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionRequest":{"kind":"symbol","url":"\/documentation\/openaikit\/transcriptionrequest","fragments":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"kind":"identifier","text":"TranscriptionRequest"}],"title":"TranscriptionRequest","role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","abstract":[{"type":"text","text":"A request to transcribe audio into text using OpenAI’s Whisper model."}],"navigatorTitle":[{"kind":"identifier","text":"TranscriptionRequest"}],"type":"topic"}}}