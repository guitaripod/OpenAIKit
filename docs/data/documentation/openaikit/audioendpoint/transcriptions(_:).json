{"identifier":{"url":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint\/transcriptions(_:)","interfaceLanguage":"swift"},"schemaVersion":{"major":0,"minor":3,"patch":0},"metadata":{"roleHeading":"Instance Method","symbolKind":"method","title":"transcriptions(_:)","externalID":"s:9OpenAIKit13AudioEndpointC14transcriptionsyAA21TranscriptionResponseVAA0F7RequestVYaKF","role":"symbol","modules":[{"name":"OpenAIKit"}],"fragments":[{"text":"func","kind":"keyword"},{"text":" ","kind":"text"},{"text":"transcriptions","kind":"identifier"},{"text":"(","kind":"text"},{"text":"TranscriptionRequest","kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit20TranscriptionRequestV"},{"text":") ","kind":"text"},{"text":"async","kind":"keyword"},{"text":" ","kind":"text"},{"text":"throws","kind":"keyword"},{"text":" -> ","kind":"text"},{"text":"TranscriptionResponse","kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit21TranscriptionResponseV"}]},"hierarchy":{"paths":[["doc:\/\/OpenAIKit\/documentation\/OpenAIKit","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint"]]},"variants":[{"paths":["\/documentation\/openaikit\/audioendpoint\/transcriptions(_:)"],"traits":[{"interfaceLanguage":"swift"}]}],"seeAlsoSections":[{"identifiers":["doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionFormat","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TimestampGranularity"],"anchor":"Related-Documentation","title":"Related Documentation"},{"identifiers":["doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionFormat","doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TimestampGranularity"],"anchor":"Transcribing-Audio","title":"Transcribing Audio","generated":true}],"abstract":[{"type":"text","text":"Transcribes audio into text in the original language."}],"kind":"symbol","sections":[],"primaryContentSections":[{"kind":"declarations","declarations":[{"tokens":[{"kind":"keyword","text":"func"},{"kind":"text","text":" "},{"kind":"identifier","text":"transcriptions"},{"kind":"text","text":"("},{"kind":"externalParam","text":"_"},{"kind":"text","text":" "},{"kind":"internalParam","text":"request"},{"kind":"text","text":": "},{"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","kind":"typeIdentifier","text":"TranscriptionRequest","preciseIdentifier":"s:9OpenAIKit20TranscriptionRequestV"},{"kind":"text","text":") "},{"kind":"keyword","text":"async"},{"kind":"text","text":" "},{"kind":"keyword","text":"throws"},{"kind":"text","text":" -> "},{"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","kind":"typeIdentifier","text":"TranscriptionResponse","preciseIdentifier":"s:9OpenAIKit21TranscriptionResponseV"}],"platforms":["Linux"],"languages":["swift"]}]},{"kind":"parameters","parameters":[{"content":[{"type":"paragraph","inlineContent":[{"type":"text","text":"A "},{"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","isActive":true,"type":"reference"},{"type":"text","text":" containing the audio file and configuration options."}]}],"name":"request"}]},{"kind":"content","content":[{"text":"Return Value","type":"heading","level":2,"anchor":"return-value"},{"inlineContent":[{"text":"A ","type":"text"},{"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","type":"reference","isActive":true},{"text":" containing the transcribed text and optional metadata.","type":"text"}],"type":"paragraph"}]},{"kind":"content","content":[{"anchor":"discussion","text":"Discussion","type":"heading","level":2},{"inlineContent":[{"text":"This method uses OpenAI’s Whisper model to convert audio files into accurate transcriptions.","type":"text"},{"text":" ","type":"text"},{"text":"It supports multiple languages, various audio formats, and can provide detailed timing information.","type":"text"}],"type":"paragraph"},{"anchor":"Basic-Example","text":"Basic Example","type":"heading","level":2},{"code":["\/\/ Simple transcription","let audioData = try Data(contentsOf: audioFileURL)","let request = TranscriptionRequest(","    file: audioData,","    fileName: \"interview.mp3\"",")","let response = try await audioEndpoint.transcriptions(request)","print(response.text)"],"type":"codeListing","syntax":"swift"},{"anchor":"Advanced-Example-with-Timestamps","text":"Advanced Example with Timestamps","type":"heading","level":2},{"code":["\/\/ Detailed transcription with word-level timestamps","let request = TranscriptionRequest(","    file: audioData,","    fileName: \"podcast.mp3\",","    language: \"en\",  \/\/ Hint for better accuracy","    prompt: \"Technical podcast about Swift programming\",","    responseFormat: .verboseJson,","    timestampGranularities: [.word, .segment]",")","","let response = try await audioEndpoint.transcriptions(request)","","\/\/ Access detailed information","print(\"Detected language: \\(response.language ?? \"unknown\")\")","print(\"Duration: \\(response.duration ?? 0) seconds\")","","\/\/ Process word-level timestamps","for word in response.words ?? [] {","    print(\"\\(word.word) at \\(word.start)s\")","}"],"type":"codeListing","syntax":"swift"},{"anchor":"Creating-Subtitles","text":"Creating Subtitles","type":"heading","level":2},{"code":["\/\/ Generate SRT subtitles","let request = TranscriptionRequest(","    file: videoAudioData,","    fileName: \"video_audio.mp3\",","    responseFormat: .srt",")","let response = try await audioEndpoint.transcriptions(request)","try response.text.write(to: subtitlesURL, atomically: true, encoding: .utf8)"],"type":"codeListing","syntax":"swift"},{"style":"note","name":"Throws","content":[{"inlineContent":[{"text":"","type":"text"},{"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError","isActive":true,"type":"reference"},{"text":" if the transcription fails. Common errors include:","type":"text"}],"type":"paragraph"},{"type":"unorderedList","items":[{"content":[{"inlineContent":[{"type":"reference","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/invalidFileData","isActive":true},{"type":"text","text":": Audio file is corrupted or in an unsupported format"}],"type":"paragraph"}]},{"content":[{"type":"paragraph","inlineContent":[{"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/apiError(_:)","isActive":true,"type":"reference"},{"text":": File too large (>25MB) or other API errors","type":"text"}]}]},{"content":[{"inlineContent":[{"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/rateLimitExceeded","type":"reference","isActive":true},{"type":"text","text":": Too many concurrent requests"}],"type":"paragraph"}]}]}],"type":"aside"},{"style":"note","name":"Note","content":[{"type":"paragraph","inlineContent":[{"text":"Supported audio formats include: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, and webm.","type":"text"},{"text":" ","type":"text"},{"text":"File uploads are limited to 25 MB.","type":"text"}]}],"type":"aside"}]}],"references":{"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionRequest":{"title":"TranscriptionRequest","navigatorTitle":[{"text":"TranscriptionRequest","kind":"identifier"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionRequest","kind":"symbol","abstract":[{"type":"text","text":"A request to transcribe audio into text using OpenAI’s Whisper model."}],"url":"\/documentation\/openaikit\/transcriptionrequest","type":"topic","role":"symbol","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"TranscriptionRequest","kind":"identifier"}]},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionResponse":{"navigatorTitle":[{"text":"TranscriptionResponse","kind":"identifier"}],"type":"topic","abstract":[{"text":"The response from an audio transcription request.","type":"text"}],"fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"TranscriptionResponse","kind":"identifier"}],"url":"\/documentation\/openaikit\/transcriptionresponse","title":"TranscriptionResponse","role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionResponse","kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit/AudioEndpoint":{"title":"AudioEndpoint","navigatorTitle":[{"kind":"identifier","text":"AudioEndpoint"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint","kind":"symbol","type":"topic","url":"\/documentation\/openaikit\/audioendpoint","abstract":[{"type":"text","text":"Provides access to OpenAI’s audio-related API endpoints."}],"role":"symbol","fragments":[{"kind":"keyword","text":"class"},{"kind":"text","text":" "},{"kind":"identifier","text":"AudioEndpoint"}]},"doc://OpenAIKit/documentation/OpenAIKit/OpenAIError/apiError(_:)":{"title":"OpenAIError.apiError(_:)","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/apiError(_:)","url":"\/documentation\/openaikit\/openaierror\/apierror(_:)","type":"topic","kind":"symbol","abstract":[{"text":"An error response was received from the OpenAI API.","type":"text"}],"role":"symbol","fragments":[{"text":"case","kind":"keyword"},{"text":" ","kind":"text"},{"text":"apiError","kind":"identifier"},{"text":"(","kind":"text"},{"text":"APIError","kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit8APIErrorV"},{"text":")","kind":"text"}]},"doc://OpenAIKit/documentation/OpenAIKit/OpenAIError/invalidFileData":{"type":"topic","abstract":[{"text":"The provided file data is invalid or corrupted.","type":"text"}],"fragments":[{"kind":"keyword","text":"case"},{"kind":"text","text":" "},{"kind":"identifier","text":"invalidFileData"}],"url":"\/documentation\/openaikit\/openaierror\/invalidfiledata","title":"OpenAIError.invalidFileData","role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/invalidFileData","kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit/OpenAIError":{"fragments":[{"kind":"keyword","text":"enum"},{"kind":"text","text":" "},{"kind":"identifier","text":"OpenAIError"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError","url":"\/documentation\/openaikit\/openaierror","title":"OpenAIError","navigatorTitle":[{"kind":"identifier","text":"OpenAIError"}],"role":"symbol","abstract":[{"text":"The primary error type for all OpenAI API interactions.","type":"text"}],"type":"topic","kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit/TimestampGranularity":{"navigatorTitle":[{"text":"TimestampGranularity","kind":"identifier"}],"type":"topic","abstract":[{"type":"text","text":"Granularity levels for timestamps in transcription responses."}],"fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"TimestampGranularity","kind":"identifier"}],"url":"\/documentation\/openaikit\/timestampgranularity","title":"TimestampGranularity","role":"symbol","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TimestampGranularity","kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit/TranscriptionFormat":{"title":"TranscriptionFormat","navigatorTitle":[{"text":"TranscriptionFormat","kind":"identifier"}],"type":"topic","kind":"symbol","abstract":[{"text":"Output formats for audio transcription.","type":"text"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/TranscriptionFormat","url":"\/documentation\/openaikit\/transcriptionformat","role":"symbol","fragments":[{"text":"enum","kind":"keyword"},{"text":" ","kind":"text"},{"text":"TranscriptionFormat","kind":"identifier"}]},"doc://OpenAIKit/documentation/OpenAIKit/OpenAIError/rateLimitExceeded":{"fragments":[{"kind":"keyword","text":"case"},{"kind":"text","text":" "},{"kind":"identifier","text":"rateLimitExceeded"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/OpenAIError\/rateLimitExceeded","url":"\/documentation\/openaikit\/openaierror\/ratelimitexceeded","title":"OpenAIError.rateLimitExceeded","role":"symbol","abstract":[{"type":"text","text":"The API rate limit has been exceeded."}],"type":"topic","kind":"symbol"},"doc://OpenAIKit/documentation/OpenAIKit":{"kind":"symbol","abstract":[{"text":"A powerful, type-safe Swift SDK for the OpenAI API with support for all major endpoints and platforms.","type":"text"}],"identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit","role":"collection","title":"OpenAIKit","url":"\/documentation\/openaikit","type":"topic"},"doc://OpenAIKit/documentation/OpenAIKit/AudioEndpoint/transcriptions(_:)":{"title":"transcriptions(_:)","type":"topic","kind":"symbol","abstract":[{"type":"text","text":"Transcribes audio into text in the original language."}],"url":"\/documentation\/openaikit\/audioendpoint\/transcriptions(_:)","identifier":"doc:\/\/OpenAIKit\/documentation\/OpenAIKit\/AudioEndpoint\/transcriptions(_:)","role":"symbol","fragments":[{"text":"func","kind":"keyword"},{"text":" ","kind":"text"},{"text":"transcriptions","kind":"identifier"},{"text":"(","kind":"text"},{"text":"TranscriptionRequest","kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit20TranscriptionRequestV"},{"text":") ","kind":"text"},{"text":"async","kind":"keyword"},{"text":" ","kind":"text"},{"text":"throws","kind":"keyword"},{"text":" -> ","kind":"text"},{"text":"TranscriptionResponse","kind":"typeIdentifier","preciseIdentifier":"s:9OpenAIKit21TranscriptionResponseV"}]}}}